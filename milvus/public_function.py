"""
å…¬å…±å‡½æ•°åº“
è¯¥æ–‡ä»¶åŒ…å«ä¸€äº›å¸¸ç”¨çš„å…¬å…±å‡½æ•°ï¼Œç”¨äºæ•°æ®å¤„ç†ã€æ–‡ä»¶è¯»å†™ç­‰æ“ä½œã€‚
"""

import os
import json
import pickle
from pathlib import Path
from sentence_transformers import SentenceTransformer
from processor.SummaryGenerator import SummaryGenerator


def write_data_to_pkl(docs, file_path):
    """å°†æ•°æ®å†™å…¥åˆ° pkl æ–‡ä»¶"""
    with open(file_path, 'wb') as file:
        pickle.dump(docs, file)


def read_data_from_pkl(file_path):
    """ä» pkl æ–‡ä»¶åŠ è½½æ•°æ® """
    try:
        with open(file_path, 'rb') as file:
            docs = pickle.load(file)
    except:
        raise FileNotFoundError(f"æ–‡ä»¶ {file_path} ä¸å­˜åœ¨")

    return docs


def write_data_to_txt(data, file_path):
    """å°†æ•°æ®å†™å…¥åˆ° txt æ–‡ä»¶"""
    with open(file_path, 'w', encoding='utf-8') as file:
        json.dump(data, file, ensure_ascii=False, indent=4)


def read_data_from_txt(file_path):
    """ä» txt æ–‡ä»¶åŠ è½½æ•°æ®"""
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            data = json.load(file)
    except:
        raise FileNotFoundError(f"æ–‡ä»¶ {file_path} ä¸å­˜åœ¨")

    return data


def get_local_model_path(model_name: str) -> str:
    """
    å°† 'Alibaba-NLP/gte-multilingual-base' è½¬æ¢æˆæœ¬åœ° cache è·¯å¾„
    å¦‚ ~/.cache/huggingface/hub/models--Alibaba-NLP--gte-multilingual-base/snapshots/<hash>
    """
    safe_name = model_name.replace("/", "--")
    hub_dir = Path.home() / ".cache" / "huggingface" / "hub"
    model_dir = hub_dir / f"models--{safe_name}" / "snapshots"
    
    # é»˜è®¤åªå–ç¬¬ä¸€ä¸ª snapshot å­ç›®å½•ï¼ˆä¸€èˆ¬åªæœ‰ä¸€ä¸ªï¼‰
    snapshot_dirs = list(model_dir.glob("*"))
    if not snapshot_dirs:
        raise FileNotFoundError(f"No local snapshot found for model: {model_name}")
    
    return str(snapshot_dirs[0])


def load_embedding_model(model_name: str, device: str):
    """åŠ è½½åµŒå…¥æ¨¡å‹"""
    print(f"ğŸš€ åµŒå…¥æ¨¡å‹ï¼š{model_name}ï¼ŒåŠªåŠ›åŠ è½½ä¸­...")
    try:
        model_path = get_local_model_path(model_name)
        embedding_model = SentenceTransformer(
            model_path,
            device = device,
            trust_remote_code = True,
            local_files_only = True
        )
        print("âœ… åµŒå…¥æ¨¡å‹åŠ è½½å®Œæˆï¼")
    except Exception as e:
        print(f"âŒ åµŒå…¥æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}")
        raise e

    return embedding_model


def load_summary_model(model_name: str, config):
    """åŠ è½½æ‘˜è¦ç”Ÿæˆæ¨¡å‹"""
    print(f"ğŸš€ æ‘˜è¦ç”Ÿæˆæ¨¡å‹ï¼š{model_name}ï¼ŒåŠªåŠ›åŠ è½½ä¸­...")
    try:
        summary_model = SummaryGenerator(model_name, config)
        print("âœ… æ‘˜è¦ç”Ÿæˆæ¨¡å‹åŠ è½½å®Œæˆï¼")
    except Exception as e:
        print(f"âŒ æ‘˜è¦ç”Ÿæˆæ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}")
        raise e

    return summary_model


