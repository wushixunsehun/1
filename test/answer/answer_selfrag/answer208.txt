nvidia-smi 命令用于查看 NVIDIA GPU 的状态和使用情况，通常在需要监控 GPU 资源或排查问题时使用。使用方法包括直接在终端输入 nvidia-smi 或者结合作业调度系统命令如 yhrun jobid=<job_id> nvidia-smi 来查询特定作业的 GPU 使用情况。通过该命令可以获取以下信息：1. GPU 的驱动版本、CUDA 版本以及 GPU 名称等基本信息；2. GPU 的温度、功耗、性能状态以及计算资源使用率；3. 显存使用情况，包括已使用和总显存容量；4. 当前占用 GPU 的进程及其使用的显存大小。此外，还可以看到 GPU 是否处于忙碌状态以及是否有进程在使用 GPU 资源。例如，文本中提到某 GPU 正在使用 98% 的计算资源，占用 1542MiB 显存，而其他 GPU 的使用率为 0%，同时显示有一个 Python 进程占用了 1539MiB 显存。这些信息有助于用户了解 GPU 的运行状态并进行相应的优化调整。