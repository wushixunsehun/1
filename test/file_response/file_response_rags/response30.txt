{
    "query": " yhalloc 中如何设置作业每个任务使用2个CPU？",
    "summaries": [
        "本文档介绍了yhalloc命令的多个选项，用于控制作业在资源管理系统中的执行和资源分配。主要功能包括：设置任务与CPU、socket、core或thread的绑定方式，指定每个任务所需的CPU数量，切换工作目录，独占节点，从文件获取节点列表，获取用户环境变量，设置作业名称，处理资源回收信号等。这些选项帮助用户更精细地控制作业的资源使用和执行行为，以优化性能和资源利用率。",
        "本文介绍了在HPC2上使用CALYPSO自动Split模式提交任务的步骤。首先生成结构优化作业脚本，修改参数配置，去掉`calypso.x`前的`./`。然后提交任务，需注意两次运行的区别：第一次生成`vasp.sh`，第二次提交作业。需确保`vasp.sh`和`caly_auto_split.py`中设置的核数一致，后者修改位置在第287行。提供了一个`vasp.sh`示例，包含循环执行VASP计算的命令。",
        "yhbatch 是用于提交批处理作业的命令，支持多种选项来控制作业的资源分配、执行方式和依赖关系。例如，--overcommit 允许每个处理器运行多个任务，-o 指定输出文件，--partition 选择资源分区，--time 设置运行时间限制，-p 指定分区，--dependency 定义作业依赖关系等。此外，还支持资源限制传递、作业重新排队、节点共享、临时磁盘空间设置等功能。环境变量也可用于设置选项，且命令行选项优先级高于环境变量。"
    ],
    "contents": [
        "node.e --tmp=VMB最少临时磁盘空间。。 -u, --usage显式简短帮助信息并退出。e -—-uid=userDAF user 的号份提交和运行作业，而不是执行 yhbatch 的用户。执行 yhbatch的用户号份将用于检查目标分区的访问权限。例如，root 用户可以使用此选项在RootOnly 分区中以普通用户寻份运行作业。wser 可以是用户名或数值用户 UID。e -V, --version显示版本信息并退出。e -v, --verbose增加 yhbatch MIHAILA. AMS Sv. SAUL F OLEACEAEe -w, --nodelist=node name listte OR Ta EAT A EAE BEY VA AG SP BE 2% BEB] CT cn[1-5,7,..)) Fax o MUZE FEY FEAST A AE CAR «BREA A 4 II AS BARE家资源管理系统重新排序。e --wckey=wckey作业使用的 wekey. AACE CPE TrackWCKey=no (ik), UCT KAR II.e --wrap=command stringyhbatch 将把指定的命令串包闭成一个简单的“sh”shell 脚本，并把该脚本提交到控制进程。当使用 --wrap 时，不能在命令行指定脚本名字和参数。e -x, --exclude=node name list不要将指定的节点分配给作业。186\n16.4. yhbatch输入环境变量在司动时，yhbatch 将读取并处理如下环境变量中设置的选项。请注意，环境变量中的选项将轿盖批处理脚本中的选项，而命令行选项将履盖环境变量中的选项。。 SBATCH ACCOUNT: 同 -A, --account。 SBATCH_ACCTG_FREQ: 同 --acctg-freq。 SLURM_CHECKPOINT: 同 --checkpoint。 SLURM_CHECKPOINT_DIR: [A] --checkpoint-dir。 SBATCH_CONN_TYPE: [A] --conn-type。 SBATCH_CPU_BIND: 同 --cpu_bind。 SBATCH DEBUG: 同 -v, --verbose。 SBATCH DISTRIBUTION: 同 -m,",
        "【已解决】HPC2 CALYPSO自动Split模式提交任务\n**标签**: CALYPSO\n**创建时间**: 2023-10-26 14:32:53\n**更新时间**: 2023-10-26 14:34:51\n**作者**: 梁言\n1. 产生结构优化作业提交脚本\n./caly_auto_split.py 参数   ###参数可选pbs、lsf、yhi、slurm\n11行修改成如下，去掉了calypso.x前的./\ncalypath = 'calypso.x',machine = 'pbs'):\n2.提交结构预测任务\nnohup./caly_auto_split.py 参数> caly.log 2>&1 &\n##########实例\n运行第一次    ./caly_auto_split.py yhi 产生vasp.sh ，然后根据环境修改\n运行第二次   nohup./caly_auto_split.py yhi> caly.log 2>&1 & 是提交作业\n有两个地方有设置运行核数，vasp.sh 里和caly_auto_split.py 里，需要一致\n后者修改的位置在caly_auto_split.py里的287行\nsubmit = 'yhbatch -p TH_SHORT2 -N 1 -n 28 vasp.sh'\nvasp.sh示例\n#!/bin/bash\nfor(( i=1; i<=3; i++ ));\ndo\ncp INCAR_$i INCAR\ncp CONTCAR POSCAR\nyhrun -N 1 -n 20 -p TH_SHORT2  /THL7/home/fjnu1/vasp.5.4.4/bin/vasp_std > vasp.log 2>&1\ndone",
        ", --overcommit183\n资源管理系统手册WEE AUR. AY, yhbatch 为每个处理器分配一个任务。指定 --overcommit时，将显式允许每个处理器上运行多个任务。然而，每个节点上运行的任务数不超过 MAX TASKS PER NODE 个任务。。 -o, --output=filename pattern将批处理脚本的标准输出写到 filename pattern 指定的文件中。文件名规范清参见--input 选项。。 --open-mode=append|truncate使用附加模式或截断模式打开标准输出和标准错误文件。缺省值由系统配置文件中的 JobFileAppend 参数指定。e -P, --denpendency=dependency_list延迟运行作业，直到指定的依赖关系被满足。dependency_1stf 形如 type:jobid|:jobid|[tpe:7obid[:7opid]j。多个作业可以共享使用相同的依赖关系，这些作业也可以属于不同的用户。作业提交后可以通过 yhcontrol 命令修改依赖关系。一 after: jobid|:jobid...]此作业可在指定的作业开始执行后运行。一 afterany: jobid|:jobid...]此作业可在指定的作业终止后运行。一 afternotok: jobid|:jobid...]此作业可在指定的作业失败〈非 0 退出码，节点失效，超时等) 后运行。一 afternotok: jobid|:jobid...]此作业可在指定的作业成功〈运行结束，退出码为 0) 后运行。— singleton此作业在之前运行的具有相同名字和用户的作业终止后运行。e。 -p, --partition=partition name在指定分区中分配资源。如未指定，则由控制进程在系统默认分区中分配资源。。 --propagate[=rlimits]将那些可修改〈软) 资源限制传递到计算贡点并应用到作业任务进程。如未指定riizp2its，则传递所有资源限制。资源管理系统文持如下资源名字《尽管有些系统不文持茶些选项):— ALL: 所有资源限制184\n16.4. yhbatch— AS: 进程的最大地址空间— CORE: core 文件大小— CPU: 最多 CPU 时间— DATA: 进程的数据段大小— FSIZE: 所创建",
        "地请求 12 个处理器，则控制进程可能仅分配给 3 个节点。然而，通过使用 --cpus-per-task=3 选项，控制进程将知道每个任务需要同一节点上的 3 个处理器，并为 4 个任务分配 4 个节点。e -D, --chdir=path在执行命令之前将目录切换到 pathoe --exclusive此作业不能与其他运行的作业共享节点。此选项是 --share 的反义，哪个出现在命令行的最后哪个起作用。(缺省的 share/exclusive 行为与系统配置相关。)。 -F, --nodefile=node file159\n资源管理系统手册类似与 --nodelist，但是节点列表包含在文件 node file 中。列表中的文件名可以路多行。文件中的重复节点名将被忽略。列表中的节氮顺序不重要，节氮列表将科资源管理系统重新排序。。 --get-user-env|=timeout]|mode|此选项用于使 yhalloc 获取 --uid 所指定的用户的登录环境变量。环境变量通过运行“su - username -c /usr/bin/env”并分析输出的方法获取。请注症，yhalloc执行时的环境变量将比如此获取的环境变量更优先。如果不想被传递到加载的程序，请在运行 yhalloc 前清除相应的环境变量。可选的 timeout 值是秒数，缺省为 8秒。可选的 mode 值控制“su”的运行选项。mode 置为“S”时,“su”执行时没有“-”选项; mode 值为“L”时,“su”执行时有“-”选项，以复制登录环境。如果未指定 mode，则使用资源管理系统编译时的内置值。应用示例包括“--get-user-》” Kfs下二 o6 6env”, “--get-user-env=10”, “--get-user-env=10L”, “--get-user-env=S注意: 此选项仅在执行 yhalloc 的有效用户 UID W root NAR.。 -—-gid=group如果以 root 运行 yhalloc，且使用了 --gid 选项，则以 group 的",
        "仅在执行 yhalloc 的有效用户 UID W root NAR.。 -—-gid=group如果以 root 运行 yhalloc，且使用了 --gid 选项，则以 group 的组访问权限提交YENL. group 可以是组名字或数字的组 GID.。 -h, --help显示帮助信息并退出。。 —-hint=type根据应用提示进行任务绑定:一 compute_bound选择适合计算密集型应用的设置: 使用每个 socket 上的每个 core。一 memory_bound选择适合内存密集型应用的设置: 仅使用每个 socket 上的一个 core.— [no]multithreadLA | 使用 core 上额外的 thread，这可能对通信密集型应用有益。— help显示帮助信息。。 -I, --immediate|=seconds|如果资源在指定的时间内不能被满足则退出。如果没有指定秒数，则资源必须立即可用。缺省地，yhalloc 将阻喜等竺直到资源可用。160\n16.2. yhalloc-J, --job-name=jobname为作业指定名字。当和查看系统中的作业时，名字将和作业 JobID 一起显示。缺省的名字命令行指定的“commza7zd”。--jobid=jobid使用指定的 JobID 分配资源。注意: 仅对 root HR AR.-K, --kill-command|=siganl|yhalloc 在获取资源后总是运行用户指定的命令，并无穷等待直到该命令退出。如末指定了 --kill-command 选项，当资源管理控制进程通知 yhalloc 作业分配已被收回时，yhalloc 将向用户命令发送指定的信号。作业分配可能因几个原因被回收:有人使用 yhcancel 命令取消了作业，或作业到达运行时间限制等。如果没有指定aA MBE, Wika A SIGTERM.-k, --no-kill当分配给作业的节点失效时不要自动终止作业。用户需要自己在节点失效时进行容错。当发生节点失效时，运行在该节点上的活动作业步〈通各为 MPI 作业) 几乎肯定会发生致命错误;但是使用 --no-kill 时，分配给作业的节点不会被回收，从而用户可以在剩余的",
        "16.4. yhbatch— AS: 进程的最大地址空间— CORE: core 文件大小— CPU: 最多 CPU 时间— DATA: 进程的数据段大小— FSIZE: 所创建文件的大小— MEMLOCK: 锁定内存的大小— NOFILE: 打开文件数目— NPROC: 可用进程数目— RSS: 最大物理内存— STACK: 栈大小-Q, --quiet不要输出一般信息。错误信息仍将显示。--qos=qos作业的服务质量。QOS 可以在记账数据库中为每个用户/系统/帐号 association 定义。当系统配置参数 AccountingStorageEnforce 包含“qos”时，用户将仅能使用为其 association 定义的 QOS。—-requeue在节点失效时将作业重新排队。当作业被重新排队后，批处理脚本从头开始执行。参见 —-no-requeue 选项。配置参数 JobRequeue 控制系统上的缺少行为。--reservation=name从指定的预约中为作业分配资源。-s, --share作业可以与其它运行作业共享节点。这可以导致更早分配资源，以及更高的系统利用率，但是由于竞争节点内的资源，应用的性能可能会下降。缺省的共享/互斥行为与系统配置相关。-t, --time=time作业运行的总时间限制。如果请求的时间限制超过分区的时间限制，作业将保持在排队状态。缺省的作业运行时间限制是分区的时间限制。当到达运行时间限制时，作业的所有作业步的所有任务都将被发送 SIGTERM 和 SIGKILL 信号。两个信号之185\n资源管理系统手册间的时间间隔有系统配置参数 KillWait 指定。时间限制设置为 0 表示没有时间限制。可用的时间格式包括“7pzpautes” “minutes:seconds”, “hours:minutes:seconds”,“days-hours”, “days-hours:minutes”, VU “ days-hours:minutes:seconds”。 —-tasks-per-node=n[a] --ntasks-per-node.e --tmp=VMB最少临时磁盘空间。。 -u, --usage显式简短帮助信息并退出。e -—-uid=userDAF user 的号份提交和运行作业，而不是执行",
        "局部域选项，则每个 socket 被作为一个局部域。文持的选项值包括:— qluiet]SEB ISAT A PLA TE CRA)— vLlerbose]任务运行前报告绑和定情况一 no [nej]不绑定任务到 CPU CRE)— rank根据任务号自动绑定。0 号任务被绑定到 0 号 socket (2K core BK thread), FF.仅在整个节点分配给作业的情况下文持。一 map_cpu: list按照给出的列表将 CPU 映射到任务，其中 list 形如 cpuidd,cpuid1,...cpuidN .CPU ID 为十进制数，有前组“0x”时为十六进制数。仅在整个节点分配给作业的情况下文持。158\n16.2. yhalloc一 mask cpu: list按照给出的列表设置任务的 CPU #885, eA list 形如 mask0,mask1,...maskN .CPU 撞码总是十六进制数，前缀“0x”可选。— sockets自动生成把任务绑定到 socket WEIS. WARES MS AACN socket WAT, FY能导致非最优绑定。— cores自动生成把任务绑定到 core 的掩码。如果任务数与分配的 core 数不同，可能导致非最优绑定。— threads自动生成把任务绑定到 thread 的掩码。如果任务数与分配的 thread AA,可能导致非最优绑定。一 ldoms自动生成把任务绑定到 NUMA 局部域的掩码。如果任务数与分配的NUMA 局部域数不同，可能导致非最优绑定。— help显示帮助信息。。 -C, —-Cpus-per-task=ncpus告知资源管理系统控制进程，作业步的每个任务需要 ncpus 个处理器。知未指定此选项，则控制进程加你个尝试为每个任务分配一个处理需。例如，考虑一个 4任务的应用，每个任务需要 3 个处理器。如果系统由四处理器贡点组成，而我们简单地请求 12 个处理器，则控制进程可能仅分配给 3 个节点。然而，通过使用 --cpus-per-task=3 选项，控制进程将知道每个任务需要同一节点上的 3"
    ]
}