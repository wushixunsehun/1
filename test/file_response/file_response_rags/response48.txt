{
    "query": "如何通过运维平台查看用户作业的报错原因？",
    "summaries": [
        "本文档为支持专员提供常见操作指南，包括查看用户计算资源和磁盘配额、提高作业优先级、延长作业时限以及查看用户作业报错原因。用户可通过运维平台进行相关操作，如“资源操作”查看账户及用户资源信息，或通过“查看用户配额”了解存储使用情况。提高作业优先级和延长作业时限需经审批，而查看作业日志可用于分析作业中断原因。",
        "系统出现多个故障，包括TH-3F的握手次数变化、TH-HPC的raid1和raid2超时故障。集群总览页面整合了节点、作业和存储信息。运维平台用于处理故障，值班人员可通过登录平台查看报警信息并执行操作。Lustre存储故障处理包括挂起作业、查询日志、重启节点等步骤。",
        "系统出现进程引擎故障，作业被信号9终止。MPI版本问题可能导致错误，建议替换.bashrc中的编译器和MPI路径。作业运行中可能因系统维护被挂起，需手动终止并续算。程序因编译与运行环境不一致导致AVX支持错误，应移除-xHOST/-xAVX选项。存储配额默认为500G软限制、1T硬限制，超限将无法写入。IO错误可能由存储压力或OST满载引起。ls命令卡顿可能因节点负载高、网络延迟或存储恢复。GPU无法识别可能因PCIe连接松动。"
    ],
    "contents": [
        "@mno ~]#\n六、支持专员常见问题\n6.1 查看用户计算资源\n连接对应集群，点击“资源操作”，进入“查看用户资源”，如下图：\n统一监控运维平台= 运维管理\n\n定制大屏机房运维总览剧本执行\n\nTH-HPC\n\nTH-HPC4PDTH-HPC\n日 ®\n\n© 存储分区操作\n\n© 资源操作修改用户组配额\n剧本执行Onset | ©\n© 作业操作\n© 服务操作\n© 数据拷贝\n\n用户登录解锁\n\n执行审计\n\n修改用户配额\n\n用户锁定查询\n\n查询账户资源\n\n查询用户组配额\n查询用户资源 X\n\n天对执行\n命令输出:\n\nPLAY [121 .16 。 225 .1] 2800 bb OBOE BASSO IDOI IA II IIIa Ia I IA Ia Ia a aa Aa I TR\n\nchanged: [121.16.225.1]\n\nok: [121.16.225.1] => {\n“msg”: [\n\"Cluster | Account |User | Partition | Share| GrpJobs | GrpTRES | GrpSubmit | GrpWal1|GrpTRESMins |MaxJobs |MaxTRES |Max\n\"tianhe| sunfx| sunfx|th_hpc1|1|30|cpu=512,node=16|30|||| ||| | [normal] ||\"\n查询账户资源会显示这个组的所有资源，查询用户资源只显示组内这个用户的资源。\n查询结果如下图所示：\no Cluster [AccountUser Partition]Share|GrpJobs GrpNodes _Grpcpus| Grpitem|arpSubmit | — ¢\n\ntianhekanbukanbw th sr1383826020\ntianhekanbwkanbwdebug13822420\n\ntianhekanbwkanbw 。 gpu_test13856\n查询结果的主要字段含义如下：\n字段名 | 含义\nAccount | 账号名\nUser | 用户名\nPartition | 队列名\nGrpJobs | 可运行作业数\nGrpNodes | 可用节点数\nGrpCPUs | 可用核数\nGrpSubmit | 可提交作业数\n6.2 查看用户磁盘配额\n连接对应集群，点击“资源操作”，进入“查看用户配额”，",
        "TH-3F: mn26 : S07C11PU06,，\n\n握手次数发生变化\n\nTH-HPC: ost64 : raid1出现\ntimeout故障\n\n” TH-HPC: ost64 : raid2出现\n\ntimeout故障\n（2）集群总览\nHPC、HPC4、1903都有自己的集群总览页面，将节点情况、作业情况、存储情况集中展示，以TH-HPC4总览页面为例，可以看出其实就是把原来分散的节点、作业、存储使用率监控数据整合到一个页面展示。\n© 2024年05月29日15.35 。 用户名-fengqiang 退出 |\n\nTH-HPCAEIE |\n\nnnil wasecere |)TeI] reuse7\n\neRss© pending 9 ne\n=omm\n\n服务节点o55%所 ee\n2Bs2s加\n\noR加15416127703(T)\n77\n\nseat=pn\n».6 6eo 0 0*\n\nJIL| |__ eee II\nost i7\n\nTT\n三 系统故障处理\n一线值班员通过运维平台处理系统故障，下面介绍运维平台的登录、使用方法。\n3.1 运维平台登录\n每个值班人员都有自己的运维平台账号，值班室调试机的chrome浏览器上有登录运维平台的书签，值班人员点击书签，输入用户名和密码，再点击登录，可登录到运维平台。\n© 新标签页x 十\n\n& > GC Q 在Google中拓索，或者输入一个网址\n\nB ses SO NSCCRERE @ SEEEXHET © EesueTe B 2ARER\n图3-1 浏览器书签\n一一\n\n河统一监控运维平台\n\n一一\n\n用户登录\n图3-2 登录页面\n3.2 功能概述\n登陆运维平台后，选择左侧边栏的 “运维总览”页面，该页面显示当前的系统报警情况，这样值班人员就可以直接在运维平台上获取需要处理的报警信息，不需要去显示系统报警的监控大屏去获取报警信息。\n右上角点击账号--个人信息，可以更改密码。\n统一监控运维平台iQxX * 2 ee\n\nOo RL报警开关\n04\n剧本编排\n剧本执行\n集群故障点故障级别发生时间状态操作\nTH-3F7. =e 警告2024-05-",
        "| 文件数硬限制\ngrace | 文件数配额状态\n6.3 提高作业优先级\n作业提高优先级是指将某个排队优先级较低的用户作业提高作业优先级，使得该作业可以尽快运算。该功能针对一些需要尽快得到作业运行结果的用户，经高性能计算部部长许可后，可对指定的作业进行提高优先级操作。操作流程如下：\n统一监控运维平台= 运维管理、\n\n定制大屏机房运维总览剧本执行\n\nTH-HPC\n其他操作 节点操作\n\n TH-HPC4PDTH-HPC\na\n\n 口 存储分区操作|\n\n2 BRE取消作业\n\n局 用户操作\n\n修改作业时限\n\n号 服务操作\nO 数据拷贝\n\n查询作业日志\n\n恢复作业\n\n查询作业信息\n\n挂起作业\n\nAGERE\n您确定要执行作业提权操作吗?\n\n* 作业bid\n请输入作ybid\n* 权重”最大\n6.4 延长作业时限\n作业可运行的时间受用户可用计算分区的限制，不同的计算分区有着不同的运行时间限制，一旦用户在该计算分区单次运行作业的时间达到该分区设置的运行时间限制，则slurm会把该作业终断。该操作可将指定作业号的作业设置为无运行时间限制，该操作经过高性能计算部部长同意后才能执行。\n统一监控运维平台= 运维管理\n\n定制大屏机房运维总览剧本执行\n\nTH-HPC\n其他操作 节点操作\n\nTH-HPC4PDTH-HPC\n\n5 SR]\n\n2 存储分区操作|\n口 ZR取消作业aiowet\n2 用户操作\n器 服务操作\n\n延长作业时限\n\n查询作业信息\n\n挂起作业\n\n作册提权\n您确定要执行修改作业时限操作吗?\n\n*作yid\n\n请输入作yid\n\n* 时限\n6.5 查看用户作业报错原因\n支持专员询问某个作业的中断原因，一线值班员通过运维平台的“其他操作-查看用户作业”功能对用户作业中断前的节点日志信息进行查看，具体操作步骤如下：\n统一监控运维平台= 运维管理\n\n定制大屏机房运维总览剧本执行\n\nTH-HPC4PDTH-HPC\n日 ce TH-HPC\n© 存储分区操作|\n©",
        "数\nGrpNodes | 可用节点数\nGrpCPUs | 可用核数\nGrpSubmit | 可提交作业数\n6.2 查看用户磁盘配额\n连接对应集群，点击“资源操作”，进入“查看用户配额”，如下图：\n统一监控运维平台\n\n= 运维管理 、\n\n定制大屏机房运维总览剧本执行\n\n其他操作 节点操作\n\n TH-HPC4\n\n日 ee TH-HPC\n OD 存储分区操作\n2 ee\n\n© 作业操作\n号 服务操作\n© 数据拷贝\n\nTH-HPC\n\n全 TH-HPC\n\n修改用户组配额修改用户配额\n\n用户登录解锁用户锁定查询\n\n查询账户资源\n\n查询用户资源\n您确定要执行查询用户配额操作吗?\n\n+用户名|\nER\n\n+存储人区 |\nSRR\n\n取消确认\n查询用户组配额会显示这个组的所有资源，查询用户资源只显示组内这个用户的资源。\n以查询用户组配额为例，查询结果如下图所示：\n查询用户组配额 X\n\n天对执行\n\n命令输出:\n\nPLAY 【21 .16 .21 。1] 82000000020 Ia Ia Ia IIa Ia I TT IA I I\n\nchanged: [121.16.21.1]\n\nok: [121.16.21.1] => {\n“msg”: [\n\nmsg\n“Disk quotas for grp sunfx (gid 5000):\n\nFilesystem used quota limit grace files quota limit grace\",\n/THL6 = 239.7G600G1T一71948 1700000 2666666-\"\n查询结果的主要字段含义如下：\n字段名 | 含义\nFilesystem | 用户所在存储分区\nkbytes | 已用存储\nquota | 磁盘软限制\nlimit | 磁盘硬限制\ngrace | 磁盘存储配额状态\nfiles | 已用文件数\nquota | 文件数软限制\nlimit | 文件数硬限制\ngrace | 文件数配额状态\n6.3 提高作业优先级\n作业提高优先级是指将某个排队优先级较低的用户作业提高作业优先级，使得该作业可以尽快运算。该功能针对一些",
        "stack:\nMPIDI_CH3I_Progress(176): progress engine failure)\nslurmd[cn1368]: *** STEP 2796179.0 KILLED AT 2015-10-12T11:27:12 WITH SIGNAL 9 ***\nslurmd[cn1368]: *** STEP 2796179.0 KILLED AT 2015-10-12T11:27:12 WITH SIGNAL 9 ***\nA：该错误提示一般是由mpi版本导致。解决方法：使用/vol6/source.sh中的内容替换原~/.bashrc中关于intel编译器、mpi的路径。\nQ:任务提交运行后，有时在还未达到队列的时间天数期限时，运行的程序已“停止工作”（输出文件没有更新），但是通过作业查询命令（yhq）查看，作业看起还在R运行。\nA:遇到这个情况，请您及时手动杀掉您的作业，从断掉的地方接着续算就可以了。\nQ:输出的slurm文件中是如下数据：yhrun: got SIGCONT。我在天河服务器用户手册上没找到这条数据的解释。请问这条数据代表什么意思?\nA:这个是系统管理员临时维护系统，为了避免影响用户的作业，而把用户的作业挂起了出现的提示了。\nQ程序运行报错：Fatal Error: This program was not built to run in your system. Please verify that both the operating system and the processor support Intel(R) AVX. yhrun: error: cn2375: task 0: Exited with exit code 1\nA：该错误说明程序的编译时环境和运行时环境不一致，即程序编译时使用了支持AVX的选项，运行时的硬件环境不支持该AVX优化。\n一般这种情况发生是由于用户在编译程序时加入-xHOST/-xAVX选项（或是在安装软件时，系统自动读取到登陆节点上CPU的flag支持avx，故在编译软件时加入了-xHOST），那程序就会根据登陆节点的CPU配置信息进行优化编译，然而程序的运行是在计算节点上，计算节点的CPU配置信息可能不支持AVX，就与登陆节点不同，就会报",
        "统一监控运维平台iQxX * 2 ee\n\nOo RL报警开关\n04\n剧本编排\n剧本执行\n集群故障点故障级别发生时间状态操作\nTH-3F7. =e 警告2024-05-16T15:33:05未处理\nTH-HPC44e 警告2024-05-16T15:05:41未处理\nTH-3Feeee 通知2024-04-10T16:23:35未处理\nTH-3Mi7e 通知2024-04-04T08:22:06未处理\n\n共4条数据10条[页\n点击左侧边栏的“剧本执行”，可以切换到运维操作页面，点击TH-HPC、TH-3F等可以连接对应的集群，超过5分钟没有操作，将断开连接集群。\n运维操作的主要功能如下图所示：\n统一监控运维平台= 运维管理、\n\n定制大屏Bas 运维总揪\n\n其他操作 节点操作\n\nTH-HPC4\n\nTH-3F\nBIASTH-3M.\n\nTH-3K\n\n操作提示: 点击左侧树中集群名以连接集群 ~ 点击操作类型 ~ 点击操作按钮 ~ 填入参数，执行操作\n\n查看\n文档\n存情节点，怠 。重户、关机、开机、重启pdp、查看负载、查看日志.\n| ESR oO BEE, 查看dmesg、查看lustre active情况、关机、开机\n\n重启ntp\n本\n重启mysql\n\n| BRR © BSRR SHEARER HERRRACAE SRTBE SMa Bie.\n注意：运维操作页面内，在不同集群之间切换，标签保留。如果运维操作切换到运维总览或监控页面，运维操作内的标签全部会关掉。\n3.3 Lustre存储故障\n3.3.1 mds/ost报宕机或报unhealthy\n（1）挂起对应分区作业，并在微信群通知业务部门。\n查询报警的mds/ost属于哪个分区，参照下表：\nmds节点 | ost节点 | 存储分区 | 所属集群\nmds0 | ost0-7,ost40-47 | THL5 | HPC-ES\nmds1 | ost8-39 | THL6 | HPC1\nmds2 | ost48-79 | THL7 | HPC2\nmds3 | ost80-111 | THL8 |",
        "HPC-ES\nmds1 | ost8-39 | THL6 | HPC1\nmds2 | ost48-79 | THL7 | HPC2\nmds3 | ost80-111 | THL8 | HPC3\nmds4 | ost112-143 | fs1 | HPC4\n例如mds1宕机，即需要挂起THL6的分区作业，如下图所示。\n统一监控运维平台= 运维管理、\n\n定制大屏剧本执行\n\nTH-HPC\n其他操作 节点操作\n\n TH-HPCA© TH-HPC > THL6\n© TH-HPC\n日 中 存储分区操作\ngris 2EL分区作业恢复\n\nQTH7\nOTH\nO AiReE\nO 用户操作\n© 作灿操作\n\n四 肥各二人矿\n如下图查看日志，如果有-30或scsi cmnd错误，联系二线值班人员处理；如果没有报-30或scsi cmnd错误，进行下一步。\n统一监控运维平台= 运维管理、\n\n定制大屏剧本执行\n\nTH-HPCTH-HPC4\n\n其他操作\n\nof 节点编号: mds1\n\n日 ce TH-HPC\n序号: 2488\n©) HPC1-127\n日 storage节点名称: mds1\n TH-3F\n\n查询内存\n\n清除进程标记硬盘\n\n所属集群 TH-HPC\n所属分区:_null\n\n存储位置: 老机房-TH-HPC-HPC1-\n127-21.0\n\n查询硬盘信息Airaid (SB\n\ncpu进程排序mem进程排序\n\n硬盘大小. 无硬盘\n节点状态: 连接成功 |\n\n查询rsf信息\n\nBRE\n重启mds。选择“其他操作”—对应集群—“其他操作”—“电源管理”。\n输入“节点名”和“动作（重启）”后确认。\nTH-HPC TH-HPC4\n节点操作\n\nTH-HPC4PDTH-HPC\n\nafer]\n\n剧本编排BO 存储分区操作\n\nOTHLS登陆节点部署客户端-， MDS节点部署客户.， OSTHRBBEP...计算节点部署客户端.， 远程在线用户\n剧本执行四THL6\n二emsiveenee wm—\n© 资源操作\n\n0 用户操作\n\n© 作业操作mds1:查询日志 久",
        "“lfs quota –g username /vol-th”查看账号配额会看到已使用存储的数字旁边有一个“*”号，状态“4w1d23h59m57s”表示一个月的倒计时，如果用户在倒计时结束前将使用存储清理到500G以下，则存储状态恢复正常，否则，用户存储无法写入；如果用户使用存储大于1T，用户会无法写入。\nQ：磁盘无法写入，报“quota error”错误\nA：这是由于用户使用存储或文件数超过配额设定，需要用户对数据进行清理到磁盘配额软限制以下方可继续使用。\nQ：作业运行提示“forrtl: Input/output error”\nA：可能是存储某一时刻压力较大，造成IO错误，请您重新提交作业。\nQ：作业运行时报错：forrtl: No space left on device，forrtl: severe (38): error during write, unit 12，但是同样的作业再次提交时可能就正常运行完成。\nA：该问题主要由文件系统中某一OST存储已满导致，请联系与您对接的工程师或系统管理员。\nLustre文件系统由若干IO服务器（Object Storage Services）和Object Storage Targets(OST)组成。当对一个文件进行读写操作时，为了提高IO效率，文件系统会自动将该文件的读写操作分割成多个，在多个OST上并发实现。如果在该过程中，使用到的某一OST出现问题，就会发生读写错误。\nQ:我使用ls命令查看目录下的文件，可是一直停留下那里，没有显示。\nA:遇到这个问题，您可以等待一会，再重新使用ls命令查看目录文件。\n原因之一可能是TH-HPC的登录节点负载比较重，造成使用终端命令受到影响；原因之二可能是用户客户端的网络负载比较重，出现比较严重的网络延迟；原因之三可能是TH-HPC系统的存储正在进行恢复调整。\n6.6 GPU使用问题\nQ：使用CUDA toolkit编译程序后，在gpu_test分区提交作业，运行时提示错误：no CUDA-capable device is detected\nA：可能原因有二种情况：\n原因之一可能是分配到的该计算结点上用于连接CPU与GPU的PCIe总线松动，导致无法找到device。解决方法：在提交作业时",
        "时加入了-xHOST），那程序就会根据登陆节点的CPU配置信息进行优化编译，然而程序的运行是在计算节点上，计算节点的CPU配置信息可能不支持AVX，就与登陆节点不同，就会报上面的提示错误。\n解决方法：编译时去掉-xHOST/-xAVX选项，使用其他优化选项。\n备注：-xHost will cause icc/icpc or icl to check the cpu information and find the highest level of extended instructions support to use.\n天河登陆节点ln1、ln2、ln3上的CPU配置信息flag均无avx，ln8、ln9上均有avx。\n如果在ln8或ln9上安装软件时，configure后一定要检查下编译flag是否加入了-xHOST，如果加入，请修改对应的configure文件，将-xHOST删除\n6.5 存储问题\nQ：登陆系统时提示“Some errors happened when getting quota info”\nA：这是由于在对系统进行调整时登陆结点quota服务没有启用导致，对用户本身的操作和作业不会有影响，管理员会定时对此进行调整，请放心使用。\n解决方法：这是因为登陆节点quota服务没有启用，对用户本身的操作和作业不会有影响。\n值班人员每天定时对vol-th、WORK、vol6的quota进行检查，尤其是存储出现问题后（如ost重启），quota会异常关闭，以vol-th为例重启方式如下：\nlfsquotaoff -ug /vol-th\nlfsquotaon -ug /vol-th\nQ：默认的磁盘配额是多少？磁盘配额的含义是什么？\nA：为了合理利用有限的存储资源，目前中心对用户默认进行存储软限制500G，存储硬限制1T，文件数软限制100万，文件数硬限制200万的磁盘配额限制。以磁盘存储为例说明软、硬限制的含义，文件数软、硬限制的含义与其一样。用户使用存储低于500G时，存储状态正常；当用户使用存储介于500G和1T之间时，用户配额异常，通过“lfs quota –g username /vol-th”查看账号配额会看到已使用存储的数字旁边有一个“*”号，状态“4w1d23h59m57s”表示一个月的倒计时，如果用户在倒计时结束前将使用"
    ]
}