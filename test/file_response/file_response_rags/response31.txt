{
    "query": "提交作业时，如何确保只分配具有 “gpu” 特性的节点？",
    "summaries": [
        "本文介绍了在使用HPC集群进行多GPU训练时的作业提交配置和节点资源占用情况。主要包含以下内容：1. 提交作业需设置-N或-n参数，否则会报错；2. 节点被独占的三种情况：8卡64核全用完、8卡未用完但64核用完、8卡用完但64核未用完，其中第二种情况会导致显卡浪费；3. 可通过指定设备号（如CUDA_VISIBLE_DEVICES）来控制使用的GPU。",
        "HPC4 gpu分区支持单节点双卡和八卡配置，建议一个节点提交两个作业以避免资源浪费。未指定设备号时，可通过CUDA_VISIBLE_DEVICES设置GPU编号；程序中指定设备号时，无需额外设置。PyTorch和TensorFlow的设备指定方法可参考相关链接。",
        "本文介绍了通过 `yhrun jobid=<job_id> nvidia-smi` 命令查询 GPU 利用率的方法，适用于 k80 集群。测试显示，VASP 可成功查询 GPU 使用情况，而 LAMMPS、Python、GROMACS 等软件无法查询，可能与作业调度系统有关。同时，查询过程中出现“Requested nodes are busy”提示，表明节点可能处于忙碌状态。"
    ],
    "contents": [
        "【已解决】HPC4 gpu分区单节点提交两个作业\n**标签**: gpu\n**创建时间**: 2022-06-30 15:22:52\n**更新时间**: 2022-06-30 15:22:52\n**作者**: 杜思慧\n**1.背景**\n目前hpc4上的gpu分区配置为单节点双卡，gpu1分区为单节点八卡，可mix使用；\n在gpu分区为避免浪费，建议一个节点提交两个作业\n**2.脚本**\n未在程序中指定设备号时：\n#!/bin/bash\nmodule add pytorch/1.11.0-cu11.3-py3.9\nmodule add loginnode/ln0\nCUDA_VISIBLE_DEVICES=0 python 3d.py &\nCUDA_VISIBLE_DEVICES=1 python 3d-1.py &\nwait\n在程序中指定设备号时：\n#!/bin/bash\nmodule add pytorch/1.11.0-cu11.3-py3.9\nmodule add loginnode/ln0\npython 3d.py &\npython 3d-1.py &\nwait\n**3.备注**\n程序中指定设备号的方法：\nPytorch: https://www.cnblogs.com/darkknightzh/p/6836568.html\nTensorflow: https://blog.csdn.net/weixin_31866177/article/details/89403727",
        "up infinite      1 idle gsn1\n[dush@th-hpc4-ln1 unet-no-chu-size]$ yhq\nJOBID PARTITION     NAME     USER ST       TIME NODES NODELIST(REASON\n560426      gpul test,sh  dush R       0:05      1 gsng\n了\na meh hea 7.\n该节点64个核全部用完后，再提交作业到该节点会进入排队状态无法计算\n[dush@th-hpc4-1n1 unet-no-chu-size]$ yhq\nJOBID PARTITION    NAME    USER ST      TIME NODES NODELIST(REASON)\n560603     gpul    n.sh    dush PD      0:00     1 (Resources)\n560602   gpul test.sh § dush R   0:31   1 gsne\n第二种情况会造成显卡的浪费，要尽量避免\n（3）8个卡被用完但是64个核未被全部用完：gpus-per-node=8，cpus-per-gpu=4\n脚本：\n#!/bin/bash\n#SBATCH gpus-per-node=8\n#SBATCH cpus-per-gpu=4\nyhrun torchrun nproc_per_node=8 train_multi_GPU.py\ngpul         up infinite      1 mix gsno\ngpul         up infinite      1 idle gsn1\n[dush@th-hpc4-ln1 unet-no-chu-sizel$ yhq\nJOBID PARTITION    NAME    USER ST      TIME NODES NODELIST(REASON)\n560480      gpul test.sh © dush R       0:07      1 gsng\n8个卡被用完时",
        "【测试中】利用yhrun查询gpu利用率\n**标签**: 无标签\n**创建时间**: 2023-11-16 11:13:20\n**更新时间**: 2023-11-17 11:13:39\n**作者**: 杜思慧\n**1. 查询语句**\n#该方法也适用于k80集群\nyhrun jobid=<job_id> nvidia-smi\n2.测试情况\n单卡查询：\n目前仅vasp可同通过该方法查询，其他软件无法查询疑似和作业调度系统有关\nvasp\n[dush2Gth-hpc4-Lng ~]$ yhq\nJOBID PARTITION     NAME     USER ST       TIME NODES NODELIST(REASON)\n1443650       gpu   sub.sh    dush2 R       2:06      1 gn36\n[dush2@th-hpc4-1tn0 ~]$ yhrun jobid=1443650 nvidia-smi\nThu Nov 16 11:12:51 2023\n+十\n| NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5\n|  2-2 rere rere rere re eee ee++十\n| GPU Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC\n| Fan Temp Perf Pwr:Usage/Cap|         Memory-Usage | GPU-Util Compute M.\n|                        |                MIG M. |\n一一=一一一一一一一一一一=一一一一一一一一一一一一一一一一一二一一一一一一一一一一一一一一=一一=一一=一+一|\n|   9 NVIDIA A100 80G... Off | 00000000:4B:00.0 Off",
        "-per-task=1\n#SBATCH cpus-per-gpu=8\nyhrun python train.py\n注：使用时需设置-N 或 -n，不设置会无法提交作业，报以下错误：\nyhbatch: error: Batch job submission failed: Invalid generic resource (gres) specification\n**3. 节点被独占的几种情况**\n（1）8个卡和64个核被全部用完：gpus-per-node=8，cpus-per-gpu=8\n脚本：\n#!/bin/bash\n#SBATCH gpus-per-node=8\n#SBATCH cpus-per-gpu=8\nyhrun torchrun nproc_per_node=8 train_multi_GPU.py\ngpul         up infinite      1 alloc gsno\ngpul         up infinite      1 idle gsn1\n[dush@th-hpc4-ln1 unet-no-chu-sizel$ yhq\nJOBID PARTITION    NAME    USER ST      TIME NODES NODELIST(REASON)\n560360      gpul test.sh  dush R\n1      1 gsng\n（2）8个卡未被用完但是64个核全部用完：gpus-per-node=4，cpus-per-gpu=16\n脚本：\n#!/bin/bash\n#SBATCH gpus-per-node=4\n#SBATCH cpus-per-gpu=16\nyhrun torchrun nproc_per_node=4 train_multi_GPU.py\nsey          SPF eames       oo sibewe.\ngpul         up infinite      1 alloc gsng\ngpul         up infinite      1 idle gsn1\n[dush@th-hpc4-ln1 unet-no-chu-size]$ yhq\nJOBID PARTITION     NAME",
        "NODELIST(REASON)\n560480      gpul test.sh © dush R       0:07      1 gsng\n8个卡被用完时，再提交作业会排队\ned         up infinite      1 mix gsn0\nup infinite      1 idle gsn1\nRousheth- hpc4-Lnl unet-no-chu-size]$ yhq\nJOBID PARTITION     NAME     USER ST       TIME NODES NODELIST(REASON\n560607      gpul     n.sh     dush PD       0:00      1 (Resources\n560605      gpul test.sh § dush R       0:56      1 gsne\n**4.指定设备号**\n（1）按顺序指定设备号（设备号指定方法以在程序中通过os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"指定为例）\n提交脚本\n#!/bin/bash\n#SBATCH partition=gpu1\n#SBATCH gpus-per-node=1\n#SBATCH cpus-per-gpu=8\nyhrun python train.py\n可交到显卡计算\n1                                 1                   Uivsapres |\n+\nul\n+.\n| 7 NVIDIA A100-SXM... Off | 09000000    0.0 Off |              9 1\n| MA 30C PO 62w/49ow |     9MiB / 81251MiB |     0%     Default |\n|",
        "一一一一一一一一一一一一一一一一一二一一一一一一一一一一一一一一=一一=一一=一+一|\n|   9 NVIDIA A100 80G... Off | 00000000:4B:00.0 Off |                    0\n| NMA 53C    PQ 300W / 300W | 37811MiB / 81070MiB |    100%      Default\n|                                 |                        |              Disabled |\nf4+4++\n+十\n| Processes:\nGPU   GI   cI        PID Type   Process name                  GPU Memory\nID ID                                                   Usage\nlammps。python，gromacs等均无法查询\n[dush2@th-hpc4-1n1 accelerate]$ yhq\nJOBID PARTITION     NAME     USER ST       TIME NODES NODELIST(REASON)\n1443675       gpu   sub.sh    dush2 R       0:15      1 gn36\n[dush2@th-hpc4-1n1 accelerate]$ yhrun jobid=1443675 nvidia-smi\nlyhrun: Job 1443675 step creation temporarily disabled, retrying (Requested nodes are busy)"
    ]
}