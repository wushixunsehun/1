{
    "query": "如何通过参数配置 Lustre 文件系统的 OST 服务网络请求调度策略（NRS）以优化批量读写性能？请结合策略类型及参数含义说明。",
    "summaries": [
        "本文档介绍了Lustre文件系统中NRS（Network Resource Scheduler）的TBF（Token Bucket Filter）规则配置、实时策略和延迟策略。TBF用于控制IO请求的速率，支持添加实时特性以确保高优先级请求的带宽分配。延迟策略通过模拟高负载来测试系统对时间敏感问题的处理能力，允许设置请求延迟的最小和最大时间范围。这些功能可通过lctl命令进行配置和调整。",
        "本文档介绍了Lustre文件系统中几种RPC调度策略的配置和使用方法。ORR策略用于设置支持的RPC类型，如reads、writes或reads_and_writes。TRR策略基于目标OST索引进行批量循环调度，其参数与ORR类似。TBF策略通过限制RPC速率来保证服务质量，可根据NID、JobID、OPCode、UID/GID等分类，并通过规则列表动态调整速率限制。",
        "Lustre 文件系统通过将文件分条到多个 OST 上，以提高峰值聚合带宽和性能。适用于大文件或高并发访问场景，最多支持 2000 个 OST。条带化可提升 IO 性能，但会增加开销和风险。选择合适的条带大小（如 1MB-4MB）有助于优化性能，避免锁定争用。使用 `lfs setstripe` 命令配置文件布局，设置条带数量、大小和起始 OST，以实现负载均衡和空间利用。"
    ],
    "contents": [
        "相同速率限制的类获得的带宽要比预先均衡配置所获得得带宽要少。造成这种情况的原因是拥塞服务釉上的索重负载会导致某些类错过最后期限。在出列时，令牌的数量可能于 1。在最初的实现中，所有类都被平等对待，以罗松寺弃超额的令牌。随痢硬令牌补偿〈HTC) 策略的实施，我们使用 HTC 匹配的规则对类进行配置。个特性意味痢该类队列中的请求具有较高的实时性要求，必须尽可能满足市宽分配。错过最后期限时，该类保持最后期限不变，剩余的时间 〈剩余的流逝时间除以 1 将被补偿到下一轮。从而确保了下一个空闲 IO 线程始终选择此类来服务，直到所有累计的超额令牌处理完毕或该类队列中没有挂起的请求。命令:添加实时特性的新命令格式:lctl set param x.x.x.nrs tbf rule=\\\"start rule name arguments... realtime=1示例:$ lctl set_param ost.OSS.ost_io.nrs tbf rule\"start realjob jobid-{dd.0} rate=100 realtime=1在这个例子中，那些JopID 为 dd.0 的 RPC 将以 100 req/sec 的速率进行实时处理。(在Lustre 2.10 中引入)34.6.6. 延迟策略NRS 延迟策略旨在通过于扰 PtlRPC 层的请求处理时间来模拟高服务器负载，从而暴露与时间有关的问题。如果局用此策略，将在请求到达时计算应该开始处理请求的时间位移量，并人允许其在用户定义的范围内波动。然后使用cfs_binheap将请求按照分配的开始时间进行排序，并保存。一旦请求的开始时间已过，它将从 binheap 中移除以供处理。412\nLustre 文件系统操作手册 译者:这aX延迟策略可在所有类型的 PHURPC 服务上局用，有以下可用于调整其行为的可调参数:* {service}.nrs delay min{service}.nrs_delay_min 用于控制请求被此策略延迟的最短时间量 CLARA单位) 。默认值是 5 秒。读取此值运行:1 lcetl get Param {",
        "ost_10.nrs orr supportec=reg_ supported: readshp_supported=reads_ and writesERAN, SEAT LG EEL ( reg_dquantum) 和高优先级 (hp_quantum) RPCs 有不同的支持的RPC 类型。为 ORR 策略设置文持的RPC 类型，运行:$ lctl Set Param ost.OSS.ost_io.nrs orr Supported=reads|writes|reads_and writes这将设置 ORR 策略文持的项规和高优先级 RPC 类型为指定值。EXE AT GSTS LA Pa A A tes CIC RPC 指定不同的文持类型 :$ lctl set param ost.OSS.ost_io.nrs orr supported=reg _supported|hp supported:reads|writes|reads_and writesBON, AR SUBACK RPC 文持类型设置为批量读和批量写:403\n123Lustre 文件系统操作手册这ay$ lctl set_paramost.OSS.ost_1o.nrs orr supported=reg_supported:reads and writesost.OSS.ost_1o.nrs orr supported=reg_supported:reads and writesHU Ea TIA, ET EEA a OS i A a CZK RPC 的文持类型设置为不同的值。34.6.4. 基于目标的循环 (TRR) 策略基于目标的循环 (TRR) 策略对 brw RPC 执行批量循环调度，每个批次由属于相同OST 的RPC《〈由QOST索引标识) 构成。除了使用 brw RPC 的目标 OST 索引而不是后端 fs 对象的 OST FID 来确定 RPC 调度顺序以外，TRR 策略与基于对象的循环 CORR) 策略相同。TRR 策略和 ORR 策略的实施效果相同，它使用以下可调参数来调整其行为:。 ost.OSS.ost io.nrs trr quantum与 ORR 策略中的 ost.OSS.ost_io.nrs orr quantum 参数的目标和用法完全相同。* ost.OSS.ost io.nrs trr offset type与 ORR 策略",
        "釉上的人磁盘都可以管理线性的 IO，则不存在莞委。如宋每个文件都有 100 个对象 ，那么客户冰就会彼此竞争以获得服务硕的注意，并且每个节反上的磁盘将在 100 个不同的方向上寻找，导致不必要的竞争。“增加风险。 当文件在所有服务咒上进行条融化，而其中一人台服务吉出现故障，这坚文件的一小部分将丢失。相反，如采每个文件只有一个条带，丢失的文件会更少，但它们将宛全丢失。许多用户更能接受丢失部分文件《即使是全部内容)，而不是所有文件都丢失部分内容。19.2.1. 选择条带大小选择条带大小是一种权衡行为。下面将介绍较为合理的默认值。条齐大小对于单条审文件疫有影响。“ 条带大小必须是页大小的整数倍。Lustre 软件工具将强制执行 64KB 的整数倍(ia64 和 PPC64 区点的最大页大小) ，避免页规格较小的平台上的用尸创建可能会导致 ia64 客户端出现问题的文件。194\nLustre 文件系统操作手册 译者: 李硕。 推荐的最小条带大小是 S12KB。 虽然可以创建条带大小为 64KB 的文件，但最小的实际条带大小为 S12KB ，因为 Lustre 文件系统通过网络发送数据块大小为 1MB。选择更小的条带大小可能会导致磁盘 IO 效率低下，人性能下降。。适用于高速网络线性 VO 的条带大小在 1MB 到 4MB 之间。在大多数情况下，大于4MB 的条带大小可能导致更长的锁定保持时间，增加共享文件访问期间的争用情况。。最大条带大小为 4GB。 在访问非常大的文件时，使用较大的条带大小可以提高性能。它允许每个客户端独占访问文件的一部分。但如果条带大小与 IO 模式不匹配，较大的条带大小可能会适得其反。。 选择一个考虑到应用程序的写入模式的条带化模式。 跨越对象边界的写入效率要比在单个服务器上完整写入的效率略低。如果文件以一致旦对齐的方式写入，请将条带大小设置为 wzite () 大小的整数倍。19.3. 配置 Lustre 文件布局 〈条带化模式) (LEfEs setstripe)使用 Ifs",
        "文件以一致旦对齐的方式写入，请将条带大小设置为 wzite () 大小的整数倍。19.3. 配置 Lustre 文件布局 〈条带化模式) (LEfEs setstripe)使用 Ifs setstripe 命令创建指定文件布局〈条市化模式) 配置的新文件。1 lfs setstripe [--size|-s stripe size] [--stripe-count|-c stripe count][--overstripe-count|-C stripe count] \\2 [--index|-i start_ost] [--pool|-p pool name] filename|dirnamestripe_sizestripe size 表示移动到下一个 OST Ail] BLA OST APY BH ato BRUstripe _ size是1MB。将该参数设置为0, MITER AY). stripe_size值必须是 64 KB 的整数倍。stripe count (--stripe-count, --overstripe-count)stripe_count 表示要使用OST 的数量。默认值为 1。将其设置为0，则会使用该PRU Ai BUCH. f stripe_count 设置为-1 意味着对所有可用的 OST 进行分条。当使用 --overstripe-count时，必要时应在每个OST 上使用。start_oststart ost 是文件写入的第一个OST。start_ost 的默认值是-1，它允许 MDS选择起始索引。强烈建议使用此默认设置，因为它可根据需要通过 MDS 完成空间和负载均衡。如果将 start_ost 的值设置为非 -1，则该文件将从指定的 OST 索引开始。OST 索引编号从 0 开始。注意WR Ta REA OST 处于非活动状态或处于降级模式，则 MDS 将目动选择另一个目标。195\n———Lustre 文件系统操作手册 译者:As大如果 start ost {HW0, stripe count 值为1，则所有文件都将写入OST0, 直到空间耗尽。这很可能不是你想要的。如果您只希望调整 stripe count ，而保持其他参数为默认设置，请不要指定任何其他参数:client# lfs setstripe -c stripe",
        "delay min{service}.nrs_delay_min 用于控制请求被此策略延迟的最短时间量 CLARA单位) 。默认值是 5 秒。读取此值运行:1 lcetl get Param {service}.nrs delay min例如，在 ost io 服务上读取最小延迟设置 :1 $ lct]l get Param ost.OSS.ost_io.nrs delay min2 ost.OSS.ost_io.nrs delay min=reg delay min:53 hp delay min:5设置 RPC 处理的最小延玉 :1 lctl set param {service}.nrs delay min=0-65535RORY tis DLA ie (EIEAR RPC 设置给定服务的最小延迟时间。例如，要将 ost_io 服务的最小延迟时间设置为 10，请运行:1 $ Ictl set Param ost.OSS.ost_io.nrs delay mir=102 ost.OSS.ost_io.nrs delay min=-10对于文持高优先级RPC 的 PHURPC 服务，可为前规和高优先级RPC 设置不同的最小延迟时间 :1 ， Jctl set param {service}.nrs delay min=reg delay min|hp delay min:0-65535例如，在 ost_io 服务上将高优先级 RPC 的最小延迟时间设置为3:1 $ Ictl set Param ost.OSS.ost_io.nrs delay min=hp delay min:32 ost.OSS.ost_io.nrs delay min=hp delay min:3请注意，在任何情况下最小延玉时间都不能超过最大延玉时间。* {service}.nrs delay max{service} .nrs_delay_max 用于控制请求被此策略延迟的最长时间量〈以秒为单位) 。默认值是 300 秒。读取此值运行:1 lctl get param {service}.nrs delay max例如，在 ost io 服务上读取最大延迟设置 :413\nLustre 文件系统操作手册 译者:这ay1 $ lctl get param",
        "文件分割到尽可能多的 OSS 上，以达到该文件所需的峰值聚合带宽。请注意，只有当文件大小很大或文件一次被许多节点访问时，才建议使用大量OSS 进行分条。目前，Lustre 文件可以在多达 2000 个 OST 上进行条带化。193\nLustre 文件系统操作手册 译者:As大“ 超出 OSS 带宽时用于提升性能。 如果客户端总带宽超过服务器带宽，且应用程序数据读写速率足够快而能够充分利用额外的 OSS 人带宽，则跨越多个 OSS 将文件条融化可以提高性能。最大有效条带数的限制为: 客户端/作业的 IO 28 BR BESOSS 性能。(由 Luster2.13 引入) 匹配条带与 VO 模式。当多个市点同时对一个文件进行写入时，可能有一个以上的客户痛会写到一个条带上，这会导致锁交换的问题，即客户端XT BA ATTA CPP ET FF, BEM VO Bar NE. WER IO 可以进行条价对齐，使每个条带只被一个客户器访问，就可以避免这个问题。从 Lustre 2.13 开始谎加了“overstriping\" 功能，人允许每个 OST 有多个条帝。这对于线程数超过 OST 数的情况特别有帮助，使得在这种情况下也可以将条人带数与线程数匹配。“为大文件提供空间。当单个 OST 没有足够多的空闲空间来存放整个文件时，可将文件分条。减少或避免使用条带化的原因:。 增加开销。 在常规操作 (如 stat 和unlink ) 期间，条带化会导致更多的锁定和额外的网络操作。即使这些操作并行执行，一次网络操作所花的时间也少于 100次操作。同时，服务硕竞争情况也会随之增加。考虑一个拥有 100 “SF A 100 个 OSS的集群，每个 OSS 合一个 O0ST。如宋每个文件只有一个对象并且人负载均匀分布，每人台服务釉上的人磁盘都可以管理线性的 IO，则不存在莞委。如宋每个文件都有 100 个对象 ，那么客户冰就会彼此竞争以获得服务硕的注意，并且每个节反上的磁盘将在",
        ".ost_io.nrs tbf rule=\\\"start lozone_userl opcode={ost_read ost write} rate=200 rank=computes\"在这个例子中，规则\"iozone_userl\" 被添加至规则\"computes\" 之前，顺序如下 :$ lctl get_param ost.OSS.ost_io.nrs tbf ruleost.OSS.ost_io.nrs tbf rule=regular requests:CPT 0:userl jobid=-{iozone.500 dd.500} 100, ref 0iozone_userl opcode={ost_read ost write} 200, ref 0computes nid-{192.168.1.[2-128]@tcp} 500, ref 0default * 10000, ref 0CPT 1:userl jobid=-{iozone.500 dd.500} 100, ref 0iozone_userl opcode={ost_read ost write} 200, ref 0computes nid-{192.168.1.[2-128]@tcp} 500, ref 0default * 10000, ref 0high priority requests:CPT 0:userl jobid=-{iozone.500 dd.500} 100, ref 0iozone_userl opcode={ost_read ost write} 200, ref 0411\n1Oo192021222324—N—NLustre 文件系统操作手册 译者:这aycomputes nid-{192.168.1.[2-128]@tcp} 500, ref 0default * 10000, ref 0CPT 1:userl jobid=-{iozone.500 dd.500} 100, ref 0iozone_userl opcode={ost_read ost write} 200, ref 0computes nid-{192.168.1.[2-128]@tcp} 500, ref 0default * 10000, ref 0“拥塞下的TBF 实时策略在评估 TBF 期间，我们发现当所有类的 IO 市寓需求总和超过系统容量时，有具有相同速率限制的类获得的带宽要比预先均衡配置所获得得带宽要少。造成这种情况的原因是拥塞服务釉上的索重负载会导致某些类错过最后期限。在出列时，令牌的数量可能于 1。",
        "将第一个匹配的规则作为其规则，从而确定 RPC 令牌速率。规则可在运行时谎加到列表或从列表中删除。每当规则列表发生更改时，队列将更新其匹配的规则。@)>34.6.5.1. 启用 TBF 策略”命令:lctl Set Param ost.OSS.ost_io.nrs policies=\"tbf <policy>\"—Ha, RPC 可以根据其NID、JOBID、OPCode 或 UID/GID 来进行分类。启用 TBF策略时，您可以指定其中一种方式，或使用\"tbf\"' 允许所有方式并执行细粒度 RPC 请求分类。405\nLustre 文件系统操作手册 译者:这ay示例:1 $ lctl set Param ost.OSS.ost_io.nrs policies=\"tbf\"2 $ lctl Set param ost.OSS.ost_io.nrs policies=\"tbf nid\"3 $ lctl set param ost.OSS.ost_io.nrs policies=\"tbf jobid\"4 5 lctl set param ost.OSS.ost_io.nrs policies=\"tbf opcode\"5 $ lctl Set param ost.OSS.ost_io.nrs policies=\"tbf uid\"6 $ lctl set_ param ost.OSS.ost_io.nrs policies=\"tbf gid\"34.6.5.2. 局用 TBF 规则 «TBF 规则在ost.0SS.ost _ io.nrs thf rule参数中定义。命令:1 lctl Set Param x.x.x.nrs tbf rule=2 \"[reg|hp] start rule name arguments...\"SEP, 'rule_name' 为TBF WU, ‘arguments’ 为包含详细规则的字符串。以下是 TBF 策略的不同类型 :。基于 NID 的TBF 策略命令:1 lctl Set Param x.x.x.nrs tbf rule=2 \"[reg|hp] start rule name nid={nidlist} rate=rate\"'nidlist’ 的格式与配置LNET 路由相同。y7ate'",
        "ORR 策略中的 ost.OSS.ost_io.nrs orr quantum 参数的目标和用法完全相同。* ost.OSS.ost io.nrs trr offset type与 ORR 策略中的 ost.OSS.ost_io.nrs orr offset type 参数的目标和用法完全相同。。 ost.OSS.ost_ io.nrs trr supported与 ORR 策略中的 ost.OSS.ost_io.nrs orr supported 参数的目标和用法完全相同。(在 Lustre 2.6 中引入)34.6.5. 令牌桶过滤句 (TBF) 策略STARE ait (TBF) 策略通过强制限制客户端或作业的 RPC 速率而使 Lustre 服务达到一定的 QoS 〈服务质量)。404\nEnaueuebased onIDDequeuebased ondeadlines>@eeae 中国中中国回国加 56>].中国国国加 »6>»>@eaeae »§”Incoming 会 HandlingRPC ie RPC图 28: Internal stucture of TBF policyAl 32.1 TBF 策略的内部结构= RPC 请求到达时，TBEF 策略根据它的分类将它放到一个等竺队列中。根据 TBF配置，RPC 请求的分类可以基于了PC 的 NID BK JobID. TBF 策略在系统中需要维护多个队列，RPC 请求分类的每个类别有一个队列。这些请求在处理之前等竺FIFO 队列中的令牌，从而使 RPC 速率保持在限制乙下。Lustre 服务太忙无法及时处理所有请求时，所有队列的处理速率都不会达到指定值。但除了一些 RPC 速率比配置慢以外，并无任何坏处。在这种情况下，速率较高的队列比速率较低的队列具有优势。管理队列的 RPC 速率，我们不需要手动设置每个队列的速率，而是通过定义TBF策略匹配规则来确定 RPC 速率限制。所有定义的规则存储在有序列表中。每个新创建的队列将遍历规则列表并将第一个匹配的规则作为其规则，从而确定 RPC 令牌速率。规则可在运行时谎加到列表或从列表中删除。每当规则列表发生更改时，队列将更新其匹配的规则。@)>34.6."
    ]
}