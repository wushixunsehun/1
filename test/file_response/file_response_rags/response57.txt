{
    "query": "用户提交作业后出现“Lustre error”报错，可能的原因是什么？",
    "summaries": [
        "Lustre 文件系统可能出现多种错误，如“received cancel for unknown lock cookie”和“went back in time”，通常与网络配置或磁盘缓存问题有关。当磁盘缓存未正确提交数据时，可能导致数据丢失或恢复失败。故障切换时若共享存储不一致，也会引发错误。多客户端使用 O_APPEND 写入文件存在锁竞争和性能问题。启动时因读取元数据可能导致延迟，但随着缓存增加会改善。内存不足、SCSI 队列大小过小等也会影响性能。在备份 ldiskfs 文件系统时，日志功能可保持一致性，但硬件故障仍需运行 e2fsck 恢复。",
        "Lustre 文件系统中的授权缓存允许数据在超过 OST 配额时仍能成功写入，这可能导致配额限制失效。通过调整客户端参数可缓解此问题。Lustre 还提供配额统计信息，用于监控和分析配额操作性能。此外，Lustre 支持与分层存储管理 (HSM) 的集成，使文件可在高速缓存的 Lustre 文件系统和较慢的 HSM 存储之间同步。",
        "当Lustre文件系统出现空间不足问题时，可扩展OST磁盘空间或使用lfs_migrate迁移文件。若因打开的文件占用大量空间，可通过MDS获取打开文件句柄，并用lfs fid2path转换为路径。若文件已删除，可能返回错误，此时可通过NID定位节点并用lsof找到并终止相关进程。创建新文件时出现ENOSPC错误可能表示MDS inode资源耗尽，需扩展。可通过lfs df -i查看inode使用情况。此外，看门狗定时器触发可能表示操作超时，但通常为暂时性问题，也可能指示线程卡住。初始设置超时可能与名称解析有关，需检查/etc/hosts配置是否正确。"
    ],
    "contents": [
        ") 映射到本地主机 (127.0.0.1) 而不是正确的 IP 地址。这可能会产生这个错误:LustreError: (ldlm handle cancel()) received cancel for unknown lock cookieOxe74021a4b41b954e from nid Ox7f000001 (0:127.0.0.1)35.3.9. Ab#H\"LustreError: xxx went back in time\" 错误MDS 8k OSS 每次为客户机修改MDT 或 OST 磁盘文件系统的状态时，它都会为每个目标记录一个递增的操作交易编号，并将其与该操作的响应一起返回给客户机。当服务锅将这些事务提交到磁盘上时，会定期将 last_committed 事务编号返回给客户机，使其能够从内存中丢弃待处理的操作，因为在服务器故障时不再需要恢复这些操作。在某些情况下，在服务器被重启或故障后，会出现类似以下错误信息:LustreError: 3769:0: (amport.c:517:ptlrpc_ connect interpret () )testfs-ost12 UUID went back in time (transno 831 was previously committed,428\nLustre 文件系统操作手册 译者:这ay3 server now claims 791)!出现这种情况的原因是:\"您正在使用在数据写入实际执行前就声称有数据写入的人磁盘设备〈如具有大绥存的设备) 。如果该磁盘设备的故障或断电导致缓存丢失，那么您认为已完成的约定交易也将丢失。这非常严重，您应该在重新局动 Lustre 文件系统之前对该存储运47 e2fsck.。 根据 Lustre 软件的要求，用于故障切换的共享存储是缓存一致的。这确保了如采合服务硕接管另一合服务锅，它可以看到最新的准确数据副本。当服务需进行故障切换时，如果共享存储未提供所有端口之间的缓存一致性，则 Lustre 软件可能会产生错误。如果您知道错误的确切原因，则无需采取进一步行动。如有果您不知道，请与您的磁盘供应商进行深入探讨。如果错误发生在故障转移期间，请检查您的磁盘缓存设置。如果错误发生在未进行故障切换的重启后，请尝试如何能让磁盘写入成功，然后解雇数据",
        "授权缓存和配额限制在 Lustre 文件系统中, 授权缓存并不受配额限制影响。为加速 TO ，OSTs 会向 Lustre客户端授权缓存。该缓存使数据即使超过 OSTs 配额，仍能成功写入，并重写配额限制。顺序是:1. 用户将文件写入 Lustre 文件系统。2. 如果 Lustre 客户端拥有足够的授权缓存，则会向用户返回\"成功\" 并安排在 OSTs 上的写入操作。3. 因为 Lustre 客户已经向用户返回\"成功\"，OST 不能使这些写入失败。由于授权缓存，写入操作将始终重新配额限制。例如，如果您为用户 A 设置 400GB的配额并使用 IOR 从一批客户端为用户 A 写入数据，则您将写入比 400GB 多得多的数据，最终导致超出配额的错误 (EDQUOT)。注意授权缓存对配额限制的作用可以得到缓解，但无法消除。运行以下命令减少客户端上及数据最大值 〈最小值为 1MB) :* lctl set param osc.*.max dirty mb=825.8. Lustre 配额统计信息Lustre 软件可以收集监控配额活动的统计信息，如特定期间发送的配额 RPC 类型、完成RPC 的平均时间等。这些统计信息对于衡量 Lustre 文件系统的性能很有用。300\nLustre 文件系统操作手册这ay43) ACen} A CAS min time，max time和sum time值组成。配额事件sync_acq reqsync _rel reqasync_acq reqasync _rel reqwait_for_blk_quota(Iquota_chkquota)wait_for_ino quota(Iquota_chkquota)wait_for_blk_quota(Iquota_pending commit)wait_for_ino quota(Iquota_pending commit)wait for pending blk_quota_req(qctxt_wait_pending dqacq)wait for pending ino_quota_req(qctxt_wait_pending dqacq)nowait for pending blk_quota_req(qctxt_wait_pending dqacq)说明配额从设备发送获取配额的请求并等待回复。配额从设备发送释放配额的请求并等待回复。配额从设备发送获取配额的请求但不等待回复。",
        "解雇这个问题，您可以扩展 OST 的磁盘空间，或使用Lfs _migrate将文件迁移至不那么拥挤的 OST 上。(Lustre2.6 引入) 在某些情况下，一些持有打开的文件的进程消耗了大量的空间(例如: 失控进程癌已删除的打开的文件写入大量数据)。可以从 MDS 中获取文件系统中所有打开的文件句柄的列表列表 :mds# lctl get Param mdt.*.exports.*.open filesmdt .myth-MDT0000.exports.192.168.20.159¢@tcp.open_ files=[ O0x200003ab4: 0x435: 0x0][O0x20001e863: Oxlcl: 0x0][0x20001e863: Oxlc2: 0x0]These file handles can be converted into pathnames on any client viathe lfs fid2pathcommand (as root):client# lfs fid2path /myth [0x200003ab4:0x435:0x0] [0x20001e863: 0x1lcl1: 0x0][Ox20001e863: 0x1c2: 0x0]lfs fid2path: cannot find ' [0x200003ab4: 0x435:0x0]': No such file ordirectory/myth/tmp/ 4M/myth/tmp/1G在某些情况下，如果文件已经从文件系统中删除，fid2path 会返回一个”文件没有找到\" 的错误。你可以使用客户端的NID(如上面的例子中的 192.168.20.159@tep) 来确定文件是在哪个节点上打开的，而 lsof 则可以找到并杀死持有该文件的进程# lsof /mythO°COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE:NAME;logger 13806 mythtv Or REG 35,632494 1901048576384 144115440203858997/myth/logs/job.1283929.log (deleted)426\nLustre 文件系统操作手册译者:这ay在创建新文件时发生的 Linux错误-28 (ENOSPC) 可能表示 MDS 的 inode 资源已HS, MDS 需要扩展。新创建的文件不会写入满的OST，而现有文件将继续存在最初创建的OST 中。要查看 MDS 上的 inode 信息，请输入:1 lfs df -i2 UUID Inodes IUsed IFree",
        "quota_req(qctxt_wait_pending dqacq)说明配额从设备发送获取配额的请求并等待回复。配额从设备发送释放配额的请求并等待回复。配额从设备发送获取配额的请求但不等待回复。配额从设备发送释放配额的请求但不等待回复。在数据写入 OSTs 之前，OSTs 将检查剩余块配额是否足够。这将在 l1quota_chkquota Pe aH完成的。在 MDS 上创建文件之前，MDS 检查剩余的 inode配额是否足够。这将在 Iquota_chkquota 函数中完成的。将块写入 OST 后，会更新相关配额信息。这是在Iquota_ pending commit 函数中完成的。文件完成创建后，会更新相关配额信息。这是在Iquota_pending commit 函数中完成的。在MDS 或0STs 上，有一个线程随时为特定UID/GID 发送块配额请求。其他线程发送配额请求则需要等待。这是在qctxt_wait pending dqacq 函数中完成的。在MDS 上，有一个线程随时为特定 UID/GID发送 inode 配额请求。其他线程发送配人额请求则需要等待。这是在qctxt_wait pending dqacq 函数中完成的。在MDS 或OSTs 上，有一个线程随时为特定UID/GID 发送块配额请求。当线程进入qctxt_wait pending dqacq 时，无需再等待。这是在 qctxt wait pending dqacq301\n——ULDLustre 文件系统操作于册 译者:这ay配额事件 说明PACA SE WHY 0nowait for pending ino quota req 在MDS 上，有一个线程随时为特定 UID/GID(qctxt_ wait pending dqacq) 发送 inode 配额请求。当线程进入qctxt wait pending dqacq 时，无需再等待。这是在 qctxt wait pending dqacq函数中完成的。quota_ctl {# FA lfs ssetquota ，1Lfs quota 等将生成 quota_ctl 统计信息。adjust_qunit 每当 qunit 发生调整时，都将被记录。25.8.1. 解析配额统计信息AC AMZ ze Ot at Lustre 文件系统性能的重要指标",
        "，请与您的磁盘供应商进行深入探讨。如果错误发生在故障转移期间，请检查您的磁盘缓存设置。如果错误发生在未进行故障切换的重启后，请尝试如何能让磁盘写入成功，然后解雇数据设备损坏问题或磁盘错误。35.3.10. Lustre 错误: \"Slow Start Page Write\"当操作花很长的时间分配一批内存页时，会出现slow start_pPage_write消县。请驳使用这些内存页接收网络通信，然后再用于写入们盘。35.3.11. 多客户端O_APPEND 写入的劣势多客户端通过oO_APPEND写入单个文件是可能的，但存在很多缺点，使它成为次优解决方案。。每个客户端都需要对所有 OST 进行BOF 锁定。这是由于在检查所有 OST 之前，很难知道哪个 OST 保存了文件的结尾。所有的客户端都使用同一个O_APPEND，因此存在很大的锁定开销。。 第二个客户端在第一个客户端完成写入之前不能获取所有锁，客户端只能顺序写入。”为避免死锁，它们以已知的一致顺序获取锁。对于条融化文件来说，客户端在狂取所有 OSTsS 的锁前无法知道哪个 OST 持有文件的下一部分。35.3.12. Lustre 文件系统启动时的减速当 Lustre 文件系统司动时，它需要从磁盘读入数据。重司后运行的第一个 mdsrate，MDS 需要等街所有 OST 完成对象预创建，这将导致文件系统司动时的减速429\n12Lustre 文件系统操作手册 译者:As大文件系统运行一段时间后，绥存中将包含更多的数据，从磁盘读取关键元数据引起的可变性将大大地消除。文件系统现在从绥存中读取数据。35.3.13. OST 上的日志信息\"Out of Memory\"规划 OSS 贡点硬件时，请把 Lustre 文件系统中多个组件的内存使用情况列入考感。WRATFAVE, \"out of memory\" 消妃将被记录。在正半操作期间，以下几种状况表明服务融节扣内存不足:。 内核\"out of memory\" 和/或\"room-killer\" 消息。 Lustre\"kmalloc of 'mmm' (NNNN bytes) failed...\" JHA。 Lustre BK AY SERIA NUERE RE\"try to",
        "不会写入满的OST，而现有文件将继续存在最初创建的OST 中。要查看 MDS 上的 inode 信息，请输入:1 lfs df -i2 UUID Inodes IUsed IFree IUse%s Mounted on3 myth-MDTO000 UUID 1910263 1910263 0 100% /myth[MDT: 0]4 myth-OST0000 UUID 947456 360059 587397 89% /myth[OST: 0]5 myth-OSTO001 UUID 948864 233748 715116 91% /myth[OST:1]6 myth-OST0002 UUID 947456 549961 397495 89% /myth[OST:2]7 myth-OST0003 UUID 1426144 477595 948549 95% /myth[OST: 3]8 myth-OST0004 UUID 1426080 465248 1420832 57% /myth[OST: 4]910 filesystem summary: 1910263 1910263 0 100% /myth通常，Lustre 9 4 1% IL FR RAR A RN A FR iF TE ZEA PR调用中检查返回代码，它会将其解码为文本的错误消息 (如 No space left onqevice)。这两个版本的错误信息都会出现在系统日志中。你也可以使用 Letl get_param 命令来监控任一客户端的OSTs #1 MDTs 上的空间和对象使用情况。—lctl get_param {osc,mdc}.*. {kbytes, files} {free, avail, total}注意您可以在/usr/include/asm/errno.h中找到其他数字错误代但以及简短的名称和文本说明。35.3.7. 触发 PID NNN 看门狗定时器在某些情况下，服务融和氮会触发看门狗定时从，这会导致进程堆栈转储到控制A, Lustre 站核调试日志转储到/tmp 〈默认情况下) 。触发看门狗定时需并不意味痢线程的 OOPS 错误，而是它完成给定操作将需要比预期更长的时间。在茶些情况下，可能会出现这种情况。例如，RAID 重建实际上减慨了 OST 上的了9 速度，它可能会触发看门狗定时需跳。但不久之后",
        "给定操作将需要比预期更长的时间。在茶些情况下，可能会出现这种情况。例如，RAID 重建实际上减慨了 OST 上的了9 速度，它可能会触发看门狗定时需跳。但不久之后又有一条消息，表明有问题的线程已经完成了处理〈几秒钟后) 。一般来说，这表示这只是一个暂时的问题。在其他情况下，它可能会指示线程因软件错误〈如锁反转) 而卡住了。—Lustre: 0:0: (watchdog.c:122:lcw_cb())以上消息表明看门狗已为 pid 933 局动:它在 100000ms 内关闭:427\n—OO =ULD—ULD567Lustre 文件系统操作手册 译者:这ayLustre: 0:0: (linux-debug.c:132:portals debug _dumpstack() )显示进程的堆栈:933 11 ost 25 D F896071A 0 933 1 934 932 (L-TLB)£6d87c60 00000046 00000000 £896071a £8def7cc 00002710 00001822 2da48cae0008cfla f6d7c220 fed7c3d0 fod86000 £3529648 fod87cc4 £3529640 £8961d3d00000010 f6d87c9c ca65al3c OOO0ILEEL 00000001 00000001 O0000000 00000001Val FAB:filter do _biot0x3dd/0xb90 [obdfilter]default wake functiont+0x0/0x20filter direct iot0x2fb/0x990 [obdfilter]filter Preprw readt+0x5c5/0xe00 [obdfilter]lustre swab niobuf remote+0x0/0x30 [ptlrpc]ost _brw_readt+0x18df£/0x2400 [ost]ost_handlet+0x14c2/0x42d0 [ost]8 ptlrpc_server handle request+0x870/0x10b0 [ptlrpc]9 ptlrpc_maint0x42e/0x7c0 [ptlrpc]——35.3.8. 处理初始 Lustre 文件系统设置的超时如果您遇到 Lustre 文件系统初始设置的超时或挂起，请查看服务吉和客户端的名称解析是否正常工作。某些版本配置/etc/hosts将本地计算机的名称 (由hostname' 命令指示) 映射到本地主机 (127.0.0.1) 而不是正确的 IP 地址。这可能会产生这个错误:LustreError: (ldlm handle cancel()) received cancel for unknown",
        "和/或\"room-killer\" 消息。 Lustre\"kmalloc of 'mmm' (NNNN bytes) failed...\" JHA。 Lustre BK AY SERIA NUERE RE\"try to free pages\" WA35.3.14. EE SCSI VO 大小某些 SCSI SK aIRE PERAK VO 大小对于高性能的 Lustre 文件系统而言仍然过小。我们已经调整了不少驱动程序，但您仍然可能会发现某些驱动程序使用 Lustre 文件系统时性能不理想。由于默认值是硬编码的，您需要重新编译驱动程序来更改默认值。另外，一些驱动程序的默认设置可能是错误的。如果您察觉到IO PE AB RZ, HL Lustre 文件系统统计信息的分析表明其IO 不是1MB，请检查 /sys/block/device/queue/max sectors kb。如果max_sectors _kb值小于 1024，请将其设置为 1024 或更大，从而提高性能。如果更改max_sectors kb值没有改变 Lustre IO 大小，您可能需要检查 SCSI 驱动程序AF第三十六章故障恢复36.1. 在备份 ldiskfs 文件系统上恢复错误或损坏OSS, MDS 或MGS 服务句裔省时, 无需在文件系统上运行e2fck，ldiskfs journaling会确保文件系统在系统崩溃时仍保持一致。客户端不直接访问 ldiskfs 文件系统，因此客户端朋溃与服务吉文件系统一致性无关。只有当有事件导致了 ldiskfs journaling 无法处理的问题时 〈如硬件设备故障或IO错误) ，才需要在设备上运行 e28ck。如果 ldiskfs 内核代码检测到磁盘损坏，它会将文件系统挂载为只读，以防止进一步损坏，但仍允许该设备的读取访问。这在服务器的系统日志中显示为\"-30\" (EROFS) 错误，例如:Dec 29 14:11:32 mookie kernel: LDISKFS-fs error (device sdz):ldiskfs_ lookup: unlinked inode 5384166 in dir #145170469430\nLustre 文件系统操作手册 译者:这ay3 Dec 29 14:11:32 mookie kernel: Remounting filesystem readonly在这种情况下，通常只需要在损坏设备上运行 e2fick，然后再重新启动设备。在",
        "quota_ctl 统计信息。adjust_qunit 每当 qunit 发生调整时，都将被记录。25.8.1. 解析配额统计信息AC AMZ ze Ot at Lustre 文件系统性能的重要指标。正确解析这些统计信息可以帮助您诊断配质问题，并做出一些调整，以提高系统性能。例如，如果您在 OST 上运行此命令:lctl get_param lquota.testfs-OSTO000.stats您将得到类似以下的结果:Snapshot time 1219908615.506895 secs.usecsasync _acq req 1 samples [us] 32 32 32async rel req 1 samples [us] 555nowait for pending blk quota _req(qctxt wait pending dgacq) 1 samples [us] 2\\2 2quota_ctl 4 samples [us] 80 3470 4293adjust_qunit 1 samples [us] 70 70 70在第一行中，snapshot _ time 表明获得这些数据的时间。其余行列出了配额事件及其相关数据。在第二行中async acq req事件发生一次。此max timefilsum time分别为32、32 和32。单位是微秒 〈hs) 。在第五行中quota ctl事件发生四次。此max time和sum time分别为80、3470 和 4293。单位是微秒 (us) 。TWalin!Be 件 的min time,{in|beni件 的min time,302\nLustre 文件系统操作手册这ay(在 Lustre 2.5 中引入)第二十六章分层存储管理 (HSMD26.1. 简介Lustre 文件系统可以使用一组特定的功能绑定到分层存储管理 (HSM) 解决方案。这些功能可将 Lustre 文件系统连接到一个或多个外部存储系统 〈通消是 HSM) 。通过绑定到HSM 解决方案，Lustre 文件系统可以作为高速缓存在这些速度较慢的 HSM 存储系统的前端工作。Lustre 文件系统与 HSM 的集成提供了一种机制，使文件同时存在于 HSM 解决方案中，并在 Lustre 文件系统中存有元数据条目可供检查。读取，写入或截断文件将触发文件数据从 HSM 存储中取回到 Lustre 文件系统中。将文件复制到"
    ]
}