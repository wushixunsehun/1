{
    "query": "如何重新生成Lustre配置日志？说明具体流程。",
    "summaries": [
        "本文档介绍了Lustre文件系统的线程数配置和调试日志设置。首先，说明如何永久设置OST的线程数最大值为256，并验证设置是否生效。接着，讲解了调试日志的配置方法，包括调整调试级别以平衡性能和日志信息量，以及如何添加或移除调试标志。最后，提到使用lctl和sysctl命令管理调试参数，并简要介绍了OST统计信息的查看方法，如使用llstat工具监控统计数据。",
        "本文档描述了Lustre文件系统的部署和配置过程，包括创建OST设备、挂载Lustre卷、设置用户权限、开启存储配额、使用ZFS命令管理存储以及GlusterFS在ION节点的配置。主要步骤涵盖mkfs.lustre命令的使用、挂载操作、权限调整、配额设置、ZFS硬盘更换和GlusterFS服务的部署与启动。",
        "tunefs.lustre 用于修改 Lustre 目标磁盘上的配置信息，不会重新格式化磁盘或删除目标信息。更改的配置将在下次挂载时生效。参数是附加的，除非使用 --erase-params 删除旧参数。选项包括设置注释、打印输出、删除参数、设置服务节点、故障切换节点、指定文件系统名称、设置索引、挂载选项、网络、MGS 配置等。示例包括更改 MGS NID 和添加故障转移节点。手册还提到了其他工具如 lustre req history.sh 和 /proc 文件系统中的统计信息。"
    ],
    "contents": [
        "threads_ max=2562 ost.OSS.ost_io.threads_ max=256。 将线程数的最大值永人地设置为 256:# lctl conf param testfs.ost.ost io.threaqs max=256Lustre 2.5 及以上版本请运行:# Ictl set param -P ost.0SS.ost io.threaqs max=256ost.OSS.ost_io.threads max=256。查看threadqs max 设置已激活，请运行:1 # lctl get_param ost.0SS.ost _ 11o.threaqs max2 ost.OSS.ost _ io.threaqs max=256注意如采在文件系统运行时更改了服务线程数，则此更改在文件系统俘止运行前可能了会生效。超过新设置的threadqs_max值的正在运行的服务线程不会被停止。39.10. 调试日志Lustre 会默认生成所有操作的详细日志以辅助调试。可通过1ct1 get_paramqebug找到调试的相关标志。调试的开销会影响 Lustre 文件系统的性能。因此，为最小化调试对性能的影响，可以降低调试级别。这会影响存储在内部日志缓冲区中的调试信息量，但不会改变 syslog的信息量。当您需要收集日志用于调试各种问题时，可以提高调试级别。可以使用\" 符号名称\"来设置调试查码，其具体格式如下:。 验证使用的调试级别，请运行以下命令来检查用于控制调试的参数:# Ictl get param debug debug= ioctl neterror warning erroremerg ha config console。 RAL (AZAR), TTL TE A ISITE Par :508\nLustre 文件系统操作于册 译者:这ay# sysctl -w lnet.debug=\"neterror\" debug = neterrorWEE AAA, TEER ATK A EIA TE Ra:# sysctl -w lnet.debug=0 debug = 0。为生产环境设置适当的调试级别，请运和# Ictl set param debug=\"warning dlmtrace error emerg harpctrace vfstrace\" debug=warning dimtrace error emerg harpctrace vfstrace此示例中显示的标志收集了足够的高级信息以帮助",
        "$ zpool offline <pool> <vdev> #下线设备\n示例\n$ zpool offline ost48 JBOD8-S3\n#找到坏盘\n$ll /dev/disk/by-vdev/JBOD8-S3\nlrwxrwxrwx 1 root root 9 May 17 09:11 /dev/disk/by-vdev/JBOD8-S3 -> ../../sdq\n#下线即可\n$ echo 1 > /sys/block/sdq/device/delete\n4.2 ION转发节点配置\n4.2.1 Gluster方法转发\n4.2.1.1 Glustrefa配置\n服务端部署：\n1.在ion上使用mount.lustre挂载thfs3\nmount.lustre -o localflock 89.72.102.8@o2ib:/thfs3/thfs3\n2.（如果ion无法直接执行第四步，则执行）从mn6上拷贝服务端压缩包至ion节点相应目录上\nscp mn6: /home/test651/software/bin/gluster-ion-bin.tar.bz2ion:/tmp\n3.（如果ion无法直接执行第四步，则执行）在ion根目录下解压服务端压缩包，解压后得到/usr/local/glusterfs目录\nssh ion tar -xmhf /tmp/gluster-ion-bin.tar.bz2 -C /。并修改脚本/usr/local/sbin下面的start_glusterfs_tcp.sh和start_glusterfs_glex.sh脚本中根据ion主机名确定文件系统名字部分的代码，此处的文件系统名字即为ion上lustre文件系统在根目录下的挂载点：\nif [ $ion_index -ge 30 ] && [ $ion_index -le 59 ]\nthen\nfsname=\"thfs3\"\nport=20000\nfi\n4.启动当前ion的glusterfs glex服务端：start_glusterfs_glex.sh\n5.启动当前ion的glusterfs tcp服务端：start_glusterfs_tcp.sh\n6.确认glusterfs服务是否已经启动 ps aux | grep glusterfs，进程参数说明如下；如果没有glusterfs进程，则需要查看日志文件确认具体原因\n•-f 指定读取的配置文件\n•-l 指定日志存放位置\n•-L 指定日志输出等级，等级从低到高分别为：CRITICAL（什么",
        "--servicenode=oss40@o2ib --servicenode=oss41@o2ib --index=3 ost40-3/ost40-3\nmkfs.lustre --ost --mgsnode=mds16@o2ib --mgsnode=mds17@o2ib --mgsnode=mds18@o2ib --mgsnode=mds19@o2ib --fsname=thfs3 --backfstype=zfs --servicenode=oss40@o2ib --servicenode=oss41@o2ib --index=4 ost40-4/ost40-4\nmkfs.lustre --ost --mgsnode=mds16@o2ib --mgsnode=mds17@o2ib --mgsnode=mds18@o2ib --mgsnode=mds19@o2ib --fsname=thfs3 --backfstype=zfs --servicenode=oss40@o2ib --servicenode=oss41@o2ib --index=5 ost40-5/ost40-5\n4.1.7 lustre卷挂载\n# md16 挂载 mgs16 和mdt16\n$ clush -w mds[16-19]-b mount_server\n$ cluster -w oss[40-59] -b mount_server\n4.1.8 设置普通用户读写权限\n$ lctl conf_param thfs3-MDT0000.mdt.identity_upcall=NONE\n$ lctl conf_param thfs3-MDT0001.mdt.identity_upcall=NONE\n$ lctl conf_param thfs3-MDT0002.mdt.identity_upcall=NONE\n$ lctl conf_param thfs3-MDT0003.mdt.identity_upcall=NONE\n4.1.9 设置开启存储配额\n$ lctl conf_param thfs3.quota.mdt=ugp\n$ lctl conf_param thfs3.quota.ost=ugp\n4.1.10 存储挂载\n$ mount -t lustre -o nosuid,localflock 89.72.102.16@o2ib:/thfs3 /thfs3\n4.1.11 常用命令\n$ zpool list#查看zfs卷\n$ zpool status #查看zfs池状态\n$ zpool iostat1 [单位秒] #查看卷的读写\n4.1.12 zfs更换硬盘\n$ zpool offline <pool> <vdev> #下线设备\n示例\n$ zpool offline ost48 JBOD8-S3\n#找到坏盘\n$ll /dev/disk/by-vdev/JBOD8-",
        "Ictl set param debug=\"warning dlmtrace error emerg harpctrace vfstrace\" debug=warning dimtrace error emerg harpctrace vfstrace此示例中显示的标志收集了足够的高级信息以帮助调试，但它们不会对性能造成任何严重影响。。 为已经设置的标志诡加新标志，请在每个标志前面加上\"+'\":# Ictl set param debug=\"+neterror tha\" debug=+neterror +ha# Ictl get param debug debug=neterror warning error emerg haconsole”移除标志，请在标志前附加\"-\":# lctl set param debug=\"-ha\" debug=-ha # lctl get paramdebug debug=neterror warning error emerg console调试参数包括 :。 subsystem debug 一控制子系统的调试日志。* debug_path 一指示被目动或手动触发时调试日志转储的位置。默认路径是/tmp/1Lustre-1Log。可使用以下命令设置这些参数:1 sysctl -w lnet.debug={value}其他参数:。 panic_on_lbug 一当 Lustre 软件检测到内部问题 (LBUG日志和条目) 时，会调用\"panic\"，从而导致节点裔溃。在配置内核骨省转储实用程序时，这尤其有用。Lustre 软件检测到内部不一致时，将触发故障转储。。upcall 一允许您指定在遇到LBUG日志条目时调用的二进制文件的路径。使用以下四个参数调用此二进制文件:\"字符帅\"LBUG\"LBUG发生的文件。 函数名称。 文件中的行号309\n——ULD567Lustre 文件系统操作于册 译者:这ay39.10.1. 解析 OST 统计数据OST stats 文件可用于提供每个 OST 活动的统计信息。例如:# lctl get Param osc.testfs-OSTO0000-osc.statssnapshot time 1189732762 .835363L 4ost_ create 1+ost get info 1L 4ost_connect 1+ost_set_ info 1obd_ ping 212可使用L1stat实用程序监视一段时间内的统计信息。eee if lcstath-citl. HERRIMAN 〈以秒为单位)",
        "1L 4ost_connect 1+ost_set_ info 1obd_ ping 212可使用L1stat实用程序监视一段时间内的统计信息。eee if lcstath-citl. HERRIMAN 〈以秒为单位) ，请使用-i选项。在下面的示例中，使用了-c选项先清除统计信息，-i10选项设置为每 10 its 次统计信息$ llstat -c -1I10 ost_io/usr/bin/llstat: STATS on 06/06/07/proc/fs/lustre/ost/OSS/ost_io/ stats on 192.168.16.35@tcpsnapshot time 1181074093 .276072/proc/fs/lustre/ost/OSS/ost_io/stats @ 1181074103.2848958 Name Cur. Cur. #9 Count Rate Events Unit last min avg max stddev10 req waittime 8 0 8 [usec] 2078 34 259.75 868 317.4911 req qdepth 8 0 8 [regs] l 0 0.12 1 0.3512 req_ active 8 0 8 [reqs] ll 1 1.38 2 0.5213 reqbuf avail 8 0 8 [bufs] 511 63 63.88 64 0.3514 ost_write 8 0 8 [bytes] 169767 72914 212209.62 387579 91874.291516 /proc/fs/lustre/ost/OSS/ost_io/stats @ 1181074113.29018017 Name Cur. Cur. #18 Count Rate Events Unit last min avg max stddev19 req waittime 31 3 39 [usec] 30011 34 822.79 12245 2047.7120 req qdepth 31 3 39 [regs] 0 0 0.03 1 0.1621 req active 31 3 39 [reqs] 58 1 1.77 3 0.7422 reqbuf avail 31 3 39 [buffs] 1977 63 63.79 64 0.41510\n23242526272Oo29303—32Lustre 文件系统操作手册 译者:这ayost write 30 3 38 [bytes] 1028467 15019 315325.16 910694 197776.51/",
        "|序是: 1. 卸载文件系统上的所有客户端，2. EURO ABE ||| 上的 MDT APTA OST, 3.在每个服务器上运行|上tunefs.lLustre --writeconf device, 4. 挂载MDT 和||| OST, 5. 挂载客户端。|44.18.4. 示例更改 MGS AY NID 地址。(在每个目标磁盘上执行，它们都应联系同一个 MGS 。)tunefs.lustre --erase-param --mgsnode=new_nid --writeconf /dev/sda为此目标添加故障转移 NID 位置。tunefs.lustre --param=\"failover.node=192.168.0.13@tcp0\" /dev/sda也可见本章第 14 7i\"mkfs.lustre\", 28 15 47\"mount.lustre\" 和第 3 节\"lctl\"。44.19. 附加系统配置程序AS Ti EES 24 Lustre 的其他系统配置实用程序。44.19.1. 应用程序分析工具lustre req history.sh位于/usrbin 中，它从客户端运行，从本地节点和连接FN ARS ae ACRES AY EZ? AY Lustre RPC 请求历史记录，从而更好地了解协调网络活动。585\nLustre 文件系统操作手册 译者:这ay44.19.2. More/proc 统计信息vfs ops_stats提供了更多统计信息, Cia PID, PPID, GID 等来跟踪 Linux VFS操作调用。—/proc/fs/lustre/llite/*/vfs_ops statsN/proc/fs/lustre/llite/*/vfs_track_[pid|ppid|gid]extents_stats可用于显示来目客户端的IO AAA Don (Za tree eee值)。—/proc/fs/lustre/llite/*/extents stats, extents stats per procesoffset_statsiii (i ATE Ne PO iy Be SISA—/proc/fs/lustre/llite/*/offset statsLustre 也包含了 Per-client 〈每个客户端的) 和优化的 MDT 统计信息:。 WR at _LiB EAN Per-client 统计信息每个MDS",
        "梗概tunefs.lustre [options] /dev/device44.18.2. 说明tunefs.lustrek 可用于修改 Lustre 目标磁盘上的配置信息。这不会重新格式化磁盘或探除目标信息，但修改配置信息可能会导致文件系统无法使用。注意此处所做的更改只在下次挂载目标时产生效果。使用 tunefs.lustre 时，参数是\" 附加的\" 。即除旧参数外，指定的新参数不会蔡换它们，而是附加上去的。要删除所有旧的 tunefs.lustre 参数并仅使用新指定的参数，请运行:$ tunefs.lustre --erase-params --param=new parameterstunefs.lustrefp © HA] AF ik ® /proc/fs/lustrexv fF Hu hw aA有目己的OBD 设备的任何参数，因此可以将其指定为 pal fs-nameobd|fsname.obdtype.proc file name=value,. 例如 :S$ tunefs.lustre --param mdt.identity upcall=NONE /dev/sdal44.18.3. 选项tunefs.lustre 选项如下所示: |选项 | 说明 | | -------------------------- | -一-----------|| --comment=comment | 设置有关此磁盘的用户注释，会被Lustre 忽略。|| -=-dqryzun | 只打印命令的输出，不执行命令。| | --erase-params[删除所有先前的参数信息。| | --servicenode=nid,... |设置所有服务节点的NID, GEAR A ae 7 AAO | | | BCR IRR A. --servicenodeyt A HE | | |与-=-failnodqe选项一起使用。|| --failnode=nid,...| AHA AAS EARS ARIS了区切换服务节点的NID。||| -=-servicenode选项不能与--failnodqe选项一|上|起使584\n——As大Lustre 文件系统操作手册 译者:用。注意使用 --failnode 选项时有一些限|上|制。||--fsname=filesystem name| 该服务将成所指定 Lustre 文件系统其中的一部分。||| 默认文件系统名称为1Lustre。||",
        "注意使用 --failnode 选项时有一些限|上|制。||--fsname=filesystem name| 该服务将成所指定 Lustre 文件系统其中的一部分。||| 默认文件系统名称为1Lustre。||--index=index | 强制设置特定的OST aK MDT 24]. || --mountfsoptions=opts| 设置备份文件系统挂载时使用的挂载选项。注意，||| 与早期版本的 tunefs.lustre不同，此版本完全将现||1|1有挂载选项蔡换为俞令行中指定的挂载选项。如有果||11省略任何默认挂载选项 将在 stderr 上发出警告。| | | Idiskfs AY AK认值为: MGS/MDT —errors=remount- | | | roviopen nopriv user xattr;OST — ||| errors=remount-ro,extents,mballoc ||| (在Lustre 2.5 中，OST—errors=remount-). ro ||| 请不要在不明状况时轻易更改默认挂载选项。| |--network=net,.. .|OST/7MDT限制的网络。可以根据需要重复此选项。|| --mgs|添加此目标的配置管理服务。| | --msgnodqe=nid, .. .|设置MGS 下氮的NID〈除MGS 之外的所有目标)。|| --nomgs | 删除此目标的配置管理服务。|| --quiet |打印简短的信息。|| --verbose |打印更多信息。||--wziteconf | 探除此MDT 所属的文件系统的所有配置日志，并重新||| 生成它们。这是非钊危险的操作，请务必倒载所有客 |||户端并停止此文件系统的服务右。随后，请重司所有||| 目标 (OST/MDT) 以重SERA. ESRI ||| 有目标之前，请不要启动任何客户端。正确的操作顺 | | |序是: 1. 卸载文件系统上的所有客户端，2. EURO ABE ||| 上的 MDT APTA OST, 3.在每个服务器上运行|上tunefs.lLustre --writeconf"
    ]
}