{
    "query": "客户端挂载失败时，如何排查问题所在？",
    "summaries": [
        "子目录挂载（文件集）允许客户端挂载父文件系统的子目录，限制其可见的文件系统命名空间。客户端可选择是否使用此功能，不影响对多个子目录中硬链接文件的访问，也不影响后续挂载整个文件系统的操作。示例展示了如何在客户端挂载子目录，并验证其他客户端无法访问未挂载的目录。子目录挂载不包含.Lustre目录，阻止客户端通过FID直接访问文件。Lustre配置API涉及返回代码、序列号及YAML内部表示。",
        "登录节点故障包括失去连接/宕机和负载过高。对于宕机，可通过堡垒机或监控平台确认节点状态，并通过运维平台重启。对于负载过高，可按CPU或内存查看用户进程，清理高占用进程或用户全部进程以降低负载。",
        "系统使用两种方式挂载文件系统：glusterfs转发和lustre route。glusterfs转发通过在ion上运行glusterfsd服务，cn节点挂载/vol8，数据通过gluster转发至ion处理。配置需修改gluster文件中的ip为对应ion的高速网ip。lustre route则通过路由配置实现数据转发，mds/oss添加tcp1路由，ion设置双网口并启用转发，cn添加o2ib路由，最终挂载文件系统。两种方式均需正确配置网络和路由。"
    ],
    "contents": [
        "ost127\nost127\n\n—\n\njobid\n\n1828258\n1818914\n1827402\n\nsftp-server.20654\n\nnode.20912\n1768786\nbash20461\nsftp-server.20528,\n1796896\n1825828\n\n读次数\n\njobid\n\n1818914\n1827772\n1827855\n1827875,\n1827858\n1827871\n1827872\n1827751\n1825099\n1827402\n\n1143\n7.89\n3.73\n245\n137\n4.19\nO71\n0.69\n\n03\n\n1237\n873\n615\n591\n5.33\n5.28\n4.01\n0.94\n\n06\n可以看到排序靠前的jobid。\n3.4 登陆节点故障\n3.4.1 登录节点失去连接/宕机\n监控平台报警如下：\nth-hpct-Ino\n\n失去连接\n\nTH-HPC\n\n登录节点\n\n硬件\n\n。严重\n①首先判断登录节点是否真的宕机，可以通过堡垒机ssh到登陆节点查看状态，也可以通过监控平台的节点操作里查看节点状态。\nTH-HPq\n其他操作 节点操作\n\n下ec 节点编号: th-hpc1-In0\n日 @ TH-HPC\n四 HPC1-127序号: 2523所属集群 TH-HPC硬盘大小: 无硬盘\n日 login节点名称: th-hpc1-In0所履分区: _null硬盘类型. 无硬盘\n\n@ th-hpct-Inoao\n\n:登录节点存储位置: 老机房-TH-HPC-HPC1-127-12.0\n②确认登录节点宕机后，可以通过运维平台直接重启，如下图：\n统一监控运维平台\n\nTH-HPC\n\nTH-HPC4PDTH-HPC\na fre] @\n剧本编排日 局 存储分区操作\n加THL5登陆节点部署客户端.， MDS节点部署客户.， 0ST节点部署客户.计算节点部署客户端.\n剧本执行四THL6\n局THL7el\n执行审计Otis查询传感器日志远程协助®\n© 资源操作\n局 用户操作\n© 作业操作\n© 服务操作\n号 数据拷贝\n号 应急操作\n2 批量操作\n®\n您确定要执行电源管理操作吗?\n3.4.2 负载过高\n（1）选择按CPU或内存查看导致系统负载过高的用户进程。\n统一监控运维平台= 运维管理axa @\n\n定制大屏机房运维总览剧本执行\n\nTH",
        "_2 FRAY FID (如上例中所示) ，则会返回错误。无法在 client2 上解析 FID 是因为它在该客户端上不属于已挂载文件集的一部分 (client2 上的文件集挂载在chipfs文件系统根目录下的v1_1子目录)。Client2# lfs fid2path /mnt/chip/v1_2 [0Ox200000400:0x2:0x0O]fid2path: error on FID [0x200000400:0x2:0x0]: No such file or directory子目录挂载不包含.Lusttre目录，这将阻止客户端通过 FID 直接打开或访问文件。clientl# ls /mnt/chipfs/.lustrefid lost+foundclient2# ls /mnt/chipvl_ 1/.lustrels: cannot access /mnt/chipvl_ 1/.lustre: No such file or directory第四十五章 LNet 配置 C-API45.1. API 通用信息45.1.1. API 返回代码588\n123410——12131415161718Lustre 文件系统操作手册%ty这ayLUSTRE CFG RC_NO ERR0LUSTRE CFG RC BAD PARAM-1LUSTRE CFG RC MISSING PARAM-2LUSTRE CFG RC OUT OF RANGE PARAM -3LUSTRE CFG RC OUT OF MEM -4LUSTRE CFG RC GENERIC ERR -545.1.2. API 普通输入参数所有API 都将序列号作为输入，这是一个由API 的调用者分配的数字，并且会包合在 YAML 错误返回块中。它用于将请求与啊应相关联。它在通过 YAML 接口进行配置时尤其有用，因为 YAML 接口通冲用于配置多个项目，而在返回错误块中，需要知道哪些项目已正确配置、哪些项目未正确配置。序列号正好达到了这个目的。45.1.3. API 普通输出参数45.1.3.1. YAML 内部表征 (CYAML) YAML 块完成解析后，需要进行结构化存储它，以便于将其传递给不同的函数、查询或打印。此外，还需要能够从内核返回的数据构建此内部表征，并将其返回给调用者以供调用者查询和打印。此结构表征用于 Error 和 ShowAPI Out 参数。YAML 在内部被结构化表示为:\\Nytypedef",
        "提供子目录挂载文持。子目录挂载 〈也称为文件集) 允许客户端挂载父文件系统的子目录，从而限制文件系统命名空间在特定客户端上的可见性。一个前见的用法是: 为防止挂载的子目录之外的文件的意外，客户端可以使用子目录挂载，以限制整个文件系统命名空间的可见性。值得注意的是，是否调用子目录挂载是客户问目愿的，这不会影响对多个子目录中硬链接可见的文件的访问。此外，和它也不会影响客户端随后在没有指定子目录的情况下圭载整个文件系统。client1 @tcp0:/tesfsclient2\\ 和 @tcp0:/testfs/subdir\\ ifs \\ fid\\ path2fid \\visiblelust testdirES subdir图 29: Lustre file system fileset feature图 42.1 Lustre 文件集387\n—N—N—NULD—N—ULDLustre 文件系统操作手册 译者:这ay44.19.41. 示例 以下示例将在 client] 上挂载chipfs文件系统，并在该文件系统中创建子目录v1_1。随后，Client2 将把 vL_1 子目录挂载为文件集，从而限制 client2 访问chipfs文件系统中的任何其他内容。clientl# mount -t lustre mgs@tcp:/chipfs /mnt/chipCclientl# mkdir /mnt/chip/v1_1client2# mount -t lustre mgs@tcp:/chipfs/vl_1 /mnt/chipvl1 1您可以在/etc/mtab 中检查所创建的挂载。和它应该如下所示:clientlmds@tcp0:/chipfs/ /mnt/chip lustre rw 0 0client2mds@tcp0:/chipfs/v1_1 /mnt/chipvl_1 lustre rw 0 0在/mnt/chip 下创建一个目录，并获取其 FID:clientl# mkdir /mnt/chip/v1_ 2clientl# lfs path2fid /mnt/chip/vl1_2[ 0x200000400: 0x2: 0x0]如果您尝试在 client2 上解析 /mnt/chip/v1_2 FRAY FID (如上例中所示) ，则会返回错误。无法在 client2 上解析 FID 是因为它在该客户端上不属于已挂载文件集的一部分 (client2 上的文件",
        "吗?\n3.4.2 负载过高\n（1）选择按CPU或内存查看导致系统负载过高的用户进程。\n统一监控运维平台= 运维管理axa @\n\n定制大屏机房运维总览剧本执行\n\nTH-HPC\n其他操作\n\nth-hpct-IndQ\n\n5cq 节点编号: th-hpc1-Ind\n\n日| s TH-HPC\nFRE: 2523所属集群 TH-HPC\n\n剧本编排~加 HPC1-127\n日 login节点名称: th-hpc1-In0所属分区:_null\na节点类型: 登录节点存储位置: 老机房-TH-HPC-HPC1-\n127-12.0\n执行审计\n查询日志查询内存清除进程清除用户进程\nth-hpc1-In0:cpu进程排序 X\n\n天对执行\n命令输出:\n\nPLAY [a] ws本洒洒洒洒末末洒洒宁洒洒末末\n\nchanged: [121.16.3.1]\n\nSPU/内存的使用排序\n\nok: [121.16.3.1] =>\nesRBFES, EEZIDmt进程命令\nVSZ RSS TTYSTAT STARTTame [command™,]\nangyq 5735@.2 308900 148640 pts/101 Rt 09:04 10:28 ncl 16.ncl”,\nroot33364 12.6 0.0 124128 6408 ?S69:15 “6:63 /bin/sh /usr/local/bin/rkhunter -c -\ninxubo 21825 5.@ @.@ 125488 3844 pts/128 Ss+ 89:15 ”9:68 -bash\"，\n“wangyq 40400 4.9 0.2 308896 148628 pts/101 T 09:02 0:37 ncl 16.ncl\",\n\n\"nslcd2398 3.2 ©.0 442336 1432 ?Ssl 4月16 1429:26 /usr/sbin/nslcd\",\n\n\"root888 2.1 0.0 95640 38540 ?Ss 4月16 958:11 /usr/lib/systemd/systemd-journald\",\n\"linxubo 22342 2.0 @.@ 59000 2240 ?Ss 09:15 @:0@ /usr/libexec/openssh/",
        ":11 /usr/lib/systemd/systemd-journald\",\n\"linxubo 22342 2.0 @.@ 59000 2240 ?Ss 09:15 @:0@ /usr/libexec/openssh/sftp-server\",\n\"root2264 1.4 @.1 5182264 106456 ?SLsl 4月16 644:38 /opt/thsre/exporters/telegraf/telegr\n“root21684 1.0 0.0 159956 5688 ?Ss 9:15 0:0 sshd: linxubo [priv]\",\n\n\"linxubo 22501 1.0 6.9 119748 2028 ?Ss 69:15 @:0@ bash -c while true; do sleep 1;head\n图：按CPU使用率查看用户进程\n（2）清理用户的某个进程。通过第一步得到使用率高的进程ID。\n统一监控运维平台运维管理 、\n\nSAR 。 机房 运维总览\nTH-HPC\n其他操作 节点操作\nth-hpct-IndQ\non?\n日 @ THHPC\n剧本编排日 HPC1-127\nlogin\n剧本执行© th-hpct-Ind\n\n节点编号: th-hpc1-In0\n\n序号: 2523\n节点名称: th-hpc1-In0\n\n节点类型: 登录节点\n\n查询内存\n\n所属集群 TH-HPC\n\n所属分区:_null\n\n存储位置: 老机房-TH-HPC-HPC1-\n127-12.0\n\nvo 清除单个进程\n\n清除用户进程\n\n硬盘大小: 无硬盘\n\n节点状态: 连接成功 |\n\ncpu进程排序\n统一监控运维平台\n\n定制大屏me\n\n运维总览剧本执行\n\n其他操作 。 节点操作\n\nth-hpc1-In0\n\n日 @ THHPC\n©) HPC1-127\n\nlogin\n\n© th-hpct-Ind\n\n存储位置: 老机房-TH-HPC-HPC1-\n127-12.0\n\n查询日志\n\n查询内存SHE=a\nAIRS\n\n硬盘大小: 无硬盘\n硬盘类型; 无硬盘\n\n节点状态: sea\n\ncpu进程排序\n（3）清除用户全部进程。通过第一步得到使用率高的用户名",
        "两种挂载文件系统方式\n挂载文件系统\n> 目前系统使用2种方式挂载存储，分别为glusterfs转发和lustre route方式挂载\nglusterfs转发挂载\n该方式工作模式为：\n- server:\t在ion上通过IB网络挂载文件系统客户端，再在该ion上运行glusterfsd server端\n- client:\t通过在cn上运行gluster挂载/vol8，此时cn上对/vol8下的所有操作，均通过gluster将请求数据转移至对应ion处理\n示例\n# 在ion[a-b]上通过IB网络挂载文件系统客户端\n[root@ion1%xx~]#mount -t lustre -o localflock mds0@o2ib:/TEST /vol8\n#在ion上运行glusterfsd server端\n[root@ion1%xx~]#cd /usr/local/gluster-forward/sbin\n[root@ion1%xx~]# ./glusterfsd -f gluster -l /tmp/$(hostname).log\n#在cn上运行gluster挂载/vol8\n[root@cn5440% xx~]# cd /usr/local/gluster-forward/sbin/\n[root@cn5440% xx~]#./glusterfs -f gluster -l /tmp/$(hostname).log /vol8\n计算节点转发ion配置文件\n#其中cn节点通过那个ion转发数据的配置文件在本节点的gluster,修改其中的ip为对应ion的高速网ip即可\n[root@cn5440% xx~]# cd /usr/local/gluster-forward/sbin/\n[root@cn5440% xx~]#vim gluster\n4   option remote-host <server IP地址>\nlustre route挂载\n该方式工作模式为：\n- mds/oss:\t只有IB网络，在其上添加路由配置，使所有tcp1请求转发至指定route\n- ion:\t由IB和高速网络，自身设置为route，/etc/modprobe.d/lustre.conf内添加双网口以及启用转发配置\n- cn:\t\t只有高速网络，在其上添加路由配置，使所有o2ib请求转发至指定route\n示例 ,切记为mds,oss都要设置路由配置\n[root@mds0%xx~]#modprobe lustre\n[root",
        "只有高速网络，在其上添加路由配置，使所有o2ib请求转发至指定route\n示例 ,切记为mds,oss都要设置路由配置\n[root@mds0%xx~]#modprobe lustre\n[root@mds0%xx~]#lnetctl route add net tcp1 gateway ion0-ib0@o2ib\n[root@oss0%xx~]#lnetctl route add net tcp1 gateway ion0-ib0@o2ib\n注：所有的mds和oss都要执行这条命令，添加路由配置。\n[root@ion0%xx~]#cat /etc/modprobe.d/lustre.conf\noptions lnet networks=tcp1(gn0),o2ib(ib0) forwarding=enabled\noptions ksocklnd sock_timeout=100 peer_credits=8 credits=256\noptions ko2iblnd peer_credits=128 credits=1024\n[root@ion0%xx~]#modprobe lustre\n[root@cn0%xx~]#lnetctl route add net o2ib gateway ion0-gn0@tcp1\n[root@cn0%xx~]#mount -t lustre -o localflock mds0-ib0@o2ib:/TEST /vol8"
    ]
}