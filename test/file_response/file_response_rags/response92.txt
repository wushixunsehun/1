{
    "query": "在 Lustre 文件系统中，如何通过参数配置实现对客户端 Root 用户权限的细粒度控制？请结合 Root Squash 机制及例外客户端设置说明。",
    "summaries": [
        "Root Squash 是 Lustre 文件系统的一项安全功能，用于限制超级用户访问权限。它将 root 用户的 UID 和 GID 映射为指定的值，防止未授权客户端访问 root 文件。通过配置 root_squash 参数指定映射的 UID/GID，nosquash_nids 参数指定不适用 Root Squash 的客户端。配置可通过 mkfs.lustre、tunefs.lustre 或 lctl 命令进行。调试时需注意参数语法，错误设置可能导致默认值被使用。Root Squash 设置可临时或永久更改。",
        "mkfs.lustre 和 tunefs.lustre 不进行参数语法检查，错误的 root squash 参数会在挂载时被忽略。root squash 参数需按严格语法指定，nosduash nids 参数需符合 LNet NID 范围语法。Lustre 的 Isolation 功能通过 Fileset 实现多租户隔离，使不同用户组无法访问彼此文件。配置 Isolation 需在 nodemap 中设置 fileset 参数，持久化需使用 -P 选项。SELinux 在 Lustre 客户端上支持 MAC 和 MLS 策略，确保数据安全，Lustre 服务端无需 SELinux 策略。",
        "Lustre 文件系统支持用户、组和项目配额的设置与管理。通过 `lfs quota` 和 `lfs setquota` 命令可以设置默认或特定用户的配额限制，包括块和 inode 的软硬限制。当配额设置为0时，将使用默认配额。配额在 OSTs 之间分配，由 QMT 负责管理，QSD 通过连接 QMT 获取配额信息。配额分配以大块形式进行，减少请求流量，但 qunit 大小有最小限制。若配额不足，即使其他 OST 仍有空间，也会返回错误。项目配额需所有节点升级至 Lustre 2.10 及以上版本才能正常工作。授权缓存不受配额限制影响。"
    ],
    "contents": [
        "-ld raindrwxrwx---+ 2 root root 4096 Feb 20 06:50 rain[root@client lustre]# getfacl --omit-header rainuser: :CTWXuser:chirag: rwxgroup: :r-xmask: :rwxother: :---343\nLustre 文件系统操作手册 译者:As大30.2. 使用 Root Squash (压缩)Root Squash 是一种安全功能，它限制了超级用户访问 Lustre 文件系统的权限。如果未司用 Root Squash 功能，则未授信任客户端上的 Lustre 文件系统用户可以访问、修改，甚至删除系统 root 用户的文件。使用 Root Squash 功能可以限定能够访问或修改 root 用户文件的客户端。注意，这不会阻止未授信客户端上的用户访问其他用户的文件。Root Squash 功能通过 Lustre 配置管理服务锅 (MGS) 将root 用户的用户标识〈UID)和组标识 (GID) 重新映射到由系统管理员指定的 UID 和 GID 来工作。Root Squash 功能同时也允许 Lustre 文件系统管理员指定不适用于 UID/GID 重映映的一组客户端注意Nodemaps (用 an 映射 UID 各 oe 是 root squash 的一种蔡代方案，因为它也人允许在每个客户端上进行 root squash。通过 UID 映射，和客户端甚至可以拥有一个本地的 root UID, ，而不需天本身的 oo bia30.2.1. 配置 Root SquashRoot Squash 由两种配置参数进行管理: root squash, nosquash nids.root_squash 参数用于指定 root 用户访问 Lustre 文件系统使用的 UID 和 GID.nosquash_ nids 参数用于指定不适用 Root Squash 的一组客户端,使用LNetNID范围的语法，如:—nosquash nids=172.16.245. [0-255/2]@tcp在此示例中，Root Squash 不适用于子网 172.16.245.0 FIP 地址最后一部分为偶数的 TCP 客户端30.2.2. 启用和调试 Root Squashnosquash nids 的默认值为NULL，表明默认情况下 Root Squash 适用于所有客Fito ZA]",
        "和否则用户将可能遇到不必要的故障。文件系统块配额在文件系统内的 OSTs 之间分配。每个 OST 请求分配的额度都被将被添加到配额限制里。Lustre 通过量化配额分配减少配额请求相关流量。Lustre 配额系统中，配额主目标 (QMT) 负责分配配额。目前，Lustre 仅文持一个QMT 实例，且只能在类似 MDT0000 的节点上运行。但所有的OST 和 MDT 都建立了配额从设备 〈QSD) ，它们通过连接到 QMT 来分配和释放配额空间。QSD 直接在 OSD 层进行设置。为了减少配额请求，最初配额空间以非常大的块分配给 QSDs。一个目标可以容纳多少未使用的配额空间由 qunit 大小控制。当给定 ID 的配额空间在 QMT 上快要耗尽时，qunit 大小将会减少，QSD 将通过\"glimpse callback\" 获悉新的 qunit 大小值。随后，从设备需要释放比新的 qunit 值更大的配额空间。qunit 大小不会无限缩小，对于块来说，其最小值为 JIMB，对于 inodes 来说，其最小值为 1024。这意味痢达到此最小值时配额空间重新平衡过程将停止。因此，即使许多从设备还有 1MB 块或 1024 个 inode 的剩余配额空间，仍会返回配额超标的消息。如果我们再次查看setdquota示例，运行以下1fs duota命今:1 # 1fs quota -u bob -v /mnt/testfs输出为:1 Disk quotas for user bob (uid 500):2 Filesystem kbytes quota limit grace files quota limit grace3 /mnt/testfs 30720* 30720 30920 6d23h56m44s 10101* 10000 110004 6d23h59m50s5 testf£s-MDTO000 UUID 0 - 0 一 10101 一 102406 testfs-OSTU00U0 UUID 0 一 1024 - 一 一 一7 testfs-OSTU001 UUID 30720* - 29896 - 一 一 一8 Total allocated inode limit: 10240, total allocated block limit: 30920总共 30920 的配额",
        "_ param暂时改变，或者通过 lctlset_param -P了永久改变。例如:mgs# lctl set param mdt.testfs-MDTO000.root_squash=\"1:0\"mgs# lctl set param -P mdt.testfs-MDTO000.root_squash=\"1:0\"清除 nosquash_nids 列表:mgs# lctl conf param testfs.mdt.nosquash_nids=\"NONE\"或:mgs# lctl conf param testfs.mqt.noscuasnh nids=\"clear\"nosquash nids 包含了一些NID YEA] (YN: O@elan, 1@elanl), NID 范围列表WU FES [Ss C) 或双引号 () 进行引用，每个值用空格分开，如:mds# mkfs.lustre ... --param \"mdt.nosquash nids='O0@elanl 1@elan2'\" /dev/sdallctl conf param testfs.mdt.nosquash nids=\"24¢elan 15¢elanl\"以下是一些语法错误的例子:mds# mkfs.lustre ... --param \"mdt.nosquash nids=0@elanl 1@elan2\" /dev/sdallctl conf param testfs.mdt.nosquash nids=24@elan 15@elanl使用1ct1 get param 命令查看 Root Squash 参数:mds# lctl get Param mdt.testfs+MDT0000.root_squashlctl get_param mdt.* .nosquash_nids注意nosquash nids列表为空，将返回 NONE.345\n—1Lustre 文件系统操作手册这ay30.2.3. 使用 Root Squash 的技巧在 Lustre 配置管理中，Root Squash 功能在以下几个方面有所限制:。 lct1l conf param 指定的值将柳盖参数移前的值。如果新值使用不正确的语法，那么系统将继续使用旧的参数，但在重新持载时之前正确的值将丢失。请说蛋调试 Root Squash 。* mkfs.lustre fi] tunefs.lustre 不进行参数语法检查。如果 root squash 参数错误，它们将在挂载时被忽略 ，系统将使用默认值。。 Root Squash 参数将通过",
        "中不存在定义为 fleset 的子目录，则会阻止任何属于 nodemap 的客户端挂载 Lustre.要删除 fileset 参数，只需将其设置为空字符串即可 :mgs# lctl nodemap set fileset --name tenantl --fileset ''30.3.3. 将 Isolation 持久化为了使 Isolation 持久化，必须使用佛选项 -PE的Ict1 set param来设置nodemap上的fileset 参数。347\nLustre 文件系统操作手册这aX1 mgs# lctl set param nodemap.tenantl.fileset=/dirl2 mgs# lctl set param -P nodemap.tenant1.fileset=/dirl这样，fileset 参数将被存储在 Lustre 配置的日志中，供服务融重司后获取该信息。30.4. 检查 Lustre 客户端执行的SELinux 策略SELinux 在 Linux 中提供了一种支持强制访问控制 (MAC) 策略的机制。当 MAC策略被强制执行时，操作系统的内核就会定义应用的权限，使应用不会危及整个系统。普通用户没有能力使该策略失效。SELinux 的一个目的是保护操作系统不受权限升级的影响。为此，SELinux 为进程和用户定义了受限域和非受限域。每个进程、用户、文件都被分配了一个安全环境，规则定义了进程和用户对文件允许执行的操作。SELinux 的另一个目的是保护数据的敏感性，这要归功于多级安全 (MLS) 功能MLS 是在 SELinux 的基础上，通过定义域之外的安全级别概念发挥作用。每个进程、用户和文件都被分配了一个安全级别，且该模型规定，进程和用户可以读取与自己相同或更低的安全级别的数据，但只能写入与自己相同或更高的安全级别的数据。从文件系统的角度来看，文件的安全环境必须持久存储。Lustre 利用文件上的security.selLinux扩展属性来存储这些信息。Lustre 在客户问文持SELinux。要在Lustre 上实现 MAC 和MLS，需要做的就是在所有 Lustre 客户端上执行适当的 SELinux策略 〈由 Linux 发行版提供) 。Lustre 服务锅上不需要 SELinux 策略。因为 Lustre 是一个分布式文件系统，所以使用MLS 的特殊性在于，Lustre 确实需要确保",
        "来禁用。25.4.1 用法lfs quota [-U|--default-usr|-G|--default-grp|-P|--default-prj] /mount pointlfs setquota {-U|--default-usr|-G|--default-grp|-P|--default-prj} [-bblock-softlimit] \\[-B block hardlimit] [-1 inode _softlimit] [-I inode_hardlimit][mount pointlfs setquota {-u|-g|-p} username|groupname -d /mount point设置默认的用户配额:# 1Lfs setquota -U -b 10G -B 11G -i 100K -I 105K /mnt/testfs设置默认的组配额:# 1Lfs setquota -G -b 10G -B 11G -i 100K -I 105K /mnt/testfs设置默认的项目配额:# 1Lfs setquota -P -b 10G -B 11G -i 100K -I 105K /mnt/testfs茶止默认的用户配额:# lfs setquota -U -b 0 -B 0 -i 0 -I 0 /mnt/testfsZR IL SOARS ZA Rc ait:# lfs setquota -G -b 0 -B 0 -i O -I O /mnt/testfs茶止默认的项目配额:# lfs setquota -P -b 0 -B 0 -i O -I O /mnt/testfs注意:298\nLustre 文件系统操作手册 译者:如果为某些用户、组或项目设置了配额限制，Lustre 将使用这些特定的配额限制，而不是默认的配额。任何用户、组或项目可以通过将其配额限制设置为0来使用默认配Fillo25.5. 配额分配在 Lustre 文件系统中，配额必须正确分配，和否则用户将可能遇到不必要的故障。文件系统块配额在文件系统内的 OSTs 之间分配。每个 OST 请求分配的额度都被将被添加到配额限制里。Lustre 通过量化配额分配减少配额请求",
        "FIP 地址最后一部分为偶数的 TCP 客户端30.2.2. 启用和调试 Root Squashnosquash nids 的默认值为NULL，表明默认情况下 Root Squash 适用于所有客Fito ZA] Root Squash，请将 root squash UID 和 GID 设为 0。创建MDT (mkfs.lustre --mdt) 时可设置 Root Squash 参数，如:1 mds# mkfs.lustre --reformat --fsname=testfts --mdt --mgs \\2 —-param \"mdt.root squash=500:501\" \\3 -—-param \"mdt.nosquash_ nids='0@elanl 192.168.1.[10,11]'\" /dev/sdalRoot Squash 参数可在未挂载的设备上通过tunefs . lustre:1 tunefs.lustre --param \"mdt.root_squash=65534:65534\" = \\2 --param \"mdt.nosquash nids=192.168.0.13@tcp0\" /dev/sdal344\n————————Lustre 文件系统操作于册 译者:这ayRoot Squash 参数也可通过 lctl conf param 命令更改，如:mgs# lctl conf param testfs.mdt.root_squash=\"1000:101\"mgs# lctl conf param testfs.mdt.nosquash_nids=\"*@tcp\"要检索当前的 root squash 参数设置，可以使用如下1Lct1l get_param命令:mgs# lctl get param mdt.*.root squashmgs# lctl get param mdt.*.nosquash_nids注意使用1ct1 conf param命令时，请谨记:。 lctl conf param 必须在活动 MGS 上运行。。 1Lct1 conf patram 将导致所有 MDSs 上的参数发生改变。。 运行一次1ct1 conf param只能更改一个参数。Root Squash 设置也可以通过 lctl set _ param暂时改变，或者通过 lctlset_param -P了永久改变。例如:mgs# lctl set param mdt.testfs-MDTO000.root_squash=\"1:0\"mgs# lctl",
        "隔离) 是通过 Lustre 多租户这一通用概念的实现，其目的在于从一个文件系统中提供分离的命名空间。Lustre Isolation 使同一文件系统上的不同用户群体能够超越正常的 Unix 权限/ACL，即使客户端上的用户可能有 root 访问权限。这些租户共享同一个文件系统，但他们相互之间是隔离的: 他们不能访问甚至看不到对方的文件，也不知道他们正在共享共同的文件系统资源。Lustre Isolation 使用了 Fileset 特性 ，只排载文件系统的一个子目录，而不是根目录。为了实现隔离，必须让客户端挂载子目录 〈只向租户展示自己的 包eset) 。为此，我们使用了nodemap 功能〈用 nodemap Hep} UID 和 GID) 。我们将一个租户使用的所有客户端归类到一个共同的 nodemap 条目下，并将该租户被限制的 fleset 分配给这个 nodemap 条目。30.3.1. 指定客户端在 Lustre 上强制执行多租户，依赖于能正确识别租户使用的客户端节点，并信任这些贡点的能力。这可以通过物理硬件和/或网络安全来实现，从而使客户端节扣拥有众所周知的NID。还可以使用Kerberos 或共享密钥，使用强认证。Kerberos 可以防止 NIDOoh, Ay BS Fe Pn eis EPL NID 来连接到服务磺。公私密钥还可以防止租户冒充，因为密钥可以链接到特定的 nodemap.30.3.2. 配置 IsolationLustre 上的 Isolation 可 以通过在 nodemap 条目上设置 fileset 参数来实现。所有属于这个 nodemap 条目的客户端将自动挂载这个 fileset，而不是挂载 root 目录。例如:mgs# lctl nodemap set fileset --name tenant1 --fileset '/dirl'因此，所有匹配tenant1l nodemap AY 4 Fin FETERKIN #822 A ol MN /dirlhy cee集合 〈fileset) ，表示这些客户端正在对子目录/dizr1进行隐式子目录挂载。注意如果文件系统中不存在定义为 fleset 的子目录，则会阻止任何属于 nodemap 的客户端挂载 Lustre.要删除 fileset 参数，只需将其设置为空字符串即可 :mgs# lctl nodemap set",
        "testfs-OSTU001 UUID 30720* - 29896 - 一 一 一8 Total allocated inode limit: 10240, total allocated block limit: 30920总共 30920 的配额限制被分配给了用户bob ，又进一步分配给了两个 OSTs。如上所示，值后面如果跟痢 * ，表明已超过配人额限制，尝试写入或创建文件将返回以下错误:1 S$ cp: writing ~/mnt/testfs/foo’: Disk quota exceeded.注意299\nLustre 文件系统操作手册 译者: 李硕值得请注意的是，每个OST 上的块配额以及每个 MDS 上的 inode 配额都会被消耗。因此，如果其中一个OST (或MDT) 上配额已用尽，客户端将可能无法创建文件，尽管其他 OSTs (a MDTs) 上还有可用配额。将配额限制设置得比最小 qunit 更低可能会使用户或组无法创建所有文件。因此建议使用软/硬限制 COST 数量和最小 qunit 大小的乘积) ©请使用1fs df -i (以及lctl get param *.*.filestotal) Miz inode 的总statist APA inode 计数，而是报告总 inode 数和已使用的 inode 数。空闲 inode 计数是由af (总 inodes - 使用的 inode) 计算得到。尽管知晓文件系统的总inode 数并不重要，但您应该知道 CREAR) 空闲 inode 数和已使用的 inode 数。Lustre软件通过操纵 inode 总计数，以准确报告其他两个值。25.6. 配额和版本互操作性要使用 Lustre 2.10 中引入的项目配额功能，必须将所有 Lustre 服务器和客户端升级到 Lustre 版本 2.10 或更高版本，项目配舍才能正靖工作。人否则，客户端将无法访问项目配额，也无法在 OSTs 上进行核算。25.7. 授权缓存和配额限制在 Lustre 文件系统中, 授权缓存并不受配额限制影响。为加速 TO ，OSTs 会向 Lustre客户端授权缓存。该缓存使数据即使超过 OSTs 配额，仍能成功",
        "mkfs.lustre fi] tunefs.lustre 不进行参数语法检查。如果 root squash 参数错误，它们将在挂载时被忽略 ，系统将使用默认值。。 Root Squash 参数将通过严格的语法检查。root squash 参数应由<dqecnum>:<dqecnum>指定。nosduash nids 参数应遵循 LNet NID 范围的语法。LNet NID 范围的语法:<nidlist :== <nidrange [ ' ' <nidrange ]<nidrange :== <addrrange '@' <net><addrrange :== '*!' |<ipaddr range |<numaddr_range><ipaddr_ range ==<numaddr_range>.<numaddr_range>.<numaddr_ range.<numaddr_ range<numaddr_range> :== <number |<expr_ list<expr list? := '[' <range expr [ ',' <range expr] ']'<range expr :== <number> |<number> '-' <number |<number> '-' <number> '/' <number><net> 2== <netname | <netname<number><netname> 2== \"lo\" | \"tcp\" | \"o2ib\"| \"ra\" | \"“elan\"<number> :== <nonnegative decimal> | <hexadecimal>注意对于使用数字地址的网络 (如 elan) ，地址范围必须由<numadqr range> 语法指和定。对于使用 卫 地址的网络，地址范围必须由<ipaddqr range>语法指定。例如，如果 elan 使用数字地址，则1.2.3.4e@elan 是错误的。340\n——Lustre 文件系统操作手册 译者:As大30.3. 隔离客户端到子目录树上Isolation 〈隔离) 是通过 Lustre 多租户这一通用概念的实现，其目的在于从一个文件系统中提供分离的命名空间。Lustre Isolation 使同一文件系统上的不同用户群体能够超越正常的 Unix 权限/"
    ]
}