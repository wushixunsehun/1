{
    "query": "如何在TH-eX的/fs2/home/wangrong/software/ABCluster/testfiles/isomer路径下提交脚本sub.sh？",
    "summaries": [
        "将所有mod文件复制到指定文件夹，并在Makefile中添加路径及fftw和openblas库。脚本示例中需设置环境变量和加载模块，确保使用正确的库路径，避免在登录节点加载库。提供两种运行abinit的脚本，一种手动配置，另一种使用模块加载。",
        "用户杜思慧分享了一个用于在ex上批量提交Abqus作业的Python程序。该脚本通过遍历以RUN_开头的文件夹，将指定的脚本复制到每个文件夹并提交作业。使用方法是将相关文件放在同一目录下并运行submit_jobs.sh脚本，实现自动化提交多个作业。",
        "文本描述了使用`yhrun -n ${nodes}`提交作业的过程，其中`nodes`实际表示进程数而非节点数。配置文件中`queue = cp2`，作业提交成功。通过修改`SchedulerSGE.py`中的代码可调试生成的临时脚本，例如注释掉删除文件的语句或添加调试输出。执行`citcoms lab257x113.cfg`后，生成并提交了包含节点数和进程数的SBATCH脚本，用于在集群上运行模拟。"
    ],
    "contents": [
        "os.remove(filename)\n69-\n70-            exitStatus = None\n71-            if (os.WIFSIGNALED(status)):\n72-                statusStr = \"signal %d\" % os.WTERMSIG(status)\n73-            elif (os.WIFEXITED(status)):\n或者在 SchedulerSGE.py 文件中加入一行语句(第62行），打印调试信息并退出。\n[maththu4@th-hpc4-ln1 schedulers]$ grep -C 5 sys.exit SchedulerSGE.py -n\n57-            filename = tempfile.mktemp()\n58-            s = open(filename, 'w')\n59-            print >>s, script\n60-            s.close()\n61-\n62:            sys.exit(\"%s: %s: %s: %s\" % (sys.argv[0], self.command, filename, script))\n63-\n64-            cmd = [self.command, filename]\n65-            self._info.log(\"spawning: %s\" % ' '.join(cmd))\n66-            status = os.spawnvp(os.P_WAIT, cmd[0], cmd)\n67-\n进入 /fs1/home/maththu4/Xiesj/ADJ/compress/code_1目录\n执行 /fs1/home/maththu4/Xiesj/ADJ/compress/AssimDepth_CitcomS-3.0.3_regional_v6.2/bin/citcoms  lab257x113.cfg",
        "【已解决】ex上批量提交abqus的python程序\n**标签**: 无标签\n**创建时间**: 2024-09-06 16:46:21\n**更新时间**: 2024-09-06 16:46:21\n**作者**: 杜思慧\n**1.用户需求**\ncd到每个RUN*文件夹内提交作业\n[chenrong@th-ex-1n@ task5]$ 1s\nex_abq22_py-2-2.sh RUN 11 RUN 12 RUN 13 submit jobs.sh\n[chenrong@th-ex-1n0 task5]$ 目\n**2.批量提交脚本**\n#!/bin/bash\n# 源脚本文件名\nscript_file=\"ex_abq22_py-2-2.sh\"\n# 目标文件夹的前缀\nfolder_prefix=\"RUN_\"\n# 复制并提交作业\nfor folder in ${folder_prefix}*; do\nif [ -d \"$folder\" ]; then\necho \"Processing folder: $folder\"\n# 复制脚本到目标文件夹\ncp \"$script_file\" \"$folder/\"\n# 提交作业\n(cd \"$folder\" && yhbatch \"$script_file\")\nfi\ndone\n**3.用法**\n将RUN*文件夹，submit_jobs.sh及ex_abq22_py-2-2.sh放到同一目录下，执行./submit_jobs.sh\n[chenrong@th-ex-ln0 task5]$ ./submit_jobs.sh\nProcessing folder: RUN_1 1\nSubmitted batch job 3497210\nProcessing folder: RUN_ 1 2\nSubmitted batch job 3497211\nProcessing folder: RUN_1 3\nSubmitted batch job 3497212\n[chenrong@th-ex-1n0 task5]$ ff",
        "是有的，把所有的mod复制到一个文件夹里，一次性指定\nfind . -type f -name \"*.mod\" -exec cp {} ./mod/ \\;\n并添加-I/thfs4/home/liangyan/abinit/abinit-10.0.5/mod  在Makefile\n同时也添加fftw 和 openblas库在Makefile\n-L/thfs4/home/liangyan/vasp/544/lib/ -lopenblas -L/thfs4/software/fftw/3.3.10-gcc11.1.0-ompi5.0.3/lib -lfftw3f -lfftw3_omp\n脚本示例，需要libopenblas.so.0 和 登录节点/usr/lib/aarch64-linux-gnu/下面的所有库，不能加载loginnode\n#!/bin/bash\n#SBATCH  -N 1\n#SBATCH  -n 56\n#SBATCH  -p th3k\nsource /thfs4/software/modules/bashrc\nexport OMP_NUM_THREADS=1\nmodule load GCC/11.1.0   openmpi/5.0.3-ch4-gcc11.1.0    fftw/3.3.10-gcc11.1.0-ompi5.0.3\nsource /thfs4/home/liangyan/abinit/openmpi/env.sh\nexport PATH=/thfs4/home/liangyan/abinit/openmpi/abinit-10.0.5/install/bin:$PATH\nexport LD_LIBRARY_PATH=/thfs4/home/liangyan/abinit/test/test/lib:$LD_LIBRARY_PATH\nmpirun -np 2  abinit  si24.abi  > log 2> err\n#module版本\n#!/bin/bash\n#SBATCH  -N 1\n#SBATCH  -n 56\n#SBATCH  -p th3k\nsource /thfs4/software/modules/bashrc\nexport OMP_NUM_THREADS=1\nmodule load abinit/10.0.5-gcc-11.1.0-ompi5.0.3\nmpirun -np 10  abinit  si24.abi  > log 2> err",
        "/maththu4/Xiesj/ADJ/compress/code_1目录\n执行 /fs1/home/maththu4/Xiesj/ADJ/compress/AssimDepth_CitcomS-3.0.3_regional_v6.2/bin/citcoms  lab257x113.cfg\n输出如下:\n/fs1/home/maththu4/Xiesj/ADJ/compress/AssimDepth_CitcomS-3.0.3_regional_v6.2/bin/citcoms: yhbatch: /tmp/tmpy_M4M6: #!/bin/sh\n#SBATCH -J NAm\n#SBATCH -p cp2\n#SBATCH -t 4:00:00\n#SBATCH -o stdout.txt\n#SBATCH -e stderr.txt\n#SBATCH -N 50\n#SBATCH -n 1800\n/fs1/home/maththu4/Xiesj/ADJ/compress/AssimDepth_CitcomS-3.0.3_regional_v6.2/bin/pycitcoms pyre-start /fs1/home/maththu4/Xiesj/ADJ/compress/AssimDepth_CitcomS-3.0.3_regional_v6.2/python/merlin-1.6.egg:/fs1/home/maththu4/Xiesj/ADJ/compress/AssimDepth_CitcomS-3.0.3_regional_v6.2/python/Cheetah-2.0rc8-py2.5-linux-x86_64.egg:/fs1/home/maththu4/Xiesj/ADJ/compress/AssimDepth_CitcomS-3.0.3_regional_v6.2/python/pythia-0.8.1.15-py2.6.egg:/fs1/home/maththu4/Xiesj/ADJ/compress/AssimDepth_CitcomS-3.0.3_regional_v6.2:/fs1/home/maththu4/Xiesj/ADJ/compress/AssimDepth_CitcomS-3.0.3_regional_v6.2/bin:/fs1/home/maththu4/Xiesj/ADJ/compress/AssimDepth_CitcomS-3.0.3_regional_v6.2/python:/fs1/software/spack/opt/linux-rhel8-cascadelake/intel-19.1.2.254/py-pythia-0.8.1.18-7rgxwnq/lib64/python2.7/site-packages:/fs1/software/spack/opt/linux-rhel8-cascadelake/intel-19.1.2.254/py-pythia-0.8.1.18-7rgxwnq/lib/python2.7/site-packages:/fs1/software/spack/opt/linux-rhel8-cascadelake/intel-19.1.2.254/python-2.7.16-gjwgufn/lib/python27",
        "yhrun -n ${nodes}\n[CitcomS.scheduler]\ncommand = yhbatch\n[CitcomS.job]\nqueue = cp2\n重新提交，作业提交成功。注1：一般nodes表示节点数，cpus或者cores表示核数、进程数，但是这里nodes其实是进程数，具体逻辑还得分析pythia中的脚本。\n(base) [maththu4@th-hpc4-ln1 code_1]$ /fs1/home/maththu4/Xiesj/ADJ/compress/AssimDepth_CitcomS-3.0.3_regional_v6.2/bin/citcoms  lab257x113.cfg\n('self.nodes:', 50.0, 'self.cores:', 1800)\nSubmitted batch job 161492\n注2：pythia的机制是读取参数，通过计算在/tmp目录下生成一个临时脚本文件，然后用yhbatch或sbatch命令提交，然后将临时文件删除；调试过程中 如果要确认脚本生成的是否正确，可以修改pythia中删除临时文件的语句，运行后查看/tmp目录下最新的临时文件内容，来进行排除。修改的模块代码为\n/fs1/home/maththu4/Xiesj/ADJ/compress/AssimDepth_CitcomS-3.0.3_regional_v6.2/python/pythia-0.8.1.15-py2.6.egg/pyre/schedulers/SchedulerSGE.py 文件中第68行，注释掉即可：\n[maththu4@th-hpc4-ln1 schedulers]$ grep -C 5 remove SchedulerSGE.py -n\n63-\n64-            cmd = [self.command, filename]\n65-            self._info.log(\"spawning: %s\" % ' '.join(cmd))\n66-            status = os.spawnvp(os.P_WAIT, cmd[0], cmd)\n67-\n68:            os.remove(filename)\n69-\n70-            exitStatus = None\n71-            if (os"
    ]
}