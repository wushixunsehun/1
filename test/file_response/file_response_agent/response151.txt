{
    "query": "用户通过脚本提交多个多节点 MPI 作业时，首个作业正常完成，后续作业运行结束后卡住并因 PMIx 集体操作超时被取消，报错信息显示与pmixp_coll_ring超时相关。请分析可能的故障原因，并给出优化方案。",
    "summaries": [
        "问题描述：在使用jorek程序进行DIII-D算例测试时，发现mpi_gather函数耗时异常，尤其在进程和线程组合变化时，时间显著增加。问题解决过程：通过谢老师的建议，尝试调整UCX_TLS参数，将原设置sm,glex改为glex后，测试结果恢复正常，mpi_gather耗时明显下降。问题分析：原先使用sm通信可能导致节点内与节点间通信交织，影响性能，而glex设置避免了这一问题，提升了MPI通信效率。",
        "3M系统在脚本中提交多个多节点作业时，出现作业无法正常结束的问题。第一个作业可正常完成，其余作业运行结束后卡住，最终被取消，并报错。错误信息显示与MPI的集体操作超时有关，涉及PMIx库的故障。问题可能与多作业并发执行时的资源竞争或通信机制有关，需优化脚本或调整作业提交方式以解决。",
        "该日志显示MPI作业在运行过程中出现错误，主要原因是`MPI_File_set_errhandler`调用失败，错误类型为无效参数，且错误处理程序不是文件错误处理程序。多个节点报告相同错误，导致作业被取消。目前可用环境为mpich/4.0.2-mpi-x-gcc10.2.0，性能较HPC系统慢3.28倍，属于正常范围。部分组合如3m gcc+openmpi和ex gcc+openmpi会出现内存不足或MPI发送错误。建议在ex系统使用debug版本的MPI库进行深入测试，并设置UCX日志级别为WARN。"
    ],
    "contents": [
        "in comm 0): Fatal error in internal_File_set_errhandler: Invalid argument, error stack:\nyhrun: Job step aborted: Waiting up to 32 seconds for job step to finish.\n‘internal_File_set_errhandler(86): MPI_File_set_errhandler(MPI_FILE_NULL, errh=0x94000000) failed\ninternal_File_set_errhandler(62): Error handler is not a file error handler\nslurmstepd: error: *** STEP 32333.0 ON cn10305 CANCELLED AT 2023-02-22T09:45:32 **x\nAbort(671707404) on node 153 (rank 153 in comm 0): Fatal error in internal_File_set_errhandler: Invalid argument, error stack:\ninternal_File_set_errhandler(86): MPI_File_set_errhandler(MPI_FILE_NULL, errh=0x94000000) failed\ninternal_File_set_errhandler(62): Error handler is not a file error handler\nAbort(671707404) on node 69 (rank 69 in comm @): Fatal error in internal_File_set_errhandler: Invalid argument, error stack:\ninternal_File_set_errhandler(86): MPI_File_set_errhandler(MPI_FILE NULL, errh=0x94000000) failed\ninternal_File_set_errhandler(62): Error handler is not a file error handler\nAbort(671707404) on node 55 (rank 55 in comm @): Fatal error in internal_File_set_errhandler: Invalid argument, error stack:\ninternal_File_set_errhandler(86): MPI_File_set_errhandler(MPI_FILE_NULL, errh=0x94000000) failed\ninternal_File_set_errhandler(62): Error handler is not a file error handler\n结论\n目前可以",
        "# Elapsed time ITERATION :          81.7971153\nN2 n16 c8\n0# Elapsed time in construct global matri           0.8272150\n0                 ## Elapsed time scale :           0.0865763\n0            ## Elapsed time mpi_gather :          98.2728141\n0                ## Elapsed time coicsr :           0.7123500\n0              # Elapsed time ITERATION :         175.4019889\n测试现象：\n在算例、节点数、所用核数相同的情况下，如果仅改变进程和线程的组合，会产生无法解释的mpi_gather部分时间的严重增加，并不知道产生问题的原因。\n问题解决过程\n谢老师建议试下imb或osu  micro  benchmark测试程序，里面有gather看看一个结点加一个进程，或是一个结点加两个进程，性能差别很大吗？\n前面测试的结果默认设置的是UCX_TLS=sm,glex\n谢老师建议使用UCX_TLS=glex\n再次测试N2 n4 c32\n0# Elapsed time in construct global matri           2.1123941\n0                 ## Elapsed time scale :           0.3156336\n0            ## Elapsed time mpi_gather :           3.4784617\n0                ## Elapsed time coicsr :           0.6965903\n0              # Elapsed time",
        "_ring_log: cn6147 [1]: pmixp_coll_ring.c:828:         status=PMIXP_COLL_RING_PROGRESS\nslurmstepd: error:  mpi/pmix_v3: pmixp_coll_ring_log: cn6147 [1]: pmixp_coll_ring.c:831:         buf (offset/size): 2147/10725\nAbort(807494415) on node 21 (rank 21 in comm 0): Fatal error in PMPI_Finalize: Other MPI error, error stack:\nPMPI_Finalize(194)..............: MPI_Finalize failed\nPMPI_Finalize(149)..............:\nMPID_Finalize(702)..............:\nMPIDI_UCX_mpi_finalize_hook(312):\nMPIR_pmi_barrier(281)...........: PMIx_Fence returned -24\nProgram received signal SIGSEGV: Segmentation fault - invalid memory reference.\nBacktrace for this error:\nslurmstepd: error: *** STEP 443932.16 ON cn6146 CANCELLED AT 2022-03-16T16:11:40 ***\nyhrun: Job step aborted: Waiting up to 32 seconds for job step to finish.\nyhrun: error: cn6147: tasks 16-31: Killed\ngdb attach打印堆栈信息\n(gdb) bt\n#0  futex_wait_cancelable (private=0, expected=0, futex_word=0x28a6a30) at ../sysdeps/nptl/futex-internal.h:183\n#1  pthread_cond_wait_common (abstime=0x0, clockid=0, mutex=0x28a69d0, cond=0x28a6a08) at pthread_cond_wait.c:508\n#2  pthread_cond_wait (cond=0x28a6a08, mutex=0x28a69d0) at pthread_cond_wait.c:638\n#3  0x000040003633bcfc in PMIx_Fence () from /lib/libpmix.so.2\n#4  0x000040003556c7c8 in",
        "0:cn6144\nslurmstepd: error:  mpi/pmix_v3: pmixp_coll_ring_log: cn6147 [1]: pmixp_coll_ring.c:778: Context ptr=0x40000c026350, #0, in-use=0\nslurmstepd: error:  mpi/pmix_v3: pmixp_coll_ring_log: cn6147 [1]: pmixp_coll_ring.c:778: Context ptr=0x40000c026388, #1, in-use=0\nslurmstepd: error:  mpi/pmix_v3: pmixp_coll_ring_log: cn6147 [1]: pmixp_coll_ring.c:778: Context ptr=0x40000c0263c0, #2, in-use=1\nslurmstepd: error:  mpi/pmix_v3: pmixp_coll_ring_log: cn6147 [1]: pmixp_coll_ring.c:787:         seq=1 contribs: loc=1/prev=0/fwd=0\nslurmstepd: error:  mpi/pmix_v3: pmixp_coll_ring_log: cn6147 [1]: pmixp_coll_ring.c:791:         neighbor contribs [2]:\nslurmstepd: error:  mpi/pmix_v3: pmixp_coll_ring_log: cn6147 [1]: pmixp_coll_ring.c:824:                 done contrib: -\nslurmstepd: error:  mpi/pmix_v3: pmixp_coll_ring_log: cn6147 [1]: pmixp_coll_ring.c:826:                 wait contrib: cn6144\nslurmstepd: error:  mpi/pmix_v3: pmixp_coll_ring_log: cn6147 [1]: pmixp_coll_ring.c:828:         status=PMIXP_COLL_RING_PROGRESS\nslurmstepd: error:  mpi",
        "【已解决】3M系统脚本内提交多个多节点作业会出现作业无法正常结束的问题\n**标签**: 3M；脚本内多作业；高通量；mpich\n**创建时间**: 2022-03-18 16:32:33\n**更新时间**: 2022-04-01 11:09:32\n**作者**: 李青峰\n3M系统脚本内提交多个多节点作业会出现作业无法正常结束的问题\n问题描述\n为适应用户的需求，在一个脚本内提交多个多节点作业，出现的现象是只有第一个提交的作业可以正常完成，其他作业都会正常运行但是在运行完成后卡在结束位置。\n报错作业的状态：\n程序运行内容完成后，卡住，ssh到节点后状态为S，持续一段时间后，作业被cancel掉，并报错\nslurm报错\nslurmstepd: error:  mpi/pmix_v3: pmixp_coll_ring_reset_if_to: cn6147 [1]: pmixp_coll_ring.c:741: 0x40000c0262d0: collective timeout seq=1\nslurmstepd: error:  mpi/pmix_v3: pmixp_coll_log: cn6147 [1]: pmixp_coll.c:281: Dumping collective state\nslurmstepd: error:  mpi/pmix_v3: pmixp_coll_ring_log: cn6147 [1]: pmixp_coll_ring.c:759: 0x40000c0262d0: COLL_FENCE_RING state seq=1\nslurmstepd: error:  mpi/pmix_v3: pmixp_coll_ring_log: cn6147 [1]: pmixp_coll_ring.c:762: my peerid: 1:cn6145\nslurmstepd: error:  mpi/pmix_v3: pmixp_coll_ring_log: cn6147 [1]: pmixp_coll_ring.c:769: neighbor id: next 0:cn6144, prev 0:cn6144\nslurmstepd: error:  mpi/pmix_v3: pmixp_coll_ring_log: cn6147 [1]: pmixp_coll_ring.c:778: Context ptr=",
        "【已解决】jorek-mpi_gather函数耗时异常\n**标签**: jorek；3F；mpi-x；ucx\n**创建时间**: 2021-09-29 18:00:08\n**更新时间**: 2021-09-30 10:59:55\n**作者**: 李青峰\n问题描述\n测试程序jorek\n测试算例：DIII-D算例\n算例分辨率：小规模\n测试环境：GCC-9.3.0 + MPI-X\n测试结果：\nN2 n4 c32\n0# Elapsed time in construct global matri           1.3131654\n0                 ## Elapsed time scale :           0.3150304\n0            ## Elapsed time mpi_gather :         163.8595194\n0                ## Elapsed time coicsr :           0.6984394\n0              # Elapsed time ITERATION :         242.5236701\nN2 n2 c64\n0# Elapsed time in construct global matri          11.8279150\n0                 ## Elapsed time scale :           3.4436696\n0            ## Elapsed time mpi_gather :           3.4990814\n0                ## Elapsed time coicsr :           0.7375358\n0              # Elapsed time ITERATION :          81.7971153\nN2 n16 c8\n0# Elapsed time in construct",
        "set_errhandler(MPI_FILE_NULL, errh=0x94000000) failed\ninternal_File_set_errhandler(62): Error handler is not a file error handler\n结论\n目前可以用的环境是mpich/4.0.2-mpi-x-gcc10.2.0，GCC/10.2.0\n性能方面迭代100次用了1小时22分钟，相比我们测试的HPC系统100次迭代用了25分钟，慢了3.28倍，属于正常范围内。\n这个算例1000E-15的模拟我在国产系统和hpc两边都同时测试下\n遗留问题\n还存在几种组合会出现问题\n3m gcc+openmpi 会报OUT OF MEMOREY\nex gcc+mpich   会有mpiisend类的报错\nex gcc+openmpi 会报OUT OF MEMOREY\n深入测试\n在ex系统使用debug版本的mpi库\nexport UCX_LOG_LEVEL=WARN\nmodule add MPI/mpich/4.0.2-mpi-x-dbg-icc19.0",
        "## Elapsed time coicsr :           0.6965903\n0              # Elapsed time ITERATION :          82.0330039\n结果一切正常\nN2 n16 c8\n0# Elapsed time in construct global matri           0.9933680\n0                 ## Elapsed time scale :           0.1297850\n0            ## Elapsed time mpi_gather :           8.2298188\n0                ## Elapsed time coicsr :           0.6902071\n0              # Elapsed time ITERATION :         105.7068243\n问题解决\n解决思路分析\n原先谢老师也有推荐试用过UCX_TLS=sm,glex，在这里如果使用sm通讯的话，在某些情况下（如gather），会有可能在每个节点多个进程时，并不是先处理节点内，而是处理节点间的进程，这样节点内和节点间的通讯交织在一起，有可能会影响性能。\n有sm的话，结点内使用共享主存通信，但会占用CPU时间，而且数据长时，访存量也较大，感觉会和网络传输有一定的重突，这可能会影响一些性能\n这也和MPICH的算法实现有关，有些算法是分层实现的，先做结点内，再用结点内leader做结点间通信，但MPICH的gather和allgather没有这样的算法实现"
    ]
}