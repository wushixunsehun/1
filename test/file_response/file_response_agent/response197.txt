{
    "query": "TH-3F 出现Requesteds run :stepnodesare busy报错，如何排查？",
    "summaries": [
        "TH-3F系统运行calypso.x和vasp时出现“Requested nodes are busy”错误，导致作业无法提交。问题可能由节点资源不足或内存分配不当引起。解决方法包括：将vasp作业核数从64改为56以减少资源占用；在yhrun命令中添加mem=100GB限制内存使用；尝试使用mpi-n编译的vasp并用mpirun调用。此外，建议设置NPAR=4、KPAR=1以优化计算效率。",
        "TH-ES系统用户在使用四个进程、每个进程占用一个GPU时，程序异常终止。问题出现在脚本中使用后台执行命令，导致yhrun任务在脚本结束后提前回收节点。解决方案是移除最后一个命令的&符号，或完善脚本监控所有进程结束再退出，确保任务正常完成。",
        "该文本描述了节点列表和相关系统状态信息，包括节点数量、核心数、分区状态等。部分节点出现异常日志，如dmesg输出显示错误信息，涉及网络设备和内存分配问题。同时，有操作记录显示取消了test预约并尝试释放节点。"
    ],
    "contents": [
        "18229-18259. 18261-18272. 18274-18334. 1833\n6-18362 18365-18366 18368-18371 18373-18379 18381-18382 . 18384-18398, 18400-18431]\n\nLroot@mn6 “1#\n取消test预约。\nCroot@mn6 “]# yhcontrol delete reservation=test\nCroot@mn6 “]# yhcontrol show reservation test\nReservation test not found\n14）放出节点\n检查节点dmesg，看看有无异常信息，执行：clush-w $nodelist\"dmesg-T\"\n[rootemn6“]# clush -wu cn[17408-17419.17421-17444.17446-17467.17469-17475.17478-17483.17485-17515.17517-17524.17526-17531.17533-175\n39.17541-17555.17557-17571.17573-17582.17584-17607.17616-17644.17646-17659.17661-17942.17953-17968.17970-17975.17977-17991.18000-180\n13.18015-18061.18063-18143.18148-18152.18154-18183.18192-18227.18229-18259.18261-18272.18274-18334.18336-18362.18365-18366.18368-183\n71.18373-18379.18381-18382.18384-18398.18400-18420.18429-18431] “dmesg -T\"\n\ncn17953: [Tue May20221 zni_dev 0000:01:00.0: _intr. new FPQ packet:\n\ncn17953: [Tue May2022] [ERR_PKT]: class=1:¥C0, type=2:¥P_ACCESS.\n\ncn17953: [Tue May2022] flit[00]: 0x0000142301100400.2801200000004000.0000618045062b49.38e2000135045081\n\ncn17953: [Tue May2022] flit[01]: 0x0000000000001647.fb74000000000000.000040000000001d.000000000061b978\n\ncn17955: [Tue May2022] zni_dev 0000:01:00.0: _wait_tp_dq_empty, after 85, DQ in TP of Yp#24\"s is not empty\n\ncn17987: [Tue May2022] zni_dev 0000:01:00.0: _wait_tp_dq_empty, after 85, DQ in TP of Yp#24-s is not empty\n\ncn17989: [Tue May2022] zni_dev 0000:01:00.0: _wait_tp_dq_empty, after 85, DQ in TP of ¥P",
        "not empty\n\ncn17989: [Tue May2022] zni_dev 0000:01:00.0: _wait_tp_dq_empty, after 85, DQ in TP of ¥P#24°s is not empty\n\ncn18119: [Tue May2022] alloc_contig_range: [780d9250, 780d9260) PFNs busy\n\ncn18119: [Tue May2022] alloc_contig_range: [780d9270, 780d9280) PFNs busy\n\ncn18119: [Tue May2022] alloc_contig_range: [780d9280, 780d9290) PFNs busy\n\ncn18119: [Tue May2022] alloc_contig_range: [780d9290, 780d92a0) PFNs busy\n\ncn18119: [Tue May2022] alloc_contig_range: [780d92a0, 780d92b0) PFNs busy\n\ncn18119: [Tue May2022] alloc_contig_range: [780d92b0。780d92c0) PFNs busy\n\ncn18004: [Tue May2022] zni_dev 0000:01:00.0: _wait_tp_dq_empty, after 85, DQ in TP of Yp#24-s is not empty\n\ncn18009: [Tue May2022] zni_dev 0000:01:00.0: _wait_tp_dq_empty, after 85, DQ in TP of ¥P#24’s is not empty\n\ncn17966: [Tue May2022] zni_dev 0000:01:00.0: _wait_tp_dq_empty, after 85, DQ in TP of ¥P#24°s is not empty\n\ncn17967: [Tue May2022] zni_dev 0000:01:00.0: _intr。new FPQ packet\n\ncn17967: [Tue May2022] [ERR_PKT]: class=1:¥C0, type=2:¥P_ACCESS\n\ncn17967: [Tue May2022] flit[00]: 0x0000142301100400.0801200000000000.00006180450623fa.88e21001350450a7\n\ncn17967: [Tue May2022] flit[01]: 0x000000000000d777",
        "【已解决】TH-3F系统计算calypso.x & vasp (Requested nodes are busy)\n**标签**: calypso.x & vasp\n**创建时间**: 2022-11-08 15:42:14\n**更新时间**: 2022-11-08 15:42:14\n**作者**: 刘栋杰\n**问题**：(Requested nodes are busy)\nTH-3F系统计算calypso.x & vasp\n运行脚本\ncaly.sh\n#!/bin/bash\n#SBATCH  job-name=lixing\n#SBATCH  output=log.out.%j\n#SBATCH  error=log.err.%j\n#SBATCH  partition=thcp1\n#SBATCH  nodes=1\nexport UCX_TLS=sm,tcp\n# module load fftw/3.3.8-gcc4.9.3  # 环境里已加载，这行注释或删除\nmodule load python/2.7.18\n./calypso.x > caly.log 2>&1  # 此行进行修改\nsubmit.sh\n#!/bin/sh\nexport UCX_TLS=sm,tcp,glex\nEXE=vasp_std # choose one vasp version to run. e.g. vasp / vasp_ncl / vasp_gam / vasp_neb ...\nkillall -9 $EXE\nyhrun -p thcp1 -n  56 exclusive -w $SLURM_NODELIST mem=100GB $EXE > log 2>&1\n如果使用64核作业还是存在被杀的情况，建议使用56核进行计算，把脚本中64改成56即可。\n报错1\nyhrun: Job 1663451 step creation temporarily disabled, retrying (Requested nodes are busy)\nyhrun: Job 1663451 step creation still disabled, retrying (Requested nodes are busy)\nyhrun: Job 1663451 step creation still disabled, retrying (Requested nodes are busy)\nyhrun: Job 1663451 step",
        "retrying (Requested nodes are busy)\nyhrun: Job 1663451 step creation still disabled, retrying (Requested nodes are busy)\nyhrun: Job 1663451 step creation still disabled, retrying (Requested nodes are busy)\nyhrun: Job 1663451 step creation still disabled, retrying (Requested nodes are busy)\nyhrun: Job 1663451 step creation still disabled, retrying (Requested nodes are busy)\nyhrun: Job 1663451 step creation still disabled, retrying (Requested nodes are busy)\nyhrun: Job 1663451 step creation still disabled, retrying (Requested nodes are busy)\nyhrun: Job 1663451 step creation still disabled, retrying (Requested nodes are busy)\nyhrun: Job 1663451 step creation still disabled, retrying (Requested nodes are busy)\n测试方案1 无效\n尝试设置作业内存， `step creation temporarily disabled, retrying (Requested nodes are busy)`的原因是，首先执行的`yhrun`命令分配了所有内存。 为了解决这个问题，首先可选（？）在`yhbatch`中指定总内存分配：\n#SBATCH mem=120GB   #此参数暂时先不设置，不设置默认使用全部，物理内存128G，去除其他内存开销，限制124G可正常提交作业。\nvasp脚本\nyhrun 增加 mem=100GB # vasp使用内存限制在100GB，可根据需求调整\n测试方案2 无效\nkill vasp 进程后进行等待\n#!/bin/sh\nexport UCX_TLS=sm,tcp,glex\nEXE=vasp_std # choose one vasp version to run. e.g. vasp / vasp_ncl / vasp_gam / vasp_neb ...\nkillall -9 $EXE\nsleep 1s\nyhrun -p thcp1 -n  56 exclusive -w $SLURM_NODELIST mem=100GB $EXE >",
        "[已解决] TH-ES系统用户程序异常结束问题\n**标签**: ES系统，GPU\n**创建时间**: 2021-12-03 14:51:32\n**更新时间**: 2021-12-24 09:17:26\n**作者**: 傅浩\n**问题**：TH-ES系统用户计算任务异常结束问题\n问题描述\n用户反应程序在使用单节点单进程的情况下可以正常执行，但在使用四个进程，每个进程使用一个GPU设备时，会异常终止，使用脚本信息如下：\n#!/bin/bash\n# test.sh\n./QPM001 &\n./QPM002 &\n./QPM003 &\n./QPM004 &\n任务提交命令为：\nnohup yhrun -N 1 -p TH_GPU ./test.sh &\n输出文件正常，无任何报错信息。\n问题分析\n`yhrun`命令返回的时`test.sh`命令的执行结果，而在`test.sh`文件中，采用后台方式执行了四条命令，每个命令均已后台方式执行，在四条命令执行后，系统判断`test.sh`执行完成，`yhrun`在脚本退出后会判断任务执行结束，因此会回收计算节点，导致任务异常终止。\n解决方案\n移除`test.sh`脚本中最后一行的`&`符号，即修改后的脚本内容为：\n#!/bin/bash\n# test.sh\n./QPM001 &\n./QPM002 &\n./QPM003 &\n./QPM004\n**注意**：这种解决的前提假设为最后一个命令是最后一个结束的命令，如果之前的命令计算时间超过最后一个命令，则在QPM004结束之后尚未计算完成的命令仍然会异常退出。\n比较完善的解决方法是，在提交四个进程的命令后，后台监控命令执行情况，如果所有命令均已经退出，则退出整个脚本，最终解决方案如下：\n#!/bin/bash\n# test.sh\n./QPM001 2>&1 | tee QPM002.log &\n./QPM002 2>&1 | tee QPM002.log &\n./",
        ", 18192-18227 , 18229-18259 . 18261-18272 . 18274-18334 , 18336-18362 . 18365-18366 . 18368-18371.\n18373-18379 18381-18382 . 18384-18398 . 18400-18431] NodeCnt=971 CoreCnt=15536 Features=(null) PartitionName=(null) Flags=MAINT .SPEC_NOD\nES\n\nTRES=cpu=15536\n\nUsers=root Groups=(null) Accounts=(null) Licenses=(null) State=ACTIVE BurstBuffer=(null) Watts=n/a\n\nMaxStartDelay=(null)\n\nCroot@mn6 “J# yhi -n cnl17408-17419,17421-17444 17446-17467 17469-17475 .17478-17483,17485-17515 17517-17524 17526-17531 .17533-17539.\n17541-17555 17557-17571 17573-17582 ,,17584-17607 17616-17644 , 17646-17659, 17661-17944 17946-17947 17949-17968 17970-17975 17977-17995.\n18000-18013 18015-18061 18063-18143, 18148-18152, 18154-18187, 18192-18227, 18229-18259 18261-18272, 18274-18334, 18336-18362. 18365-18366.\n18368-18371 18373-18379 , 18381-18382, 18384-18398 18400-18431] -p ALL\n\nPARTITION AVAIL TIMELIMIT NODES STATE NODELIST\n\nALLup infinite | 971 drain$ |cnl17408-17419 17421-17444, 17446-17467 17469-17475 17478-17483 17485-17515 17517-17524 1752\n6-17531.17533-17539 \"1784121771.17573-17582.17584-17607.17616-17644.17646-17659.17661-17944.17946-17947.17949-17968.1797\n0-17975 17977-17995 18000-18013. 18015-18061, 18063-18143. 18148-18152. 18154-18187 ,18192-18227 _ 18229-18259. 18261-18272. 18274-18334. 1833\n6-18362 18365-18366 18368-18371 18373-18379 18381-18382 . 18384-18398, 18400-18431]",
        "vasp_neb ...\nkillall -9 $EXE\nsleep 1s\nyhrun -p thcp1 -n  56 exclusive -w $SLURM_NODELIST mem=100GB $EXE > log 2>&1\n无效\n测试方案3\nmpi-n编译vasp，使用mpirun调用，可正常运行，计算速度略慢。\n#!/bin/sh\n#SBATCH exclusive\n#SBATCH -w $SLURM_NODELIST\n#SBATCH mem=80GB\nexe=/thfs1/home/yanggc/5.4.4-opblas-gcc9.3.0-mpi-x/mpi-n/vasp_std\nexport UCX_TLS=sm,tcp\nkillall -9 vasp_std\nsleep 1s\nmpirun -np 64  $exe > log 2>&1\nVASP参数设置\n建议设置:   其中单节点测试中，32~56核，以下参数最优。\nNPAR = 4\nKPAR = 1"
    ]
}