{
    "query": "存在任务运行时中断的问题，请检查原因。",
    "summaries": [
        "EX系统CESM2.1.3在无报错情况下出现中断，但可正常断点续算。建议使用指定脚本提交作业，包含SBATCH参数设置及环境变量导出，以解决该问题。",
        "系统出现进程引擎故障，作业被信号9终止。MPI版本问题可能导致错误，建议替换.bashrc中的编译器和MPI路径。作业运行中可能因系统维护被挂起，需手动终止并续算。程序因编译与运行环境不一致导致AVX支持错误，应移除-xHOST/-xAVX选项。存储配额默认为500G软限制、1T硬限制，超限将无法写入。IO错误可能由存储压力或OST满载引起。ls命令卡顿可能因节点负载高、网络延迟或存储恢复。GPU无法识别可能因PCIe连接松动。",
        "系统报告无法将11个节点划分为10个部分，多次出现相同错误信息。MPI_Topo_test函数调用失败，提示无效的通信器，错误源于空通信器。任务在cn2984节点上被取消，步骤519328.0于2022-02-24 17:27:43终止。"
    ],
    "contents": [
        "stack:\nMPIDI_CH3I_Progress(176): progress engine failure)\nslurmd[cn1368]: *** STEP 2796179.0 KILLED AT 2015-10-12T11:27:12 WITH SIGNAL 9 ***\nslurmd[cn1368]: *** STEP 2796179.0 KILLED AT 2015-10-12T11:27:12 WITH SIGNAL 9 ***\nA：该错误提示一般是由mpi版本导致。解决方法：使用/vol6/source.sh中的内容替换原~/.bashrc中关于intel编译器、mpi的路径。\nQ:任务提交运行后，有时在还未达到队列的时间天数期限时，运行的程序已“停止工作”（输出文件没有更新），但是通过作业查询命令（yhq）查看，作业看起还在R运行。\nA:遇到这个情况，请您及时手动杀掉您的作业，从断掉的地方接着续算就可以了。\nQ:输出的slurm文件中是如下数据：yhrun: got SIGCONT。我在天河服务器用户手册上没找到这条数据的解释。请问这条数据代表什么意思?\nA:这个是系统管理员临时维护系统，为了避免影响用户的作业，而把用户的作业挂起了出现的提示了。\nQ程序运行报错：Fatal Error: This program was not built to run in your system. Please verify that both the operating system and the processor support Intel(R) AVX. yhrun: error: cn2375: task 0: Exited with exit code 1\nA：该错误说明程序的编译时环境和运行时环境不一致，即程序编译时使用了支持AVX的选项，运行时的硬件环境不支持该AVX优化。\n一般这种情况发生是由于用户在编译程序时加入-xHOST/-xAVX选项（或是在安装软件时，系统自动读取到登陆节点上CPU的flag支持avx，故在编译软件时加入了-xHOST），那程序就会根据登陆节点的CPU配置信息进行优化编译，然而程序的运行是在计算节点上，计算节点的CPU配置信息可能不支持AVX，就与登陆节点不同，就会报",
        "【已解决】EX系统CESM2.1.3无报错中断\n**标签**: 无标签\n**创建时间**: 2024-06-28 09:50:00\n**更新时间**: 2024-06-28 09:50:11\n**作者**: 张天奇\n如果出现CESM2.1.3程序本身无任何报错而中断，同时还能正常断点继续续算，可以考虑用如下脚本提交作业：\n#!/bin/bash\n#SBATCH -p cp6\n#SBATCH -N 10\n#SBATCH -n 560\nexport GLEX_USE_ZC_RNDV=0\n./case.submit",
        "“lfs quota –g username /vol-th”查看账号配额会看到已使用存储的数字旁边有一个“*”号，状态“4w1d23h59m57s”表示一个月的倒计时，如果用户在倒计时结束前将使用存储清理到500G以下，则存储状态恢复正常，否则，用户存储无法写入；如果用户使用存储大于1T，用户会无法写入。\nQ：磁盘无法写入，报“quota error”错误\nA：这是由于用户使用存储或文件数超过配额设定，需要用户对数据进行清理到磁盘配额软限制以下方可继续使用。\nQ：作业运行提示“forrtl: Input/output error”\nA：可能是存储某一时刻压力较大，造成IO错误，请您重新提交作业。\nQ：作业运行时报错：forrtl: No space left on device，forrtl: severe (38): error during write, unit 12，但是同样的作业再次提交时可能就正常运行完成。\nA：该问题主要由文件系统中某一OST存储已满导致，请联系与您对接的工程师或系统管理员。\nLustre文件系统由若干IO服务器（Object Storage Services）和Object Storage Targets(OST)组成。当对一个文件进行读写操作时，为了提高IO效率，文件系统会自动将该文件的读写操作分割成多个，在多个OST上并发实现。如果在该过程中，使用到的某一OST出现问题，就会发生读写错误。\nQ:我使用ls命令查看目录下的文件，可是一直停留下那里，没有显示。\nA:遇到这个问题，您可以等待一会，再重新使用ls命令查看目录文件。\n原因之一可能是TH-HPC的登录节点负载比较重，造成使用终端命令受到影响；原因之二可能是用户客户端的网络负载比较重，出现比较严重的网络延迟；原因之三可能是TH-HPC系统的存储正在进行恢复调整。\n6.6 GPU使用问题\nQ：使用CUDA toolkit编译程序后，在gpu_test分区提交作业，运行时提示错误：no CUDA-capable device is detected\nA：可能原因有二种情况：\n原因之一可能是分配到的该计算结点上用于连接CPU与GPU的PCIe总线松动，导致无法找到device。解决方法：在提交作业时",
        "not subdivide           11 nodes by          10\nM_divide: can not subdivide           11 nodes by          10\nM_divide: can not subdivide           11 nodes by          10\nM_divide: can not subdivide           11 nodes by          10\nM_divide: can not subdivide           11 nodes by          10\nM_divide: can not subdivide           11 nodes by          10\nM_divide: can not subdivide           11 nodes by          10\nM_divide: can not subdivide           11 nodes by          10\nM_divide: can not subdivide           11 nodes by          10\nM_divide: can not subdivide           11 nodes by          10\nFatal error in PMPI_Topo_test: Invalid communicator, error stack:\nPMPI_Topo_test(114): MPI_Topo_test(MPI_COMM_NULL, topo_type=0xffffe4d12494) failed\nPMPI_Topo_test(67).: Null communicator\ndistr:  one band on    1 cores,   10 groups\nslurmstepd: error: *** STEP 519328.0 ON cn2984 CANCELLED AT 2022-02-24T17:27:43",
        "时加入了-xHOST），那程序就会根据登陆节点的CPU配置信息进行优化编译，然而程序的运行是在计算节点上，计算节点的CPU配置信息可能不支持AVX，就与登陆节点不同，就会报上面的提示错误。\n解决方法：编译时去掉-xHOST/-xAVX选项，使用其他优化选项。\n备注：-xHost will cause icc/icpc or icl to check the cpu information and find the highest level of extended instructions support to use.\n天河登陆节点ln1、ln2、ln3上的CPU配置信息flag均无avx，ln8、ln9上均有avx。\n如果在ln8或ln9上安装软件时，configure后一定要检查下编译flag是否加入了-xHOST，如果加入，请修改对应的configure文件，将-xHOST删除\n6.5 存储问题\nQ：登陆系统时提示“Some errors happened when getting quota info”\nA：这是由于在对系统进行调整时登陆结点quota服务没有启用导致，对用户本身的操作和作业不会有影响，管理员会定时对此进行调整，请放心使用。\n解决方法：这是因为登陆节点quota服务没有启用，对用户本身的操作和作业不会有影响。\n值班人员每天定时对vol-th、WORK、vol6的quota进行检查，尤其是存储出现问题后（如ost重启），quota会异常关闭，以vol-th为例重启方式如下：\nlfsquotaoff -ug /vol-th\nlfsquotaon -ug /vol-th\nQ：默认的磁盘配额是多少？磁盘配额的含义是什么？\nA：为了合理利用有限的存储资源，目前中心对用户默认进行存储软限制500G，存储硬限制1T，文件数软限制100万，文件数硬限制200万的磁盘配额限制。以磁盘存储为例说明软、硬限制的含义，文件数软、硬限制的含义与其一样。用户使用存储低于500G时，存储状态正常；当用户使用存储介于500G和1T之间时，用户配额异常，通过“lfs quota –g username /vol-th”查看账号配额会看到已使用存储的数字旁边有一个“*”号，状态“4w1d23h59m57s”表示一个月的倒计时，如果用户在倒计时结束前将使用"
    ]
}