{
    "query": "用户在提交批处理作业时，若需查看作业状态或取消任务，应使用哪些命令？请列出关键命令及其功能?",
    "summaries": [
        "文本主要介绍了使用 `pestat` 和 `seff` 命令查看作业信息的方法。`pestat` 可用于查询作业的详细状态，支持按用户、分区、作业ID等条件筛选，并提供多种选项控制输出内容。`seff` 用于查看特定作业的运行数据，如状态、节点数、CPU 使用情况等。注意：普通账号仅能查看自身作业。",
        "资源管理系统手册介绍了SBATCH命令的多个选项及其对应的环境变量，如--cpu_bind、--verbose、--partition等。同时，详细说明了作业运行时设置的环境变量，如SLURM_JOBID、SLURM_NODELIST、SLURM_TASKS_PER_NODE等。此外，还描述了yhbatch用于提交批处理作业，yhbcast用于将文件传送到作业节点，以及yhcancel用于取消作业。这些工具和变量帮助用户管理和控制作业的执行。",
        "yhbatch 是用于提交批处理作业的命令，支持多种选项来控制作业的资源分配、执行方式和依赖关系。例如，--overcommit 允许每个处理器运行多个任务，-o 指定输出文件，--partition 选择资源分区，--time 设置运行时间限制，-p 指定分区，--dependency 定义作业依赖关系等。此外，还支持资源限制传递、作业重新排队、节点共享、临时磁盘空间设置等功能。环境变量也可用于设置选项，且命令行选项优先级高于环境变量。"
    ],
    "contents": [
        "node.e --tmp=VMB最少临时磁盘空间。。 -u, --usage显式简短帮助信息并退出。e -—-uid=userDAF user 的号份提交和运行作业，而不是执行 yhbatch 的用户。执行 yhbatch的用户号份将用于检查目标分区的访问权限。例如，root 用户可以使用此选项在RootOnly 分区中以普通用户寻份运行作业。wser 可以是用户名或数值用户 UID。e -V, --version显示版本信息并退出。e -v, --verbose增加 yhbatch MIHAILA. AMS Sv. SAUL F OLEACEAEe -w, --nodelist=node name listte OR Ta EAT A EAE BEY VA AG SP BE 2% BEB] CT cn[1-5,7,..)) Fax o MUZE FEY FEAST A AE CAR «BREA A 4 II AS BARE家资源管理系统重新排序。e --wckey=wckey作业使用的 wekey. AACE CPE TrackWCKey=no (ik), UCT KAR II.e --wrap=command stringyhbatch 将把指定的命令串包闭成一个简单的“sh”shell 脚本，并把该脚本提交到控制进程。当使用 --wrap 时，不能在命令行指定脚本名字和参数。e -x, --exclude=node name list不要将指定的节点分配给作业。186\n16.4. yhbatch输入环境变量在司动时，yhbatch 将读取并处理如下环境变量中设置的选项。请注意，环境变量中的选项将轿盖批处理脚本中的选项，而命令行选项将履盖环境变量中的选项。。 SBATCH ACCOUNT: 同 -A, --account。 SBATCH_ACCTG_FREQ: 同 --acctg-freq。 SLURM_CHECKPOINT: 同 --checkpoint。 SLURM_CHECKPOINT_DIR: [A] --checkpoint-dir。 SBATCH_CONN_TYPE: [A] --conn-type。 SBATCH_CPU_BIND: 同 --cpu_bind。 SBATCH DEBUG: 同 -v, --verbose。 SBATCH DISTRIBUTION: 同 -m,",
        "将在每个节点上创建的文件的完整路径。dest 应该位于节点局部的文件系统上，而非节点间共享的文件系统上上。注意，并行文件系统可能提供比 yhbcast 更好的性能，尽管实际性能与文件大小，并行度，以及网络类型有关。选项。 -C, --compress压缩要传送的文件。。 -f, --force如果目标文件已存在，则答换之。e -F, --fanout=numberFa RE CUPRA IN YE ELIS a RE. A IIE 8.。 -p, --preserve保留原文件的修改时间，访问时间以及模式。e。 -S, —--size=sizeTAKE MCE) TEIN EA INERAZD. size AT EHDA k Bk om 478 KB 或 MB GRAA字节)。此大小受限于舍和信和范围限制以保持展好性能。对于内存有限的系统可能需要设置此选项值。191\n资源管理系统手册e -t, --timeout=secondsfa EH BEE PD. RA EL “yhcontrol show config”显示的 MessageTimeout值。在计算节点磁盘 1/O 性能低时可能需要设置为较大值。e -v, --verbose在 yhbcast 执行过程中显示详细事件日志。e -V, --version显示 yhbcast 版本信息。环境变量yhbcast 的某些选项可通过环境变量设置，如下。注意: 命令行选项总是履盖环境变量选项量选项。。 SBCAST_COMPRESS: --compresse SBCAST_FANOUT: --fanout=numbere SBCAST FORCE: --force。 SBCAST_PRESERVE: --preservee SBCAST SIZE: --size=sizee SBCAST_TIMEOUT: --timeout=seconds192\n16.5. yhbcast示例使用一个批处理脚本，将本地文件 my. prog 传送到各节点的/tmpy/my.prog，然后执行该程序。LA命令:> yhbatch --nodes=8 my.jobyhbatch: jobid 12345 submitted脚本内容:> cat my. job#!/bin/bashyhbcast my.prog /tmp/my.progyhrun /tmp/my. prog193\n资源管理系统手册16.6 yhcancel名字yheancel: 回作业或作业步发送信",
        "long2    alloc  36  36   32.16*   256000   241724  1242058 ustb_dcf\ncn1939           long2    alloc  36  36   32.41*   256000   248302  1242058 ustb_dcf\n注意：如果是普通账号权限，只能查看自己的作业\n使用说明：\n$ pestat -h\nUsage: pestat [-p partition(s)] [-P] [-u username] [-g groupname] [-a accountname]\n[-q qoslist] [-s/-t statelist] [-n/-w hostlist] [-j joblist] [-G] [-N]\n[-f | -F | -m free_mem | -M free_mem ] [-1|-2] [-d] [-S] [-E] [-T] [-C|-c] [-V] [-h]\nwhere:\n-p partition: Select only partion <partition>\n-P: Include all partitions, including hidden and unavailable ones\n-u username: Print only jobs of a single user <username>\n-g groupname: Print only users in UNIX group <groupname>\n-a accountname: Print only jobs in Slurm account <accountname>\n-q qoslist: Print only QOS in the qoslist <qoslist>\n-R reservationlist: Print only node reservations <reservationlist>\n-s/-t statelist: Print only nodes with state in <statelist>\n-n/-w hostlist: Print only nodes in hostlist\n-j joblist: Print only nodes in job <joblist>\n-G: Print GRES (Generic Resources) in addition",
        ", --overcommit183\n资源管理系统手册WEE AUR. AY, yhbatch 为每个处理器分配一个任务。指定 --overcommit时，将显式允许每个处理器上运行多个任务。然而，每个节点上运行的任务数不超过 MAX TASKS PER NODE 个任务。。 -o, --output=filename pattern将批处理脚本的标准输出写到 filename pattern 指定的文件中。文件名规范清参见--input 选项。。 --open-mode=append|truncate使用附加模式或截断模式打开标准输出和标准错误文件。缺省值由系统配置文件中的 JobFileAppend 参数指定。e -P, --denpendency=dependency_list延迟运行作业，直到指定的依赖关系被满足。dependency_1stf 形如 type:jobid|:jobid|[tpe:7obid[:7opid]j。多个作业可以共享使用相同的依赖关系，这些作业也可以属于不同的用户。作业提交后可以通过 yhcontrol 命令修改依赖关系。一 after: jobid|:jobid...]此作业可在指定的作业开始执行后运行。一 afterany: jobid|:jobid...]此作业可在指定的作业终止后运行。一 afternotok: jobid|:jobid...]此作业可在指定的作业失败〈非 0 退出码，节点失效，超时等) 后运行。一 afternotok: jobid|:jobid...]此作业可在指定的作业成功〈运行结束，退出码为 0) 后运行。— singleton此作业在之前运行的具有相同名字和用户的作业终止后运行。e。 -p, --partition=partition name在指定分区中分配资源。如未指定，则由控制进程在系统默认分区中分配资源。。 --propagate[=rlimits]将那些可修改〈软) 资源限制传递到计算贡点并应用到作业任务进程。如未指定riizp2its，则传递所有资源限制。资源管理系统文持如下资源名字《尽管有些系统不文持茶些选项):— ALL: 所有资源限制184\n16.4. yhbatch— AS: 进程的最大地址空间— CORE: core 文件大小— CPU: 最多 CPU 时间— DATA: 进程的数据段大小— FSIZE: 所创建",
        "16.4. yhbatch— AS: 进程的最大地址空间— CORE: core 文件大小— CPU: 最多 CPU 时间— DATA: 进程的数据段大小— FSIZE: 所创建文件的大小— MEMLOCK: 锁定内存的大小— NOFILE: 打开文件数目— NPROC: 可用进程数目— RSS: 最大物理内存— STACK: 栈大小-Q, --quiet不要输出一般信息。错误信息仍将显示。--qos=qos作业的服务质量。QOS 可以在记账数据库中为每个用户/系统/帐号 association 定义。当系统配置参数 AccountingStorageEnforce 包含“qos”时，用户将仅能使用为其 association 定义的 QOS。—-requeue在节点失效时将作业重新排队。当作业被重新排队后，批处理脚本从头开始执行。参见 —-no-requeue 选项。配置参数 JobRequeue 控制系统上的缺少行为。--reservation=name从指定的预约中为作业分配资源。-s, --share作业可以与其它运行作业共享节点。这可以导致更早分配资源，以及更高的系统利用率，但是由于竞争节点内的资源，应用的性能可能会下降。缺省的共享/互斥行为与系统配置相关。-t, --time=time作业运行的总时间限制。如果请求的时间限制超过分区的时间限制，作业将保持在排队状态。缺省的作业运行时间限制是分区的时间限制。当到达运行时间限制时，作业的所有作业步的所有任务都将被发送 SIGTERM 和 SIGKILL 信号。两个信号之185\n资源管理系统手册间的时间间隔有系统配置参数 KillWait 指定。时间限制设置为 0 表示没有时间限制。可用的时间格式包括“7pzpautes” “minutes:seconds”, “hours:minutes:seconds”,“days-hours”, “days-hours:minutes”, VU “ days-hours:minutes:seconds”。 —-tasks-per-node=n[a] --ntasks-per-node.e --tmp=VMB最少临时磁盘空间。。 -u, --usage显式简短帮助信息并退出。e -—-uid=userDAF user 的号份提交和运行作业，而不是执行",
        "hostlist: Print only nodes in hostlist\n-j joblist: Print only nodes in job <joblist>\n-G: Print GRES (Generic Resources) in addition to JobID\n-N: Print JobName in addition to JobID\n-f: Print only nodes that are flagged by * (unexpected load etc.)\n-F: Like -f, but only nodes flagged in RED are printed.\n-m free_mem: Print only nodes with free memory LESS than free_mem MB\n-M free_mem: Print only nodes with free memory GREATER than free_mem MB (under-utilized)\n-d: Omit nodes with states: down drain drng resv maint boot\n-1: Default: Only 1 line per node (unique nodes in multiple partitions are printed once only)\n-2: 2..N lines per node which participates in multiple partitions\n-S: Job StartTime is printed after each jobid/user\n-E: Job EndTime is printed after each jobid/user\n-T: Job TimeUsed is printed after each jobid/user\n-C: Color output is forced ON\n-c: Color output is forced OFF\n-h: Print this help information\n-V: Version information\nseff\n使用 seff 命令可以查看作业的具体运行数据，例如：\n$ seff 1241896\nJob ID: 1241896\nCluster: tianhe\nUser/Group: zhenggang4/zhenggang4\nState: COMPLETED (exit code 0)\nNodes: 1\nCores per node: 36\nCPU Utilized: 00:00:00\nCPU Efficiency: 0.00% of 00:00:00 core-walltime\nJob Wall-clock time: 00:",
        "A] --conn-type。 SBATCH_CPU_BIND: 同 --cpu_bind。 SBATCH DEBUG: 同 -v, --verbose。 SBATCH DISTRIBUTION: 同 -m, --distribution。 SBATCH EXCLUSIVE: 同 --exclusive。 SBATCH IMMEDIATE: 同 -1, --immediate。 SBATCH_JOBID: 同 --jobid。 SBATCH_JOB_ NAME: 同 -J, --job-name。 SBATCH MEM BIND: 同 --mem_bind。 SBATCH_NETWORK: 同 --network。 SBATCH_NO_REQUEUE: [A] --no-requeue。 SBATCH_OPEN MODE: [fA] --open-mode。 SBATCH_OVERCOMMIT: 同 -0, --overcommit。 SBATCH_PARTITION: 同 -p, --partition。 SBATCH_QOS: [A] --gos。 SBATCH_TIMELIMIT: 同 -t, --time187\n资源管理系统手册输出环境变量资源管理系统将在批处理脚本的环境中设置如下变量:。SLURM CPU _BINDWEA --cpu_bind 选项的值。。 SLURM JOB ID《〈以及 SLURM_JOBID)作业的 JobID.。SLURM JOB CPUS_PER_ NODE当前节点上此作业可用的处理器数。请注意，select/linear 插件将整个节点分配给作业，因此此值表示节点上的全部 CPU 数目。select/cons_res 插件将单个处理器分配到作业，因此此数值表示此节点上分配给作业的处理器数目。e SLURM JOB DEPENDENCYWEA --dependency 选项的值。。 SLURM_JOB_NAME作业名字。。SLURM JOB_NODELIST (以及 SLURM_NODELIST)分配到作业的节点列表。。 SLURM_JOB_NUM_NODES (以及 SLURM_NNODES)分配到作业的节点数目。。SLURM MEM BIND设置为 --mem_bind 选项的值。。 SLURM_TASKS_PER_NODE每个节点上要启动的任务数。该值由逗号分隔，顺序同 SLURM_NODELIST。如果两个以上节点有相同的任务数，则该数目后跟“(x#)” 其中“#",
        "TASKS_PER_NODE每个节点上要启动的任务数。该值由逗号分隔，顺序同 SLURM_NODELIST。如果两个以上节点有相同的任务数，则该数目后跟“(x#)” 其中“#”是重复次数。例uu, “SLURM_TASKS PER NODE=2(x3) ,1”表示前三个节点执行两个任务，第四个节点执行一个任务。。 SLURM NTASKS_PER CORE所请求的每 core 任务数。仅在指定了 --ntasks-per-core 选项时设置。e SLURM NTASKS PER NODE所请求的每节点任务数。仅在指定了 --ntasks-per-node 选项时设置。188\n16.4. yhbatche SLURM NTASKS PER SOCKET所请求的每 socket 任务数。仅在指定了 --ntasks-per-socket 选项时设置。。 SLURM_RESTART_COUNT如果作业由于系统失效被重新启动或被显式重新排队，此变量将被设置为作业重启动的次数。e SLURM SUBMIT DIR执行 yhbatch 的目录。示例(eg 在命令行指定批处理脚本文件名。批处理脚本中指定了 1 分钟的运行时间限制。$ cat myscript#!/bin/sh#SBATCH --time=1srun hostname |sort$ sbatch -N4 myscriptsbatch: Submitted batch job 65537$ cat slurm-65537.outhostihost2host3host4189\n资源管理系统手册从标准输入读取批处理脚本。$ sbatch -N4 <<EOF> #!/bin/sh> srun hostname |sort> EOFsbatch: Submitted batch job 65541$ cat slurm-65541.outhostihost2host3host4190\n16.5. yhbcast16.5 yhbcast名字yhbcast: 传送文件到分配给作业的节点ieyhbcast [options| source destfadsyhbcast 用于将文件传送到分配给当前活跃作业的所有节点。此命令仅应在批处理作业脚本中，或资源分配后派生的 Shell 中执行。souwrce AHIR EM SHEA. dest 应议是将在每个节点上创建的文件的完整路径。dest 应该位于节点局部的文件系统上，而非节点间共享的文件系统上上。注意，并行文件系统可能提供比 yhbcast 更好的性能，尽管实际性能与"
    ]
}