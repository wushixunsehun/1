{
    "query": "用户在使用HPC4系统的Lustre分布式存储时需要注意哪些关键事项？请说明软限制和硬限制的具体含义。",
    "summaries": [
        "在Lustre文件系统中，使用RAID设备时需注意以下几点：避免使用带有板载缓存的PCI适配卡，以免在HA故障转移时导致数据不一致；格式化RAID设备时，应确保IO请求与底层RAID匹配，以提升性能；对于RAID 5、6或1+0，需指定参数优化元数据布局；计算stripe width时，应使条带宽度匹配IO大小，避免“读-修改-写”操作。此外，建议将OST日志放在单独设备上，使用RAID 1阵列，并确保内存足够存储日志副本。连接SAN至Lustre时需考虑扩展性、成本及安全风险，直接访问存储可能带来安全隐患。网络端口绑定为可选配置。",
        "Lustre 文件系统中的授权缓存允许数据在超过 OST 配额时仍能成功写入，这可能导致配额限制失效。通过调整客户端参数可缓解此问题。Lustre 还提供配额统计信息，用于监控和分析配额操作性能。此外，Lustre 支持与分层存储管理 (HSM) 的集成，使文件可在高速缓存的 Lustre 文件系统和较慢的 HSM 存储之间同步。",
        "Lustre 文件系统需要足够的 RAM 和存储配置以确保性能和可靠性。非故障切换配置下，8 个 OST 的 OSS 至少需要 32 GB RAM，而故障切换配置则需至少 48 GB RAM，每个 OST 需要 6 GB 内存。网络方面，Lustre 使用专用 TCP/IP 子网或 InfiniBand 网络，需正确配置 LNet 模块。存储建议使用 RAID，MDT 推荐 RAID 1 或 RAID 10，OST 则推荐 RAID 6 以提供双重冗余。RAID 配置需考虑性能与成本平衡，并配备 RAID 监控和热备磁盘以提高可靠性。"
    ],
    "contents": [
        "需要昂贵的\" 读 -修改 -写\" 流程。以下为计算 stripe_width 的公式:stripe width blocks = chunk blocks* number of data disk= 1 MB,61\nLustre 文件系统操作手册 译者:As大其中 number of data _ disk 不包括 RAID 奇偶校验人磁盘 〈对RAID S，有一个奇偶校验人磁盘,，对RAID 6则是两个)。如有果RAID 配置不允许 chunk_blocks 恰好匹配 1 MB, lll选择接近 IMB (而不是更大) 的stripe width blocks.stripe width blocksh} {Hh WW 须 等 于chunk blocks *number of data disks) (4. {% #£ ff AA RAID 5 BK RAID 6 时 Wi 48xEstripe width blocks#X, RAID1+0 则不需要。在文件系统设备 (/dev/sde) 上运行 -reformat，为底层 ldiskfs 文件系统将指定 RAID配置。--mkfsoptions \"other _ options -E stride=chunk blocks, stripe width=stripe width block\"例如，如采一个合 6 个磁盘的RAID 6，配置有4个数据和 2 个奇偶校验磁斑，那么 chunk blocks <= 1024KB/4 = 256KB。由于数据磁盘的数量为 2 的指数，条带宽度恰好为1MB。6.4.2 外部日志的参数设置如果您已经配置了 RAID 阵列并直接使用它作为 0ST，则其中包换了数据和元数据。为了获得更好的性能，我们建议将 OST 日志放在一个单独的设备上上，创建一个小型RAID 1 阵列，并将其作为 OST 的外部日志。在一般的 Lustre S/F ASH, DUA OST 日志最大为 1GB，默认的 MDT 日志大小最大为4GB ，以处理高频率事务而不阻赛日志刷新。此外，因日志在 RAM 中有副本，须确保有足够的内存来保存所有日志副本。文件系统日志选项为 mkfs.lustre，使用 --mkfsoptions",
        "授权缓存和配额限制在 Lustre 文件系统中, 授权缓存并不受配额限制影响。为加速 TO ，OSTs 会向 Lustre客户端授权缓存。该缓存使数据即使超过 OSTs 配额，仍能成功写入，并重写配额限制。顺序是:1. 用户将文件写入 Lustre 文件系统。2. 如果 Lustre 客户端拥有足够的授权缓存，则会向用户返回\"成功\" 并安排在 OSTs 上的写入操作。3. 因为 Lustre 客户已经向用户返回\"成功\"，OST 不能使这些写入失败。由于授权缓存，写入操作将始终重新配额限制。例如，如果您为用户 A 设置 400GB的配额并使用 IOR 从一批客户端为用户 A 写入数据，则您将写入比 400GB 多得多的数据，最终导致超出配额的错误 (EDQUOT)。注意授权缓存对配额限制的作用可以得到缓解，但无法消除。运行以下命令减少客户端上及数据最大值 〈最小值为 1MB) :* lctl set param osc.*.max dirty mb=825.8. Lustre 配额统计信息Lustre 软件可以收集监控配额活动的统计信息，如特定期间发送的配额 RPC 类型、完成RPC 的平均时间等。这些统计信息对于衡量 Lustre 文件系统的性能很有用。300\nLustre 文件系统操作手册这ay43) ACen} A CAS min time，max time和sum time值组成。配额事件sync_acq reqsync _rel reqasync_acq reqasync _rel reqwait_for_blk_quota(Iquota_chkquota)wait_for_ino quota(Iquota_chkquota)wait_for_blk_quota(Iquota_pending commit)wait_for_ino quota(Iquota_pending commit)wait for pending blk_quota_req(qctxt_wait_pending dqacq)wait for pending ino_quota_req(qctxt_wait_pending dqacq)nowait for pending blk_quota_req(qctxt_wait_pending dqacq)说明配额从设备发送获取配额的请求并等待回复。配额从设备发送释放配额的请求并等待回复。配额从设备发送获取配额的请求但不等待回复。",
        "quota_req(qctxt_wait_pending dqacq)说明配额从设备发送获取配额的请求并等待回复。配额从设备发送释放配额的请求并等待回复。配额从设备发送获取配额的请求但不等待回复。配额从设备发送释放配额的请求但不等待回复。在数据写入 OSTs 之前，OSTs 将检查剩余块配额是否足够。这将在 l1quota_chkquota Pe aH完成的。在 MDS 上创建文件之前，MDS 检查剩余的 inode配额是否足够。这将在 Iquota_chkquota 函数中完成的。将块写入 OST 后，会更新相关配额信息。这是在Iquota_ pending commit 函数中完成的。文件完成创建后，会更新相关配额信息。这是在Iquota_pending commit 函数中完成的。在MDS 或0STs 上，有一个线程随时为特定UID/GID 发送块配额请求。其他线程发送配额请求则需要等待。这是在qctxt_wait pending dqacq 函数中完成的。在MDS 上，有一个线程随时为特定 UID/GID发送 inode 配额请求。其他线程发送配人额请求则需要等待。这是在qctxt_wait pending dqacq 函数中完成的。在MDS 或OSTs 上，有一个线程随时为特定UID/GID 发送块配额请求。当线程进入qctxt_wait pending dqacq 时，无需再等待。这是在 qctxt wait pending dqacq301\n——ULDLustre 文件系统操作于册 译者:这ay配额事件 说明PACA SE WHY 0nowait for pending ino quota req 在MDS 上，有一个线程随时为特定 UID/GID(qctxt_ wait pending dqacq) 发送 inode 配额请求。当线程进入qctxt wait pending dqacq 时，无需再等待。这是在 qctxt wait pending dqacq函数中完成的。quota_ctl {# FA lfs ssetquota ，1Lfs quota 等将生成 quota_ctl 统计信息。adjust_qunit 每当 qunit 发生调整时，都将被记录。25.8.1. 解析配额统计信息AC AMZ ze Ot at Lustre 文件系统性能的重要指标",
        "文件系统和内核则至少还需要附加的 1GB。因此，对于非故障切换配置，使用8 个OST 的 OSS “HY RAM 至少应为 32 GB。在 OSS 上添加额外的内存将提高读取小的、须频迷访问的文件的性能。58\nLustre 文件系统操作手册 译者:As大而对于故障切换配置，RAM 至少应为 48 GB。在故障切换配置中，每个QOSS 上有4个 OST 很正常。当 OSS 没有处理任何错误时，额外的 RAM 将被用作读取缓存。根据经验来说，可使用8 GB 的基础内存加上每个OST 3 GB 的内存。在故障切换配置中，每个 OST 需要 6 GB 内存。5.6. Lustre 文件系统的网络实现作为高性能文件系统，Lustre 文件系统对网络产生了大量的负载。因此,每个 Lustre服务器和客户端的网络接口通常都为文件系统数据交互所用。通常情况下使用专用的TCP/IP 子网，但也可使用其他网络硬件。个典型的 Lustre 文件系统实现可能包括:。Lustre 服务袁的高性能后端网络，通销是 mnfiniBand (IB) 网络。。 一个更庞大的客户端网络。。 连接两个网络的 Lustre rs atLustre 网络和路由配置及管理通过 Lustre 网络 (neb 模块中的/etc/modprobe.d/lustre.conf 配置中指定相关参数。配置 Lustre 网络，要逐一完成以下步骤:1. 识别运行有 Lustre 软件的所有设备和用来进行 Lustre 文件系统交互的网络接口。这些设备将形成 Lustre 网络。网络是一组直接相互通信的节点。Lustre 软件包括 Lustre 网络驱动硕 (LNDs) 以文持各种网络类型和硬件。配置网络的标准规则适用于 Lustre 网络。例如，两个不同子网(tcp0 和tcpl) 上的两个 TCP 网络被认为是两个不同的 Lustre 网络。2. 如果需要路由，请确定要用于路由网络之间的通信的节反。如果您使用多个网络类型 ，那么您将需要一个路由需。任何具有适当接口的节氮都可以在不同的网络硬件类型或拓扑之间为 Lustre 网络",
        "要用于路由网络之间的通信的节反。如果您使用多个网络类型 ，那么您将需要一个路由需。任何具有适当接口的节氮都可以在不同的网络硬件类型或拓扑之间为 Lustre 网络 (LNeb 数据生成路由 ------WW RA AY以是服务右、客户端或独立路由器。LNet 可将消息路由到不同的网络类型 CM, TCP到 InfiniBand) 或跨越不同的拓扑 〈如桥接两个 mnfiniBand 或TCP/P 网络)。3. 识别网络接口，将其包括在 LNet 内或排除在外。如果没有特别指定，LNet 将使用第一个可用接口或预定义的网络类型作为默认值。LNet 不应该使用的接口〈如管理网络或卫- overIB) 可被排除。包含哪些网络接口或者哪些网络接口排出在外可通过内核模块参数网络 networksAll ip2nets 来指定。4. 为了简化具有复杂网络配置网络的设置，确定一个集群范围的模块配置。对于大型集群，您可以通过在每个节氮上的 lustre.conf 文件配置一个单一的、统一NABER A ATA ABC EI ZA CE59\nLustre 文件系统操作手册 译者:As大注意我们建议您使用 IP 地址而不是主机名，以便增加调试日志的可读性，并且更容易地调试多个接口配置。第六章 Lustre 文件系统上的存储配置注意强烈建议将 Lustre 文件系统的硬件存储配置为RAID。Lustre 软件并不文持文件系统级别的元余，因而需要 RAID 来防御磁盘故障。6.1. 为MDTS 和 OSTs 选择存储设备。Lustre 体系结构允许使用任何类型的块设备作为后端存储。但这些设备的特性差别很大〈苑其是在故隐情况下) ，因此影啊配置的选择。6.1.1 元数据目标 (MDT)在MDT 上的IO 通贡主要是数据的少量读写，因而我们建议您为MDT 存储配置RAID 1。如果您需要的容量比一个磁盘大，我们则建议您配置 RAID 1+ 0或RAID 10。6.1.2 对象存储服务名 (OST)通过下面的快速测算，我们知道如无其他宛余，大型集群应配置为RAID 6 IiiRAID 5 是不可接受的。假设一个2 PB 文件系统",
        "4GB ，以处理高频率事务而不阻赛日志刷新。此外，因日志在 RAM 中有副本，须确保有足够的内存来保存所有日志副本。文件系统日志选项为 mkfs.lustre，使用 --mkfsoptions 参数。例如:--mkfsoptions \"other options -j -J device=/dev/mdJ\"创建一个外部日志，请在 OSS 上的每个 OST FAT LA FLERE:1. 创建一个 400 MB (或更大) 的日志分区 (建议使用RAID 1，在本例中，/dev/sdb 是RAID 1 设备)。2. 在分区上创建一个日志设备。运行:[oss#] mke2fs - b 4096 -O journal dev /dev/sdb journal size日志大小以 4096 FERAL. YH, IGB 的日志大小为 2602144。3. 创建 OST。在本例中，被用作 OST 的 /dev/sde 是RAID 6 设备，运行:[oss #] mkfs.lustre --ost... \\--—mkfsoptions =\"-J device=/dev/sdb1\" /dev/sdc4. 正常装入 OST.02\nLustre 文件系统操作手册这ay6.5. 连接 SAN 至 Lustre 文件系统根据您的集群规模和工作负载情况，您可能希望通过 SAN 连接至 Lustre 文件系统。在连接之前，请孝感以下因素:。在许多 SAN 文件系统中，客户端在更新时，会单独分配块或 node，并将之锁定。Lustre 文件系统的设计避免了这种在块和 inode 上的高度竞争。。Lustre 文件系统具有高度可扩展性，可拥有非常多的客户端。SAN 交换机无法扩FES, Tn SAN 的平均端口成本通肖比其他网络要高。。 FRIES Pain LA direct-to-SAN 方式接入的文件系统存在安全风险，这是因为客户端能够读 SAN 磁盘上的任何数据，行为不端的客户端可通过多种方式破坏文件系统，如不佳的文件系统、网络或其他内核软件，粳糕的布线，损坏的内存等等。风险伴随直接访问存储的客户端数量的增加而成倍增加。第七章网络端口绑定设置注意网络痛口绑定为可选",
        "阵列中才文持)，否则阵列的电源中断可能会导致无序写入或写丢失，或者奇偶校验损坏或元数据损坏，从而导致数据丢失。MDS 或 0SS ace hy) PCI 适配夯卡上如宁有板载读或写回缓存，那么在高可用人性(HA) 故障转移配置中是不安全的，因为这将导致节氮之间的不一致，可能立即或最终损坏文件系统。不应使用此类设备，或应条用板载缓存。如有果司用了回写绥存，则需要在阵列断电后进行文件系统检查。这也可能导致数据ERAU, Sm SCTE BY, FTE DOE Se EAE Ge, Ble 28 DBS(FAB StF BAK TE6.4. Idiskfs RAID 设备的格式化选项当在 RAID 设备上格式化 ldiskfs 文件系统时，确保 IO 请求与底层 RAID 匹配是有好处的。这避免了 Lustre 的 RPC 产生不必要的和磁静操作，从而大大降低性能。在格式化OST或MDT时，可使用--mkfsoptions 参数以指定额外的参数项。对于RAID 5, RAID 6或RAID 1+0 存储，在 --mkfsoptions 下指定以下参数可改进文件系统元数据的布局，确保不是所有的分配位图都存储在单一的磁盘上:-E stride = chunk blockschunk_blocks 变量以 4096 字市块为单位,含义是在移动到下一个磁盘前，写入到单个磁盘的连续数据量。它同时也被叫做 RAID 条带大小。它适用于MDT 和 OST 上的文件系统。6.4.1 计算 mkfs 的文件系统参数为了获得最好的性能，建议使用含 5 个或 9 个磁盘的RAID 5 或合 6 个或 10 个磁盘的RAID 6，每个磁盘上都有一个不同的控制荐。条带宽度应为最佳的最小IO 大小。理想情况下，RAID 配置应使得 IMB 的 Lustre RPC 可正巧匹配甲个RAID 条带，而不需要昂贵的\" 读 -修改 -写\" 流程。以下为计算 stripe_width 的公式:stripe width blocks = chunk blocks* number of data disk= 1",
        "quota_ctl 统计信息。adjust_qunit 每当 qunit 发生调整时，都将被记录。25.8.1. 解析配额统计信息AC AMZ ze Ot at Lustre 文件系统性能的重要指标。正确解析这些统计信息可以帮助您诊断配质问题，并做出一些调整，以提高系统性能。例如，如果您在 OST 上运行此命令:lctl get_param lquota.testfs-OSTO000.stats您将得到类似以下的结果:Snapshot time 1219908615.506895 secs.usecsasync _acq req 1 samples [us] 32 32 32async rel req 1 samples [us] 555nowait for pending blk quota _req(qctxt wait pending dgacq) 1 samples [us] 2\\2 2quota_ctl 4 samples [us] 80 3470 4293adjust_qunit 1 samples [us] 70 70 70在第一行中，snapshot _ time 表明获得这些数据的时间。其余行列出了配额事件及其相关数据。在第二行中async acq req事件发生一次。此max timefilsum time分别为32、32 和32。单位是微秒 〈hs) 。在第五行中quota ctl事件发生四次。此max time和sum time分别为80、3470 和 4293。单位是微秒 (us) 。TWalin!Be 件 的min time,{in|beni件 的min time,302\nLustre 文件系统操作手册这ay(在 Lustre 2.5 中引入)第二十六章分层存储管理 (HSMD26.1. 简介Lustre 文件系统可以使用一组特定的功能绑定到分层存储管理 (HSM) 解决方案。这些功能可将 Lustre 文件系统连接到一个或多个外部存储系统 〈通消是 HSM) 。通过绑定到HSM 解决方案，Lustre 文件系统可以作为高速缓存在这些速度较慢的 HSM 存储系统的前端工作。Lustre 文件系统与 HSM 的集成提供了一种机制，使文件同时存在于 HSM 解决方案中，并在 Lustre 文件系统中存有元数据条目可供检查。读取，写入或截断文件将触发文件数据从 HSM 存储中取回到 Lustre 文件系统中。将文件复制到",
        ".2 对象存储服务名 (OST)通过下面的快速测算，我们知道如无其他宛余，大型集群应配置为RAID 6 IiiRAID 5 是不可接受的。假设一个2 PB 文件系统 (2000 个容量为1TB 的磁盘) 的磁盘平均故障时间 (MT TF )为 1000 天。这意味痢失败率的期望值是 2000/1000 = 2 个磁往/天。10% 的磁盘市宽的修复时间则是 1000 GB/10 MB per sec = 100,000 秒，也就是大约 1K.而对于一个含 10 个磁盘的RAID S，在重建的1 天当中，相同阵列中的第二个磁盘失败的几率大约是 9/1000 或每天 1%。50 天之后，RAID 5 阵列则有 50% 的几率出现双重故障，导致数据丢失。因此，配置RAID 6 或其他的双重奇偶校验算法来提供足够的元余来存储 OST 非常必要为了获得更好的性能，我们建议您使用4个或8 个数据磁盘和一个或两个奇偶磁盘来创建 RAID 阵列。相比较拥有多个独立的RAID 阵列，使用更大的 RAID 阵列将会对性能造成负面影响。为最大化小规模 IO 请求的性能，存储可配置为RAID 1+0，但同时这将增加成本、降低容量。60\nLustre 文件系统操作手册 译者:As大6.2. 可靠性为增强可靠性，我们建议: (AY RAID 监控软件以快速检测出故障的磁盘，并及时将其替换从而避免双重故障和数据丢失; 使用热备份磁盘，以避免重建时的延迟。我们还建议及时备份文件系统的元数据。6.3. 性能权衡在写操作不是全条带宽度的情况下，回写 RAID 存储控制的缓存可极大地提高多种RAID 阵列的写性能。不笠的是，除非 RAID 阵列配备的缓存有电池文持 (只有在一些价格较高的硬件 RAID 阵列中才文持)，否则阵列的电源中断可能会导致无序写入或写丢失，或者奇偶校验损坏或元数据损坏，从而导致数据丢失。MDS 或 0SS ace hy) PCI 适配夯卡上如宁有板载读或"
    ]
}