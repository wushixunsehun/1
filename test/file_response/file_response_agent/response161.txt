{
    "query": "如何调整HPC4系统上的作业fu至最高级？",
    "summaries": [
        "本文介绍了在HPC4上运行Fluent-UDF的步骤，包括创建文件夹并拷贝相关文件、修改run.jou文件设置路径和参数、替换libudf中的C文件并调整配置、以及修改fluent-singularity.sh脚本以适配计算环境。整个流程涵盖了文件准备、配置修改和作业提交等关键环节。",
        "本文档为HPC4系统上运行AlphaFold2的使用说明。用户需从共享目录拷贝运行脚本至个人目录，修改脚本权限，并根据需求调整输入输出路径、模型、GPU卡号及数据库类型等参数。最后通过yhbatch命令提交任务。结果文件将生成在指定目录中。",
        "在HPC4上成功部署了2D_FD_Dunzhu_Li_2014等多个程序。首先加载CUDA/10.2和GCC/5.5.0环境，然后修改源码中的gpu.h文件，将cudaThreadSynchronize()替换为cudaDeviceSynchronize()。接着在不同目录下修改Makefile中的编译器为nvcc，并执行make进行编译。最初使用HPC4默认的GCC编译后出现段错误，改用GCC/5.5.0后问题解决，程序可正常运行。"
    ],
    "contents": [
        "【已解决】HPC4运行fluent-udf\n**标签**: 无标签\n**创建时间**: 2021-11-26 17:44:36\n**更新时间**: 2022-06-21 08:42:23\n**作者**: 杜思慧\n**使用说明**\n1. 新建文件夹，将计算相关文件拷贝到新建的文件夹\nmkdir udf\ncd udf\n[dush@th-hpc4-ln1 udf]$ ls\nfluent.cas  fluent.dat  fluent.dat.h5  fluent-singularity.sh  libudf  run.jou  sub.sh  viv_prara_chen_gai.c\n2. 对run.jou进行修改\njournal 文件中一般需要设置好如case文件、data文件的绝对路径，以及计算结果文件的绝对路径等参数，下面是一个参考的样例（以 ; 开始的行为注释行）。\n;Read cas file\nrc fluent.cas\n;Read data file\nrd fluent.dat\n;compiled udf\n/define user-defined compiled-functions load \"libudf\"\n;initialize\n;solve/initialize/initialize-flow\n;set autosave frequency for data file\nfile/autosave/data-frequency 100\n;not overwrite existing files\nfile/autosave/overwrite-existing-files no\n;set the time-step\nsolve/set/time-step 1\n;Calculate 500 iterations\nsolve/dual-time-iterate 500 20\nwc fluent-f.cas\nyes\nwd fluent-f.dat\nyes\n!sh cleanup-fluent*\n;Exit FLUENT\nexit\nyes\n3. 修改udf配置\n（1）将 libudf/src 文件夹中的c文件替换实际需要的c文件\n（2）修改 user.udf 文件的 FLUENT_INC 变量路径及CSOURCES：\n进入lnamd64文件夹，分别进入2d_host、2d_node文件夹（ls命令为显示目录内容），修改user.udf文件（指令：vi user.udf），将CSOURCES=后边替换成需要编译的C文件名称，将FLUENT_INC=改为正确的",
        "【已解决】HPC4系统alphafold2运行使用说明\n**标签**: HPC4 alphafold2\n**创建时间**: 2021-11-12 17:30:53\n**更新时间**: 2021-11-18 15:53:44\n**作者**: 吴琪\nHPC4系统alphafold2运行使用说明\n运行脚本拷贝\n从共享目录下拷贝运行脚本到自己目录下\n(base) [wuqi@th-hpc4-ln0 al]$ cp /fs1/software/alphafold/job.sh ./\n(base) [wuqi@th-hpc4-ln0 al]$ cp /fs1/software/alphafold/run_alphafold.sh ./\n修改脚本权限\n(base) [wuqi@th-hpc4-ln0 al]$ chmod 755 ./*\n修改输入参数\n打开job.sh文件，修改输入数据，输出数据的路径等运行参数\n#!/bin/bash\nmodule add CUDA/11.4.2\nyhrun run_alphafold.sh -d /fs1/software/alphafold/data \\\n-o /fs1/home/wuqi/test/rcsb_pdb_6ZXQ \\ 输入序列路径\n-m model_1 \\ 运行使用model，全部model为 model_1，model_2，model_3，model_4，model_5\n-f /fs1/home/wuqi/software/fasta_seq/rcsb_pdb_6ZXQ.fasta \\ 输出结果路径\n-a 1,2 \\ 使用GPU卡\n-t 2021-08-19 \\ 使用数据库标签\n-p \"reduced_dbs\" 使用数据库类型 可选为\"reduced_dbs\" 和 \"full_dbs\"\n任务提交\n(base) [wuqi@th-hpc4-ln0 al]$ yhbatch -N 1 -p gpu ./job.sh\n结果文件\n(base) [wuqi@th-hpc4-ln0 rcsb_pdb_6ZXQ]$ ll\ntotal 20736\n-rw-rw-r 1 wuqi wuqi 13559919 Nov 18 09:54 features.pkl\ndrwxrwxr-x 2",
        "2d_host、2d_node文件夹（ls命令为显示目录内容），修改user.udf文件（指令：vi user.udf），将CSOURCES=后边替换成需要编译的C文件名称，将FLUENT_INC=改为正确的fluent安装路径\n举例：\nCSOURCES= viv_prara_chen_gai.c\nHSOURCES=\nFLUENT_INC=/fs1/home/dush/ansys190/ansys190/v190/fluent\nGPU_SUPPORT=off\n4. 修改fluent-singularity.sh，对分区，节点数，cpuspernode，journalfile，cttype及exe进行修改\n#!/bin/bash\n# file: fluent-singularity.sh\n#\n#  Usage:\n#     1. change '-N' '-p' 'cpuspernode' 'journalfile'\n#     2. yhbatch fluent.sh\n#\n#SBATCH -N 1                                        # NODE number\n#SBATCH -p cp1                                      # Partition name( use 'yhi' to find your parititon)\ncpuspernode=36                                      # CPU cores per node\njournalfile=run.jou                                # type your journal file name,such as run.jou\ncttype=2d                                           # compute type,include:2d , 2ddp ,3d ,3ddp\nexe=$HOME/ansys190/ansys190/v190",
        "【已解决】HPC4部署2D_FD_Dunzhu_Li_2014等多个程序\n**标签**: 无标签\n**创建时间**: 2024-11-13 14:09:39\n**更新时间**: 2024-11-13 14:09:39\n**作者**: 杜思慧\n**1.加载环境**\nmodule add CUDA/10.2 GCC/5.5.0\n**2.部署**\n#修改源码中的gpu.h，将cudaThreadSynchronize() 替换为 cudaDeviceSynchronize()\ncd 2D_FD_Dunzhu_Li_2014/psv-nobox\nmake clean\nmake\ncd FD-2D/PSV\n#修改Makefile CC=/fs1/software/cuda-10.2/bin/nvcc\nmake clean\nmake\ncd FD-2D/SH_bak\n#修改Makefile CC=/fs1/software/cuda-10.2/bin/nvcc\nmake clean\nmake\n**3.报错及解决**\n使用HPC4默认的GCC进行编译后运行会报段错误，选择GCC/5.5.0重新编译后可以运行",
        "# compute type,include:2d , 2ddp ,3d ,3ddp\nexe=$HOME/ansys190/ansys190/v190/fluent/bin/fluent      # set ansys install directory and command\n#\n# set environment\n#\nyhcontrol show hostnames $SLURM_NODELIST|tee nodefile-$SLURM_JOB_ID && awk '{print $0\":\"'$cpuspernode'}' nodefile-$SLURM_JOB_ID > hostfile-$SLURM_JOB_ID\nexport cores=$(($(wc -l nodefile-$SLURM_JOB_ID |cut -d ' ' -f 1)*$cpuspernode)) && echo \"Total used cpu number is $cores\"\necho \"The computing type is $cttype\"\necho \"The journal file name is $journalfile\"\necho \"$cpuspernode per node would be used\"\n#\n# create script\n#\nCMD=$SLURM_SUBMIT_DIR\necho \"Create singlarity job file : singularity-$SLURM_JOB_ID\"\ncat > singularity-$SLURM_JOB_ID << EOF\n#!/bin/bash\ncd $SLURM_SUBMIT_DIR\nexport PATH=$HOME/ansys/ln/bin:\\$PATH\nexport LD_LIBRARY_PATH=$HOME/ansys/ln/lib64:\\$LD_LIBRARY_PATH\nexport MPIRUN_OPTIONS=\"-prot\"\nexport LC_ALL=C\n$exe -g $cttype -t$cores -cnf=./hostfile-$SLURM_JOB_ID -pdefault -i $journalfile\necho \"123\"\n#cd libudf\n#make clean\n#make\n#cd ..\n$exe -g $cttype -t$cores -cnf=./hostfile-$SLURM_JOB_ID -pdefault -i $journalfile\nEOF\n#\n#"
    ]
}