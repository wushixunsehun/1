{
    "query": "Lustre文件系统中活跃的 MDS 数量是多少？",
    "summaries": [
        "Lustre 文件系统内存需求包括客户端、MDS 和 OSS。客户端推荐至少 2GB RAM。MDS 内存需求取决于客户端数量、目录大小和负载，每个文件约占用 2KB 内存。默认日志大小为 4096MB，故障切换时需翻倍。计算示例显示，1024 个客户端、12 个交互式客户端和 600 万文件需至少 16GB RAM。OSS 内存需求包括服务线程、读取缓存等，推荐最小 32GB RAM，用于 8 个 OST 设备。额外内存可提升性能。",
        "Lustre 是一个高性能、可扩展的分布式文件系统，支持 POSIX 标准，具备高可用性、数据完整性及多种网络协议。它利用 ZFS 实现存储可靠性，支持 RDMA 等高速网络，提供原子操作和数据校验以确保一致性。Lustre 支持细粒度元数据锁定、多 MDT/OST 扩展、配额管理、文件布局控制及灾难恢复工具。其组件包括 MGS、MDS、MDT 和 OSS，支持 NFS/CIFS 导出，并基于开源 GPL 2.0 许可。",
        "Lustre 2.11 引入了 MDT 的 Lazy 大小 (LSoM) 功能，用于在 MDS 上存储文件大小信息，以减少客户端访问多个 OST 获取文件大小的开销。LSoM 数据可能不准确，但能提升性能。用户可通过 `lfs getsom` 命令查看 LSoM 数据，并通过 `lfs som_sync` 同步数据。LSoM 适用于策略引擎等场景，可加快文件大小获取速度。此外，Lustre 2.11 还引入了文件级冗余 (FLR)，允许将文件数据存储在多个 OST 上，提高系统容错性和读取性能。FLR 通过延迟写入实现，主镜像更新后，其他镜像需手动同步。"
    ],
    "contents": [
        "分配 RPC-sized MB JIO 的缓冲区，因此不需要通过 IO 请求来分配和释放缓冲区。。0SS 读取缓存: OSS 读取缓存提供 OSS 数据的只读缓存，使用浓规的 Linux 页面缓存来存储数据。与 Linux 操作系统中的常规文件系统的缓存一样，0SS 读取绥存使用所有可用的物理内存。适用于 MDS 的计算也同样适用于从 OSS 访问的文件，但因为其负载分布在更多HY OSSs “RE, (AlKKZE MDS 下列出的锁、inode 缓存等所所需的内存数也分散在这些OSS 节点上。由于这些内存需求，应将下面的计算作为确定 OSS 节点所需的最小RAM 大小。5.5.3.1 计算 OSS 内存需求4 8 “+ OST fy OSS 的推荐最小RAM 大小计算如下: Linux 内核与用户空间和守护进程的内存 = 1024 MB 以太网/TCP 23K / REWER DX (16 MB * 512 线程)= 8192 MB 1024MB 日志大小*8个OST 设备=8192MB 每个OST IO 线程的 16 MB 读/写操作缓存* 512个线程 = 8192 MB 2048 MB 文件系统读取缓存* 8 OST = 16384 MB 1024 * 4 核客户端*1024 个文件/核* 2kB/文件 = 8192MB 12 个交互式客户端* 100,000 个文件* 2kB/文件 =2400MB 2,000,000 文件〈附加工作集) * 2kB/文件 = 4096MB DLM 锁+ 文件系统元数据总量=31072MB 每个OSS DLM 锁+ 文件系统元数据= 31072MB/4 OSS = 7768MB {iti值) 每个OSS RAM 最小需求=32 GB 〈估值)预先分配的绥神区就消耗了大约 16 GB，文件系统和内核则至少还需要附加的 1GB。因此，对于非故障切换配置，使用8 个OST 的 OSS “HY RAM 至少应为 32 GB。在 OSS 上添加额外的",
        "李硕“字闻粒度文件和细粒度元数据锁定: 许多客户端可以同时读取和修改相同的文件或目录。Lustre 分布式锁管理种 (LDLM) 确保了文件系统中所有客户端和服务融之间的文件是一致的。其中，MDT 锁管理带负责管理node 权限和路径名锁。个OST 都有其目己的锁管理釉，用于锁定存储在其上的文件条带，其性能与文件系统大小相关。“配额: 用户和组配额可用于 Lustre 文件系统。“容量增长: 通过向群集添加新的 OST 和 MDT，可以不中断地增加 Lustre 文件系统的大小和集群总惠宽。“受控文件布局: 可以在每个文件，每个目录或每个文件系统基础上配置跨 OST 的文件布局。这人允许了在单个文件系统中调整文件 IO 以适应特定的应用程序要求。Lustre 文件系统使用RAID-0 进行条带化并可在 OST 之间调和空间使用大小。。网络数据完整性保护: 从客户端发送到 OSS 的所有数据的校验和可防止数据在传输期间被损坏。”MPII/O: Lustre 架构具有专用的 MPI ADIO 层，优化了并行 VO 以匹配基础文件RRR> NFS 和 CIFS 导出: 可以使用NFS (通过 Linux knfsd 或 Ganesha) 或 CIFS(通过 Samba) 将 Lustre 文件重新导出，使其可以与非 Linux 客户端 〈如Microsoft*Windows 和 *Apple *Mac OS X *) 共享。\"灾难恢复工具: Lustre 文件系统提供在线分布式文件系统检查 〈LFSCK) ，当发生主要文件系统错误的情况下恢复存储组件乙间的一致性。Lustre 文件系统在存在文件系统不一致的情况下也可以运行，而 LFSCK 可以在文件系统正在使用时运行，因此 LFSCK 不需要在文件系统恢复生产之前完成。。 性能监视: Lustre 文件系统提供了多种机制来检查性能和进行调整。。开放源代码: Lustre 软件已获得在 Linux 操作系统上运行的 GPL 2.0 许可证。1.2. Lustre 组件Lustre 软件的安装包括管理服务器 (MGS) 和一个或多个与 Lustre 网络 (LNet)",
        "已获得在 Linux 操作系统上运行的 GPL 2.0 许可证。1.2. Lustre 组件Lustre 软件的安装包括管理服务器 (MGS) 和一个或多个与 Lustre 网络 (LNet) 互连的 Lustre 文件系统。Lustre 文件系统组件的基本配置如下图所示:34\nLustre 文件系统操作手册ayManagement Server (MGS) Management Target MGT}Metadata Server (MDS) Metadata Target (MILT }© Sy Co-located MS and MDS share storageLustre clientsEn Ethermet or InfiniBand Network © ®oss 1©. 8Object Storage Servers(OSSs}图 1: Lustre component1.2.1. 管理服务器 (MGS)MGS 存储集群中所有 Lustre 文件系统的配置信息，并将此信息提供给其他 Lustre组件。每个 Lustre target 通过联系 MGS 提供信息，而 Lustre 客户通过联系 MGS 获取信起Ju OMGS 最好有目己的存储空间，以便可以独立管理。但同时，MGS 可以与 MDS 共址并共享存储空间，如上图中所示。1.2.2 Lustre 文件系统组件每个 Lustre 文件系统由以下组件组成:“元数据服务器 (MDS) - MDS 使存储在一个或多个 MDT 中的元数据可供 Lustre客户器使用。每个 MDS 管理 Lustre 文件系统中的名称和目录，并为一个或多个本地 MDT 提供网络请求处理。“元数据目标 (MDT) - 每个文件系统至少有一个MDT。MDT 在 MDS 的附加存储上存储元数据〈例如文件名，上目录，权限和文件布局)。虽然共享存储目标上的MDT 可用于多个 MDS，但一次只能有一个 MDS 可以访问。如采当前 MDS 发生web, Wl A MDS 可以为MDT 提供服务，并将其提供给客户中。这被称为MDS故障切换。分布式命名空间环境 (DNE) 可文持多个 MDT。除保存文件系统根目录的主 MDT之外，还可以添加其他 MDS “it, fs MDS “aA AY MDT 来保存文件系统的子目录树。35\nLustre 文件系统操作手册 eke",
        "上的内存大小。MDS 上没有所谓当前打开文件的\" SUR\",为它们只与给定客户端的接口相链接。每个客户端进程最多能打开几王个文件，这取决于它的ulimit。默认情况下，ldiskfs MDT 单个文件的最大条市数为 160 个 OST。在格式化MDT 时使用--mkfsoptions=\"-O ea_ inode\"可增加该值，或在格式化 MDT 后使用une2fs -O ea _ inode来启用并改变它。56\nLustre 文件系统操作手册这ay5.5. 确定内存需求5.5.1 客户端内存需求推荐使用至少2 GB RAM 的客户端。5.5.2 MDS 内存需求MDS 内存需求由以下因素决定:。 客户最大数量。 目录大小。 服务器上负载情况MDS 使用的内存数量与系统中有多少客户端，以及饭们在工作集中使用多少文件有关。它主要是由客户端一次可以容纳的锁数量决定。客户端持有的锁的数量因服务需上的负载和闪存可用性而异。交互式客户端有时可以容纳超过 10,000 个锁。在 MDS 上，每个文件大约使用2KB 的内存，包括 Lustre 分布锁管理融 (DLM) 锁和当前文件的内核数据结构。与从存储读取数据相比，将文件数据放在缓存中可以提高元数据性能 10fia ESMDS 内存需求包括:“文件系统元数据: 需要合理数量的RAM 以支持文件系统元数据。虽然文件系统元数据的数量没有硬性的限制，但如果有更多的RAM 可用，则可以减少通过磁盘了O 检索元数据的频率。“网络传输: 如果您使用的是 TCP 或其他使用系统内存来发送或接收缓训的网络传输，那么也须将这些内存需求考虑在内。“日志大小: 默认情况下，用于每个 Lustre ldiskfs 文件系统的日志大小为 4096 MB.这占用了每个文件系统的 MDS A EAI Cat) RAM.。 故障切换配置: 如果 MDS 节氮用于从另一个节点进行故障转移，那么每个日志所需的RAM 应翻倍。当主服务融发生故障时，备份服务硕才有能力处理附加的负载。5.5.2.1 计算 MDS 内存需求默认情况下，文件系统日志",
        "一个节点进行故障转移，那么每个日志所需的RAM 应翻倍。当主服务融发生故障时，备份服务硕才有能力处理附加的负载。5.5.2.1 计算 MDS 内存需求默认情况下，文件系统日志使用4096MB。额外的 RAM 用于存储更大的工作集组存文件数据，通稼它并不处于活跃状态，但应保持热度以提升访问速度。在没有锁的情况下，每个文件保存在缓存中大约需要 1.5 KB 内存。例如，在 MDS 上的单个MDT，有 1024 个客户靖、12 个交互节氮、一个 600 万个文件的工作集〈其中 400 万个文件在客户端缓存上):57\nLustre 文件系统操作手册 译者:As大操作系统开销 = 1024 MB 文件系统日志=4096MB 1024 * 4 4% Fe PF oh * 1024 个文件/核* 2KB = 4096MB 12 个交互式客户端* 100,000 个文件* 2KB = 2400 MB 2,000,000文件〈附加工作集) * 1.5kB/文件=3096 MB因此，具有这种配置的MDT 的最小需求是至少 16 GB 的RAM。但是，额外的闪存可以显者提高性能。对于包含 100 万或更多文件的目录，更多的内存大有神益。例如，当一个客户端要随机访问 1000 万个文件中的一个时，有附加的内存来进行缓存可以大大地提高性能。5.5.3 OSS AER在为一个 OSS 下氮规划硬件时，须考虑 Lustre 文件系统中几个组件的内存使用情Die CU: 上日志、服务线程、文件系统元数据等)。愉外，也须考虑 OSS 读取缓存特性，因其在 OSS 贡点上绥存数据时将消耗内存。除上文中提到的 MDS 内存需求外，OSS 的内存要求包括:。 服务线程: OSS 节点上的服务线程为每个 ost_io 服务线程预分配 RPC-sized MB JIO 的缓冲区，因此不需要通过 IO 请求来分配和释放缓冲区。。0SS 读取缓存: OSS 读取缓存提供 OSS 数据的只读缓存，使用浓规的",
        "存储的后备文件系统。这使 Lustre 能够利用 ZFS 的可扩展性和数据完整性特性来实现单个存储目标。“ 符合 POSIX 标准: 完整的POSIX 测试套件以完全相同的方式传递到本地的 ext4文件系统。在集群中，大多数操作都是原子操作，因此客户端永远不会看到损坏的数据或元数据。Lustre 软件文持mmap 0 MPF I/O 操作。.高性能异构网络: Lustre 软件支持各种高性能低延迟的网络，人允许远程直接内存访问 (RDMA) 方式实现在 InfiniBand、IntelOmniPath 等高级网络上的快速高效网络传输。可使用 Lustre 路由桥接多个RDMA 网络以获得最佳性能。Lustre 软件同时也集成了网络诊断。。 高可用性: Lustre 文件系统通过OSTSs (OSS targets) 或者MDT (MDS target) 的共享存储分区实现主动/主动故隐切换。Lustre 文件系统可以与各种高可用性 CHA)管理融一起工作，以实现目动故障切换并消除了单氮故了区 (NSPF) 。这使得应用程序透明恢复成为可能。多重安逆保护 (MMP) 提供了对高可用性系统中的错误的综合保护，和否则将会导致文件系统损坏。可配置多个 MDT 的主动/主动故障切换。这人允许了通过添加 MDT 存储设备和 MDS蔬氮来扩展 Lustre 文件系统的元数据性能。\"安全性: 默认情况下，TCP 连接只人允许授权端口通过。UNIX 组成员身份在 MDS上进行验证。“访问控制列表 (ACL) 及扩展属性: Lustre 安全模型遵循 UNIX 文件系统原则，并使用POSIX ACL 进行增强。请注意一些附加功能，如 root squash.“互操作性: Lustre 文件系统运行在各种 CPU 架构和混合端群集上，并在连续发布的一些主要 Lustre 软件版本乙间具有互操作性。“基于对象的体系结构: 客户端与磁盘文件结构相互隔离，可在不影响客户端的情况下升级存储体系结构。33\nLustre 文件系统操作手册 译者: 李硕“字闻粒度文件和细粒度元数据锁定: 许多客户端可以同时读取和修改相同的文件或目录。Lustre 分布式锁管理种 (LDLM) 确保了文件系统中所有客户端和服务融之间的文件是一致",
        "仍可以使用默认的 DoM 布局在现有目录中创建。(Lustre 2.11 中引入)第二十一章 MDT 的 Lazy 大小功能 (LSoM)21.1. 简介在 Lustre 文件系统中，MDS 上存储着 ctitme、mtime、所有者和其他文件属性。OSS上则存储着每个文件使用的块的大小和数量。要获得正确的文件大小，客户端必须访问存储文件的每个 OST，这意味着当一个文件在多个 OST 上分条时，需要使用多个 RPC来获取文件的大小和块。MDT 上的 Lazy 大小 (LSoM) 功能将文件的大小存储在 MDS上，如果应用程序能接受获取的文件大小不精准，则可以避免访问多个 OST 以获取文件大小。Lazy 意味着不能保证存储在 MDS 上的属性的准确性。由于许多 Lustre 安装环境都使用固态硬盘作为 MDT，因此 LSoM 的目标是通过将数据存储在 MDT 上来加快从 Lustre 文件系统获取文件大小所需的时间。我们和希望Lustre 策略引擎初始使用这一功能，以扫描后端 MDT 存储，或根据不同的大小做出诀策，且不依赖于完全准确的文件大小。类似的例子还包括 Lester, Robinhood, Zester 和供应商提供的许多工具。未来将改进为允许通过1fs finq等工具访问 LSoM 数据。21.2. 启动 LSoM当使用策略引擎扫搞 MDT fa SEN, LSoM 始终处于局用状态，不需要做任何操作来启用获取 LSoM 数据的功能。通过1fs getsom命令也可以访问客户端上的LSoM 数据。因为当前在客户端上通过 xattr 接口访问 LSoM 数据，所以只要缓存了索引251\nLustre 文件系统操作手册 译者: 李硕Tid, xattr_cache 就会在客户端上绥存文件大小和块计数。在大多数情况下，这是可行的，因为它改善了对 LSoM 数据的访问频率。但是，这也意味着，如果在首次访问 xattr后文件大小发生了变化，或者在首次创建文件后不久访问 xattr，LSoM 数据可能会过时。如果需要访问过时的最近 LSoM 数据，可以在客户端通过1ct1 set_param1dlm.namespaces.xmqdqcx.1LIru size=clear取消MDC 锁定，刷新",
        "创建文件后不久访问 xattr，LSoM 数据可能会过时。如果需要访问过时的最近 LSoM 数据，可以在客户端通过1ct1 set_param1dlm.namespaces.xmqdqcx.1LIru size=clear取消MDC 锁定，刷新 xattr 2. A则，如果在 LDLM 锁定超时前未访问文件，则将从客户端缓存中删除文件属性。通过LIct1l get param 1ldlm.namespaces.*mdc*.lru_max_ age储存锁定超时时长如果从特定客户端 (如 HSM 代理节点) 重复访问最近创建或频繁修改的文件的LSoM 属性，则可以使用lctl set param llite.*.xattr_ cache=0来禁用客户wi LAY xattr 缓存。但这可能会导致在访问文件时的额外开销，一般不建议使用。21.3. 用户命令Lustre 提供了1fs getsom命令以显示存储在 MDT 上的文件属性。11som_sync命令人允许用户将MDT 上的文件属性与 OSTs 上的有效或最新数据同步。可以在具有 Lustre 文件系统载入点的客户端上调用11som_sync命令。该命令使用Lustre MDS 变更日志，因此必须注册变更日志用户才能使用此命令工具。21.3.1 使用Lfs getsom显示 LSoM 数据lis getsom命令列出了存储在 MDT 上的文件属性。调用该命令需使用 Lustre 文件系统上文件的完整路径和文件名。如果没有使用选项，则存储在 MDS 上的所有文件属性都将显示出来。21.3.2 lfs getsom 命令1 1fs getsom [-s] [-b] [-f] <filename下面列出了各种 岂 getsom 选项。选项 说明-s ，仅显示给定文件的LSoM 数据的大小值。这是一个可选标志-pb ， 仅显示给定文件的LSoM 数据的块值。这是一个可选标志-£ ， 仅显示给定文件的 LSoM 数据的标志值。这是一个可选标志。有效的标志值有: SOM_FL_ UNKNOWN = 0x0000 ，表示未知或没有 SoM 数据，必须从 OSTS 获取大小; SOM _FL STRICT = 0x0001，表示已知且严格正确",
        "标志值有: SOM_FL_ UNKNOWN = 0x0000 ，表示未知或没有 SoM 数据，必须从 OSTS 获取大小; SOM _FL STRICT = 0x0001，表示已知且严格正确，252\nLustre 文件系统操作手册这aX选项”说明FLR 文件 (SOM 保证) ; SOM_FL_DEISE = 0x0002，表示已知但已过时，即在过去的某个时间点是正确的，但现在已知 (或可能) 不正确 (例如，打开进行写入); SOM_FL_LAZY = 0x0004，表示近似值，可能从未严格正确过，需要同步 SOM 数据以实现最终的一致性。第二十二章文件级元余 (ELR)22.1. 概述Lustre 文件系统最初就是为 HPC 而设计的，筷一直在具备内部元余性和容销性的高端存储上运行归好。然而，尽管这些存储系统的成本昂贵、结构复杀，存储必障仍然时有发生。事实上，在 Lustre 2.11 RA ZH, Lustre 文件系统并不比其底层的单个存储AUR ae LE EAT SE. Lustre 文件系统并没有机制能够缓解硬件存储改隐。当服务融无法访问或终止服务时，将无法访问文件。Lustre 2.11 中引入了 Lustre 文件级元余 (FLR) 功能，任何 Lustre 文件都可将相同的数据存储在多台 OST 上，以提升系统在存储故障或其它故障发生时的稳健性。在存在多个针像的情况下，可选择最合适的镜像来啊应单个请求，这对 IO 可用性有直接影啊。此外，对于许多客户闯同时读取的文件〈如输入版，共孚库或可执行文件)，可以通过创建文件数据的多个镜像来提高单个文件的并行聚合读取性能。第一阶段的FLR 功能通过延迟写入实现〈如\"图 21.1 FLR EIR GA\" 所示)。在写入镜像文件时，只有一个主镜像或首选镜像在写入过程中直接更新，而其他镜像将被标记为stale。通过使用命令行工具《由用户或管理员直接运行或通过目动监控工具运行)同步各镜像之间同步，该文件可在随后再次写入其它镜像。Object j (primary, preferred)delayed resync图 25: FLR delay writting图"
    ]
}