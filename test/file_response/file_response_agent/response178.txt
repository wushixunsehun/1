{
    "query": "将TH-eX chenx 账号预约的保留资源调整为 200 个节点，给出具体命令。",
    "summaries": [
        "本文档介绍了yhcontrol命令的使用，包括创建、更新和删除预约，设置预约的开始时间、结束时间或持续时间，指定分区、标志、节点特性、用户和账户等。还提到了环境变量的设置以及一些示例命令，如显示分区信息、作业状态、主机名、创建和更新资源预留等。命令行选项优先于环境变量设置。",
        "本文档介绍了TH-eX系统的用户分区设置、权限限制、磁盘配额以及状态查看命令。用户根据不同的分区有相应的结点数和任务运行时间限制。系统还对用户权限进行管理，基于合同规模限制使用资源，并要求用户在申请资源后才能访问计算结点。磁盘配额方面，用户有存储和文件数量的软硬限制，超出限制将影响数据操作。用户可通过相关命令查看分区、结点和作业状态，确保合理使用系统资源。",
        "天大GPU账号管理方案针对TJGPU集群进行说明，该集群包含4台8卡A800+Intel CPU节点和2台8卡A800+AMD CPU节点（已分配给南开大学），存储为137TB的/fs1，网络为200GB IB，软件与HPC4 GPU一致。用户通过提供单位、姓名、用户名向管理员（郑刚）申请账号，默认分配GPU分区2卡及存储配额。资源调整需联系管理员，计算资源和存储配额可通过指定账号配置和查询。"
    ],
    "contents": [
        "有具体如下表所示:表 3-1 用户分区设置分区限制ane ja |最多结点数 | BERK 任务最长运行时间debug4 用户调试分区 | 2 | 112 30 分钟oe 包机时用户分区 无short4 包规模普通用户分 HUIS LRT 2Klong4 包规模长队列用户分区 10 天debug6 用户调试分区 | -on 包机时用户分long6 包规模长队列用户分区由账吕权限决定 2 天21\nHISEEtee TH-eX 系统用户手册用户可以使用“大-1”或“yhcontrol show partition partition name” fii, F到相应的分区的详细信息。注意:由于大型集群系统具备一定故障率，为了保证系统稳定性，分区中有限定任务执行时间的限制，因此建议用户为程序设立“断点”从而保证任务由于意外中断后，可以继续运算。3.1.2 用户权限限制除了上述的分区限制，目前还根据用户的申请情况，针对用户做了一定的限制，该限制主要基于用户和中心签订合同的规模。包括: 最多可以使用的结点数、最多可以使用的核数、单个任务最多可以使用的结点数、单个任务最多可以使用的核数等。通过命令“yhacctmgr list association”可查看自己账号的具体权限设置。用户只有查看自己账号的权限，无查询其他账号的权限。用户在使用过程中，如果有超出自己合同范围内的计算规模的计算需求，请基于自己的需求，向中心提出申请，中心会根据用户需要审查后，进行一定的修改。为了保证系统和用户数据的安全，目前普通用户不能在没有申请资源时，就ssh 链接到计算结点，只有分配了相应的计算结点资源后，才能 ssh 到指定计算结点。3.1.3 磁盘配额限制为了合理利用有限的存储资源，目前中心对用户款认进行存储软限制 512G,存储便限制 IT，文件数软限制 100 万，文件数便限制 200 万的磁盘配额限制。用户登录后会出现如图 3-1 的磁盘配额信息:Filesystem used quota Limit grace files quota kimt = grace/fs2 3616 045126 1T - 13942 1999966",
        "的状态提示VY. wt(EIS:有的时候用户登录会出现错误提示“Some errors happened when getting quotainfo. Some devices may be not working or deactivated. The data in \"[]\" is inaccurate. ”这是因为登陆结点 quota RAIA lakh, SPH AS BREA EL ae HH用户可以用命令“jlfs quota -g groupname /fs2” KAN BAB CAN EAE AR.或通过命令“lf quota -u username /fs2 ”查看 user 的配额信息。 (其中，groupname 和 username 可以用过 id 命令获得。)3. 2 状态查看命令在用户提交作业前，应先查看系统的使用情况，这样利于用户根据系统使用情况，进行选择。3.2.1 结点状态查看 yhinfo 或 yhiyhi 为 yhinfo 命令的简写，用户可以使用 yhi 或者 yhinfo 命令查看结点的使用情况，从而根据情况做出选择。可以通过命令 whi -1 获得结点更为详细的信息。He 3-3 yhi 输出的关键词说明KE 含义PARTITION 用户可用的计算分区AVAIL 可用状态: up 表示可用; down 表示不可用TIMELIMIT 该分区的作业最大运行时长限制NODES 结点数量4down: 不可用状态idle: 空闲状态alloc: 被分配状态STAT24\nNSz TH-eX 系统用户手册CD: 成功结束，completedF: 失败结束，failedTD: 超时，timeoutNF: 因节点故障而运行失败，node_fail作业状态转换的详细图如下，由于 CD, CA, F 这三个作业状态持续时间很短，因此使用 yhd 命令可能会观察不到这些状态。作业提交用户可以使用 yhg 查看自己提交的作业，为了保证用户的数据安全，普通用户通过 yho 只能看到自己提交的作业。查看作业明细:用户可以通过如下命令来查看目己提交的作业明细其中jobid 表示作业的记号，用户根据目己作业的情况填入即可，之后用户即可以看到该作业十分详细的信息。注意: 用户作业如果长时间为 CG 状态，表示作业没有正常退出，系统管理员",
        "。e EndTime=time_ spec预约的结束时间。创建预约时必须指定结束之间或者持续时间。有效格式同StartTime.e Duration=time预约的持续时间。创建预约时必须指定结束之间或者持续时间。有效格式为minutes, minutes:seconds, hours:minutes:seconds, days-hours, days-hours:minutes 或days-hours: minutes: seconds. IM TEIIN 2} ##28 AZ} Eh, PACH AR ASIP ote PartitionName=name预约所在的分区。。 Flags=flags预约相关联的标志。要在 update 时清除某标志，请在标志名前加减号，例如“Flags=-DAILY”(注意: 某些标志不文持此操作)。当前文持的标志有:— MAINT系统维护模式，在记账时被特殊处理。此预约允许使用已经在其它预约中的节点。一 OVERLAP此预约可以分配已经在其它预约中的节点。302\n17.2. yhcontrol— IGNORE_JOBS创建预约时忽略当前运行的作业。这在预约系统中所有节点进行系统维护时特别有用。— DAILY每天在相同时间重复预约。一 WEEKLY每周在相同时间重复预约。一 SPEC_NODES预约特定的节点《〈《仅用于输出)。。 Features=features设置预约需要的节点特性。可用“《&”分隔多个值，如果需要所有特性《与操作)，或用“1”分隔，如果需要任意特性〈或操作)。可使用空数据“Features=”清除。e。 Users=user list允许使用预约的节点的用户。例如， Users=jonesi,smith2. 创建预约时必须指定Users 和/或 Accounts。e Accounts=account list允许使用预约的节点的帐喜。例如，Accounts=physcodqel ,physcodqe2。任意帐喜中的用户都可以使用预约的和节点。创建预约时必须指定 Users 和/或 Accounts.环境变量ALE yhcontrol 的选项可以通过环境变量设置。这些环境变量及其对应的选项如下。注意: 命令行选项总是覆盖环境变量选项。e。 SCONTROL_ ALL -a,--all¢ SLURM CONF 资源管理系统配置文件的位置。303\n资源管理系统手册示例yhcontrol 命令# yhcontrolyhcontrol: show part",
        "【已解决】天大GPU账号管理方案\n**标签**: gpu\n**创建时间**: 2024-06-25 17:00:49\n**更新时间**: 2024-06-25 17:00:49\n**作者**: 郑刚\n**问题**：天大GPU账号管理方案\n系统简介\n- TJGPU 集群\n- GPU\n- 4台8卡A800+intel CPU（每个节点包含 52CPUcores 8 GPU cards 512GB 内存）\n- 2台8卡A800+AMD CPU（给南开大学了）\n- 存储：/fs1 137TB\n- 网络：200GB IB\n- 软件：与 HPC4 GPU 完全一样\n- GPU\n- 4台8卡A800+intel CPU（每个节点包含 52CPUcores 8 GPU cards 512GB 内存）\n- 2台8卡A800+AMD CPU（给南开大学了）\n- 存储：/fs1 137TB\n- 网络：200GB IB\n- 软件：与 HPC4 GPU 完全一样\n- 4台8卡A800+intel CPU（每个节点包含 52CPUcores 8 GPU cards 512GB 内存）\n- 2台8卡A800+AMD CPU（给南开大学了）\n- 存储：/fs1 137TB\n- 网络：200GB IB\n- 软件：与 HPC4 GPU 完全一样\n- 2台8卡A800+AMD CPU（给南开大学了）\n- 存储：/fs1 137TB\n- 网络：200GB IB\n- 软件：与 HPC4 GPU 完全一样\n- 存储：/fs1 137TB\n- 网络：200GB IB\n- 软件：与 HPC4 GPU 完全一样\n- 网络：200GB IB\n- 软件：与 HPC4 GPU 完全一样\n- 软件：与 HPC4 GPU 完全一样\nVPN管理\n- 使用 thvpn ，创建 TJGPU 的资源即可，与其他集群VPN类似\n- 创建后资源为 TJGPU 192.168.6.3\n账号管理\n- **创建账号**\n- 提供 单位、姓名、用户名 给管理员（目前为",
        "命令行选项总是覆盖环境变量选项。e。 SCONTROL_ ALL -a,--all¢ SLURM CONF 资源管理系统配置文件的位置。303\n资源管理系统手册示例yhcontrol 命令# yhcontrolyhcontrol: show part debugPartitionName=debugAllocNodes=ALL AllowGroups=ALL Default=YESDefaultTime=NONE DisableRootJobs=NO Hidden=NOMaxNodes=UNLIMITED MaxTime=UNLIMITED MinNodes=1Nodes=snowf lake [0-48]Priority=1 RootOnly=NO Shared=YES:4State=UP TotalCPUs=694 TotalNodes=49yhcontrol: update PartitionName=debug MaxTime=60:00 MaxNodes=4yhcontrol: show job 71701JobId=71701 Name=hostnameUserId=da(1000) GroupId=da(1000)Priority=66264 Account=none QOS=normal WCKey=*123JobState=COMPLETED Reason=None Dependency=(null)TimeLimit=UNLIMITED Requeue=1 Restarts=0 BatchFlag=0 ExitCode=0:0SubmitTime=2010-01-05T10:58:40 EligibleTime=2010-01-05T10:58:40StartTime=2010-01-05T10:58:40 EndTime=2010-01-05T10: 58:40SuspendTime=None SecsPreSuspend=0Partition=debug AllocNode:Sid=snowflake:4702ReqNodeList=(null) ExcNodeList=(nul1l)NodeList=snowflakeONumNodes=1 NumCPUs=10 CPUs/Task=2 ReqS:C:T=1:1:1MinCPUsNode=2 MinMemoryNode=0 MinTmpDiskNode=0Features=(null) Reservation=(null)Shared=0K Contiguous=0 Licenses=(null) Network=(null)yhcontrol: update JobId=71701 TimeLimit=30:00 Priority=500yhcontrol: show hostnames tux[1-3]tuxltux2tux3yhcontrol: create res StartTime=2009-04-01T08:00:00 Duration=5:00:00 Users=dbremer NodeCnt=Reservation created: dbremer_1yhcontrol: update ReservationSdbremer mage taint NodeCnt=201yhcontrol: delete Reservation=dbremeyhcontrol: quit",
        "的资源即可，与其他集群VPN类似\n- 创建后资源为 TJGPU 192.168.6.3\n账号管理\n- **创建账号**\n- 提供 单位、姓名、用户名 给管理员（目前为郑刚）\n- 默认创建为：\n- 计算资源：GPU 分区 2卡\n- 存储配额：500G 1T 50万 100万\n- 提供 单位、姓名、用户名 给管理员（目前为郑刚）\n- 默认创建为：\n- 计算资源：GPU 分区 2卡\n- 存储配额：500G 1T 50万 100万\n- 默认创建为：\n- 计算资源：GPU 分区 2卡\n- 存储配额：500G 1T 50万 100万\n- 计算资源：GPU 分区 2卡\n- 存储配额：500G 1T 50万 100万\n- 存储配额：500G 1T 50万 100万\n- 调整资源（目前联系郑刚）\n- **计算资源**：用户名、分区（默认gpu）、卡数\n- **存储配额**：用户名、配额信息（软限制、硬限制、文件数软限制、文件数硬限制）\n- **计算资源**：用户名、分区（默认gpu）、卡数\n- **存储配额**：用户名、配额信息（软限制、硬限制、文件数软限制、文件数硬限制）\n- **存储配额**：用户名、配额信息（软限制、硬限制、文件数软限制、文件数硬限制）\n- 查询卡是\n- 类似 HPC4，使用 thGpuConfig 配置，使用 thGpuUsage 查询。但目前只有 nscctj 账号，可以暂时由 nscctj 账号进行配置。（目前联系郑刚）\n- 类似 HPC4，使用 thGpuConfig 配置，使用 thGpuUsage 查询。但目前只有 nscctj 账号，可以暂时由 nscctj 账号进行配置。（目前联系郑刚）",
        "用户登录后会出现如图 3-1 的磁盘配额信息:Filesystem used quota Limit grace files quota kimt = grace/fs2 3616 045126 1T - 13942 1999966 2000000图 3-1 磁盘配额登陆提示信息22\nPr TH-eX 系统用户手册表 3-2 磁盘配额各关键词说明5 ee >| Rhesystem |用户所在的共享分布式存储it | rEpiles |用疡已有的文伯数量 (单位: 个)it | 文件数量硬限制 〈单位: 个)以磁盘存储为例说明软、硬限制的含义，文件数软、硬限制的含义与其一样。用户使用存储低于 512G 时，如图 3-1 所示，存储状态正常，当用户使用存储介于512G 和 1T 之间时，存储状态如图 3-2 所示，kbytes 参数对应的数字带有“*”表示用户配额异营，“6d23h59m57Ss”表示一个月的倒计时，如果用户在倒计时结束前将使用存储清理到 512G 以下，则存储状态恢复正常。和否则用户的数据量超出软限制且超出倒计时，如图 3-3 所示。如果用户数据在倒计时期间继续增长，超出硬限制，则用户存储将无法写入，如图 3-4 Stax; 数据操作也会受限制，如图 3-5 所人小。Filesystem used quota Limit grace files quota Ltntt grace/Ts2 728G* 5126 iT 6d23h59m57s =Filesystem used quota Limit grace files quota Limtt grace/Ts2 728G* 5126 iT 438942 =Filesystem used quota limit files quota limit = grace/fs2 1.237 ;23\nNSC[nscctj@th-ex-1n0] $ cp test.txt test2.txtcp:writing './test2.txt':Disk quota exceededcp:writing './test2.txt':Input/Output3-5 用户数据超出磁盘配额限制的状态提示VY. wt(EIS:有的时候用户登录会出现错误提示“Some errors happened when getting quotainfo. Some devices may be not working or deactivated."
    ]
}