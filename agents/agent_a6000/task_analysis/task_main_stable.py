import os, re, sys
sys.path.append('./')
log_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'logs')
os.makedirs(log_dir, exist_ok=True)


import asyncio
import time, yaml
import json, uuid
import httpx, uvicorn
from mem0 import Memory
import logging, requests
from pathlib import Path
from typing import Optional
from functools import partial
from agent_state import AgentState
from fastapi import FastAPI, Request
from langgraph.graph import StateGraph, END
from agentsAPI import query_llm, strip_think
from a2a.client import A2ACardResolver, A2AClient
from a2a.types import MessageSendParams, SendMessageRequest
from fastapi.responses import JSONResponse, StreamingResponse
from prompts import UPDATE_MEMORY_PROMPT, custom_fact_extraction_prompt


logging.basicConfig(
    filename = os.path.join(log_dir, "task_analysis_agent.log"),
    level = logging.INFO,
    format = "%(asctime)s [%(levelname)s] %(name)s: %(message)s",
)
logger = logging.getLogger(__name__)
httpx_logger = logging.getLogger("httpx")
httpx_logger.setLevel(logging.WARNING)
httpx_logger.propagate = False


agents_dir = Path(__file__).resolve().parents[2]
config_path = agents_dir / "config.yaml"
with open(config_path, 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)

llm_model = config.get("llm", {}).get("model")
llm_host = config.get("llm", {}).get("base_url")
embedding_model = config.get("rag", {}).get("embedding_model")
embedding_host = config.get("rag", {}).get("base_url")
api_key = config.get("rag", {}).get("api_key")

milvus_collection = config.get("collections", {}).get("mem0_col")
milvus_host = config.get("milvus", {}).get("uri")
milvus_token = config.get("milvus", {}).get("token")


mem0_config = {
    "version": "v1.1",
    "custom_fact_extraction_prompt": custom_fact_extraction_prompt,

    # --- 8< --- æœ¬åœ° LLM æœåŠ¡ --- 8< ---
    "llm": {
        "provider": "openai",
        "config": {
            "model": llm_model,
            "openai_base_url": llm_host,
            "api_key": api_key,
        }
    },

    # --- 8< --- æœ¬åœ° Embedding æœåŠ¡ --- 8< ---
    "embedder": {
        "provider": "openai",
        "config": {
            "model": embedding_model,
            "openai_base_url": embedding_host,
            "api_key": api_key,
            "embedding_dims": 768,
        }
    },

    # --- 8< --- Milvus å‘é‡åº“ --- 8< ---
    "vector_store": {
        "provider": "milvus",
        "config": {
            "collection_name": milvus_collection,
            "embedding_model_dims": 768,
            "url": milvus_host,
            "token": milvus_token,
        }
    },

    # --- 8< --- è‡ªå®šä¹‰æ›´æ–°è®°å¿†æç¤ºè¯ --- 8< ---
    "prompts": {
        "update_memory": UPDATE_MEMORY_PROMPT,
    }
}

mem0 = Memory.from_config(mem0_config)


class Node:
    def __init__(
        self,
        name: str,
        agent_type: str,
        next_nodes: list[str],
        hostname: Optional[str] = None,
        expert: Optional[str] = None,
        sub_task: Optional[str] = None,
    ):
        self.name = name
        self.agent_type = agent_type
        self.next_nodes = next_nodes
        self.hostname = hostname
        self.expert = expert
        self.sub_task = sub_task

    def add_next_node(self, next_node):
        self.next_nodes.append(next_node)

    def __repr__(self):
        return f"èŠ‚ç‚¹åç§°ï¼š{self.name}ï¼Œç±»å‹ï¼š{self.agent_type}ï¼Œä¸‹ä¸€è·³ï¼š{self.next_nodes}"


TASK_PROMPT_TEMPLATE = '''ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ™ºèƒ½ç³»ç»Ÿä»»åŠ¡å†³ç­–ä¸“å®¶ï¼Œè¯·å…ˆæ ¹æ®ç”¨æˆ·è¾“å…¥çš„é—®é¢˜**æ€è€ƒè¯¥å¦‚ä½•å¤„ç†**ï¼Œç„¶åå†æ ¹æ®ä»»åŠ¡ç±»å‹å®šä¹‰è¿›è¡Œ**ç‰¹å¾åŒ¹é…**ã€‚å¦‚æœæ˜¯ä½ èƒ½è§£å†³çš„ä»»åŠ¡ï¼Œé‚£ä¹ˆè¾“å‡º**æœ€åˆé€‚çš„ä»»åŠ¡ç±»å‹**ï¼›å¦‚æœæ˜¯æ— æ³•è§£å†³çš„ä»»åŠ¡ï¼Œé‚£ä¹ˆç”¨**äº²åˆ‡å’Œè”¼çš„è¯­æ°”**ç»„ç»‡é€‚å½“çš„è¯­è¨€è¡¨è¾¾**æ— æ³•è‡ªåŠ¨åŒ–è§£å†³ï¼Œå¯ä»¥å°è¯•è”ç³»ç³»ç»Ÿç®¡ç†å‘˜çš„æ„å›¾**ï¼Œæ‹’ç»åŸå°ä¸åŠ¨æˆ–ç”Ÿç¡¬çš„å›ç­”ã€‚

### æ€è€ƒè¦æ±‚
1. å…ˆç®€è¦æ¨ç†ï¼šç”¨æˆ·çš„è¾“å…¥æ„å›¾æ˜¯ä»€ä¹ˆï¼Ÿä½ ä¼šå¦‚ä½•å¤„ç†ï¼Ÿéœ€è¦å“ªäº›ç³»ç»Ÿèƒ½åŠ›ï¼Ÿ
2. æ¨ç†åå†åŒ¹é…ä»»åŠ¡ç±»å‹ã€‚

### ä»»åŠ¡ç±»å‹å®šä¹‰
**çŸ¥è¯†é—®ç­”ä»»åŠ¡**
- ç‰¹å¾ï¼šç”¨æˆ·è¯¢é—®äº‹å®æ€§/è§£é‡Šæ€§é—®é¢˜ã€‚
- ç³»ç»Ÿè¡Œä¸ºï¼šæ£€ç´¢çŸ¥è¯†åº“(RAG)ï¼Œæ•´ç†ä¿¡æ¯å¹¶è¾“å‡ºç­”æ¡ˆ
- ç¤ºä¾‹ï¼š
    "å¦‚ä½•å®‰è£… xx è½¯ä»¶/ç¡¬ä»¶ï¼Ÿ"
    "å¦‚ä½•æŸ¥çœ‹ xx èŠ‚ç‚¹çš„çŠ¶æ€ï¼Ÿ"

**çŠ¶æ€æŸ¥è¯¢ä»»åŠ¡**
- ç‰¹å¾ï¼šç”¨æˆ·è¯·æ±‚è·å–ç³»ç»Ÿ/æœåŠ¡çš„å®æ—¶çŠ¶æ€ä¿¡æ¯
- ç³»ç»Ÿè¡Œä¸ºï¼šç”Ÿæˆç»ˆç«¯å‘½ä»¤â†’æ‰§è¡Œæ“ä½œâ†’æ•´ç†çŠ¶æ€æŠ¥å‘Š
- ç¤ºä¾‹ï¼š
    "æ£€æŸ¥ xx æœåŠ¡çš„è¿è¡ŒçŠ¶æ€"
    "xx ä½œä¸šçš„æ´»è·ƒæ—¶é•¿æ˜¯å¤šå°‘ï¼Ÿ"

**å¼‚å¸¸å¤„ç†ä»»åŠ¡**
- ç‰¹å¾ï¼šç”¨æˆ·æŠ¥å‘Šæ•…éšœ/å¼‚å¸¸ï¼Œéœ€è¦è¯Šæ–­å’Œè§£å†³
- ç³»ç»Ÿè¡Œä¸ºï¼šè·å–ç³»ç»ŸçŠ¶æ€â†’åˆ†æåŸå› â†’æ‰§è¡Œä¿®å¤â†’ç”Ÿæˆå¤„ç†æŠ¥å‘Š
- ç¤ºä¾‹ï¼š
    "ç£ç›˜å‡ºç°æŠ¥é”™ï¼Œåˆ†æåŸå› ç»™å‡ºè§£å†³æ–¹æ¡ˆ"
    "xx æœåŠ¡æŠ¥é”™/å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥åŸå› "

**Slurmä½œä¸šå¤„ç†ä»»åŠ¡**
- ç‰¹å¾ï¼šSlurm ä½œä¸šè¿è¡Œå¼‚å¸¸ï¼Œç”¨æˆ·è¯·æ±‚å¯¹å…¶è¿›è¡Œå¤„ç†
- ç³»ç»Ÿè¡Œä¸ºï¼šè·å–ä½œä¸šå½“å‰è¿è¡ŒçŠ¶æ€â†’è¿›å…¥ä½œä¸šæ‰€åˆ†é…èŠ‚ç‚¹æ‰§è¡Œæ“ä½œâ†’åˆ†æå¹¶ç”Ÿæˆå¤„ç†æŠ¥å‘Š
- ç¤ºä¾‹ï¼š
    "ä½œä¸š xx å¡ä½/ä¸­æ–­"
    "ä½œä¸š xx æŠ¥é”™/å‡ºé”™"

**å†™æ“ä½œä»»åŠ¡**
- ç‰¹å¾ï¼šç”¨æˆ·éœ€è¦å¯¹ç³»ç»Ÿèµ„æºè¿›è¡Œâ€œå†™â€æ“ä½œï¼Œå¦‚ä¿®æ”¹/åˆ›å»ºæ–‡ä»¶ã€æ›´æ–°é…ç½®/æƒé™ç­‰
- ç³»ç»Ÿè¡Œä¸ºï¼šåŸºäºä»»åŠ¡æè¿°ç›´æ¥è°ƒç”¨ç¬¦åˆéœ€æ±‚çš„è„šæœ¬/è¿ç»´å‰§æœ¬â†’æ‰§è¡Œâ†’è¿”å›ç»“æœç¡®è®¤
- ç¤ºä¾‹ï¼š
    "æŠŠ xx ä¸­çš„ xx è°ƒæˆ xx"
    "ä¿®æ”¹ç”¨æˆ· xx çš„ä½œä¸šé…é¢"
    "å–æ¶ˆä½œä¸š xx"
    "æ·»åŠ  xx"

### åˆ†æè§„åˆ™
1. ä¸¥æ ¼åŸºäºæ–‡æœ¬å­—é¢å«ä¹‰åˆ†æï¼Œç¦æ­¢ä¸»è§‚æ¨æµ‹
2. æ— çŠ¶æ€æ“ä½œçš„çŸ¥è¯†è¯·æ±‚ â‰  çŠ¶æ€æŸ¥è¯¢ï¼Œéœ€è¦æ¶‰åŠè·å–æœåŠ¡å™¨çŠ¶æ€çš„è¯­å¢ƒ
3. å•çº¯è¯¢é—®è§£å†³æ–¹æ¡ˆ/æ–¹æ¡ˆ/å¯è¡Œæ€§ â‰  å¼‚å¸¸å¤„ç†ï¼Œéœ€è¦å®é™…çš„æ•°æ®æˆ–æ•…éšœæè¿°ï¼Œç”šè‡³å¯ä»¥é€šè¿‡çŸ¥è¯†é—®ç­”æ¥ç»™å‡ºæŒ‡å¯¼æ€§æ–¹æ¡ˆ
4. å¯¹ç³»ç»Ÿèµ„æºçš„å˜æ›´æ“ä½œä¼˜å…ˆå½’ç±»ä¸ºå†™æ“ä½œä»»åŠ¡

### è¾“å‡ºè¦æ±‚
- å¦‚æœæ˜¯èƒ½è§£å†³çš„ä»»åŠ¡ï¼Œåˆ™ä»…è¿”å›å­—ç¬¦ä¸²å½¢å¼çš„ä»»åŠ¡ç±»å‹ï¼ˆçŸ¥è¯†é—®ç­”ä»»åŠ¡ã€çŠ¶æ€æŸ¥è¯¢ä»»åŠ¡ã€å¼‚å¸¸å¤„ç†ä»»åŠ¡ã€Slurmä½œä¸šå¤„ç†ä»»åŠ¡ã€å†™æ“ä½œä»»åŠ¡ï¼‰ï¼Œç¦æ­¢æ·»åŠ é¢å¤–çš„è§£é‡Šæˆ–é™„åŠ æ–‡æœ¬
- åªæœ‰å½“ç”¨æˆ·è¾“å…¥çš„ä»»åŠ¡è¶…å‡ºäº†ä½ èƒ½è§£å†³çš„èŒƒå›´ï¼ˆå¦‚ç¡¬ä»¶æ’æ‹”å¤„ç†ã€éœ€è¦ç®¡ç†å‘˜æƒé™çš„æ“ä½œã€ç³»ç»Ÿå±‚é¢çš„è½¯ä»¶å®‰è£…ç­‰ï¼‰ï¼Œæ‰èƒ½ç»„ç»‡é¢å¤–çš„è¯­è¨€ï¼Œä½†è¦æ³¨æ„äº²åˆ‡å’Œè”¼çš„å£å»ï¼Œåˆ‡è«ç”Ÿç¡¬

è¯·åˆ†æä»»åŠ¡ï¼š
{task}
'''


def judge_task_type(task: str):
    prompt = TASK_PROMPT_TEMPLATE.format(task=task)

    enable_thinking = config.get("intent_recog_think")
    if enable_thinking:
        task_type = query_llm(
            prompt,
            enable_thinking=enable_thinking,
            temperature = 0.1,
            max_tokens = 1024,
        )
        task_type = strip_think(task_type).strip()
    else:
        task_type = query_llm(
            prompt,
            temperature = 0,
            max_tokens = 128,
        )

    return task_type


# def judge_num_of_object(task: str) -> dict[str, dict]:
#     prompt = OBJECT_PROMPT_TEMPLATE.format(task=task)
#     raw = query_llm(prompt)
#     data = json.loads(raw)
#     for obj, meta in data.items():
#         if "sub_task" not in meta or "expert" not in meta:
#             raise ValueError(f"{obj} ç¼ºå°‘å­—æ®µ")
#     return data


def generate_dag_dict(task):
    node_dict = {}
    start_node = ""
    
    logger.info(f"è¾“å…¥ä»»åŠ¡: {task}")
    task_type = judge_task_type(task)
    # print(f"ä»»åŠ¡ç±»å‹:{task_type}")
    logger.info(f"ä»»åŠ¡ç±»å‹: {task_type}")


    if task_type == 'çŸ¥è¯†é—®ç­”ä»»åŠ¡':
        """æ“ä½œæ‰§è¡Œä»»åŠ¡ï¼šæŠ¥å‘Šåé¦ˆAgent"""
        node_dict["æŠ¥å‘Šåé¦ˆ"] = Node("æŠ¥å‘Šåé¦ˆ", "æŠ¥å‘Šåé¦ˆAgent", next_nodes=["END"], hostname='a6000-G5500-V6')
        start_node = "æŠ¥å‘Šåé¦ˆ"

    elif task_type == 'çŠ¶æ€æŸ¥è¯¢ä»»åŠ¡':
        """çŠ¶æ€æŸ¥è¯¢ä»»åŠ¡ï¼šç³»ç»Ÿæ„ŸçŸ¥ Agent----ï¼ˆå†…ç½®æ“ä½œæ‰§è¡Œ Agentï¼‰----æŠ¥å‘Šåé¦ˆ Agent"""
        # æ„å»ºç³»ç»Ÿæ„ŸçŸ¥AgentèŠ‚ç‚¹
        node_dict["ç³»ç»Ÿæ„ŸçŸ¥"] = Node("ç³»ç»Ÿæ„ŸçŸ¥", "ç³»ç»Ÿæ„ŸçŸ¥Agent", next_nodes=["æŠ¥å‘Šåé¦ˆ"], hostname='mn10')

        # æ„å»ºæŠ¥å‘Šåé¦ˆAgentèŠ‚ç‚¹
        node_dict["æŠ¥å‘Šåé¦ˆ"] = Node("æŠ¥å‘Šåé¦ˆ", "æŠ¥å‘Šåé¦ˆAgent", next_nodes=["END"], hostname='a6000-G5500-V6')
        start_node = "ç³»ç»Ÿæ„ŸçŸ¥"

    elif task_type == 'å¼‚å¸¸å¤„ç†ä»»åŠ¡':
        """å¼‚å¸¸å¤„ç†ä»»åŠ¡ï¼šç³»ç»Ÿæ„ŸçŸ¥ Agent----å¼‚å¸¸åˆ†æ Agent----ç­–ç•¥è§„åˆ’ Agent----æ“ä½œæ‰§è¡Œ Agent----æŠ¥å‘Šåé¦ˆ Agent"""
        # æ„å»ºç³»ç»Ÿæ„ŸçŸ¥AgentèŠ‚ç‚¹
        node_dict["ç³»ç»Ÿæ„ŸçŸ¥"] = Node("ç³»ç»Ÿæ„ŸçŸ¥", "ç³»ç»Ÿæ„ŸçŸ¥Agent", next_nodes=["å¼‚å¸¸åˆ†æ"], hostname='mn10')

        # æ„å»ºå¼‚å¸¸åˆ†æAgentèŠ‚ç‚¹
        node_dict["å¼‚å¸¸åˆ†æ"] = Node("å¼‚å¸¸åˆ†æ", "å¼‚å¸¸åˆ†æAgent", next_nodes=["ç­–ç•¥è§„åˆ’"], hostname='a6000-G5500-V6')

        # æ„å»ºç­–ç•¥è§„åˆ’AgentèŠ‚ç‚¹
        node_dict["ç­–ç•¥è§„åˆ’"] = Node("ç­–ç•¥è§„åˆ’", "ç­–ç•¥è§„åˆ’Agent", next_nodes=["æŠ¥å‘Šåé¦ˆ"], hostname='mn10')

        # æ„å»ºæŠ¥å‘Šåé¦ˆAgentèŠ‚ç‚¹
        node_dict["æŠ¥å‘Šåé¦ˆ"] = Node("æŠ¥å‘Šåé¦ˆ", "æŠ¥å‘Šåé¦ˆAgent", next_nodes=["END"], hostname='a6000-G5500-V6')
        start_node = "ç³»ç»Ÿæ„ŸçŸ¥"

    elif task_type == 'Slurmä½œä¸šå¤„ç†ä»»åŠ¡':
        """Slurm ä½œä¸šå¤„ç†ä»»åŠ¡ï¼šç³»ç»Ÿæ„ŸçŸ¥ Agent----ç³»ç»Ÿæ„ŸçŸ¥ Agent----ç­–ç•¥è§„åˆ’ Agent----æ“ä½œæ‰§è¡Œ Agent----æŠ¥å‘Šåé¦ˆ Agent"""
        # æ„å»ºç³»ç»Ÿæ„ŸçŸ¥AgentèŠ‚ç‚¹
        node_dict["ç³»ç»Ÿæ„ŸçŸ¥"] = Node("ç³»ç»Ÿæ„ŸçŸ¥", "ç³»ç»Ÿæ„ŸçŸ¥Agent", next_nodes=["ç­–ç•¥è§„åˆ’"], hostname='mn10')

        # æ„å»ºç­–ç•¥è§„åˆ’AgentèŠ‚ç‚¹
        node_dict["ç­–ç•¥è§„åˆ’"] = Node("ç­–ç•¥è§„åˆ’", "ç­–ç•¥è§„åˆ’Agent", next_nodes=["æŠ¥å‘Šåé¦ˆ"], hostname='mn10')

        # æ„å»ºæŠ¥å‘Šåé¦ˆAgentèŠ‚ç‚¹
        node_dict["æŠ¥å‘Šåé¦ˆ"] = Node("æŠ¥å‘Šåé¦ˆ", "æŠ¥å‘Šåé¦ˆAgent", next_nodes=["END"], hostname='a6000-G5500-V6')
        start_node = "ç³»ç»Ÿæ„ŸçŸ¥"

    elif task_type == 'å†™æ“ä½œä»»åŠ¡':
        """å†™æ“ä½œä»»åŠ¡ï¼šç­–ç•¥è§„åˆ’ Agent----æŠ¥å‘Šåé¦ˆ Agent"""
        # æ„å»ºç­–ç•¥è§„åˆ’AgentèŠ‚ç‚¹
        node_dict["ç­–ç•¥è§„åˆ’"] = Node("ç­–ç•¥è§„åˆ’", "ç­–ç•¥è§„åˆ’Agent", next_nodes=["æŠ¥å‘Šåé¦ˆ"], hostname='mn10')

        # æ„å»ºæŠ¥å‘Šåé¦ˆAgentèŠ‚ç‚¹
        node_dict["æŠ¥å‘Šåé¦ˆ"] = Node("æŠ¥å‘Šåé¦ˆ", "æŠ¥å‘Šåé¦ˆAgent", next_nodes=["END"], hostname='a6000-G5500-V6')
        start_node = "ç­–ç•¥è§„åˆ’"

    else:
        """ä¸è¿›å…¥å·¥ä½œæµï¼Œç›´æ¥è¿”å›ç‰¹æ®Šæ ‡è®°"""
        return None, task_type

    return node_dict, start_node


def travel_dag(nodes, stack):
    if stack[0] == 'END':
        return
    node = nodes[stack[0]]
    print(node.name)
    print("  |")
    stack.pop(0)
    for item in node.next_nodes:
        if item not in stack:
            stack.append(item)
    travel_dag(nodes, stack)

    return


def print_dag(nodes, start_node):
    print("ç”ŸæˆDAGæµ:")
    travel_dag(nodes, [start_node])
    print(" END")


def node_func(state: AgentState):
    print("æµ‹è¯•ç¼“å†²èŠ‚ç‚¹......")
    return


def report_memory_changes(mem_results: list[dict]) -> None:
    """
    æŠŠ Mem0 è¿”å›çš„ç»“æœåˆ†ç»„æ‰“å°åˆ°ç»ˆç«¯å’Œæ—¥å¿—ã€‚
    åªå¤„ç† eventâ‰ NONE çš„æ¡ç›®ï¼›å®Œå…¨æ— å˜åŠ¨æ—¶é™é»˜ã€‚
    """
    changes = {"ADD": [], "UPDATE": [], "DELETE": []}

    for r in mem_results:
        evt = r.get("event", "NONE")
        if evt != "NONE":
            changes[evt].append(r)

    if not any(changes.values()):
        return  # æ²¡æœ‰ä»»ä½•æ–°å¢ / æ›´æ–° / åˆ é™¤

    lines: list[str] = []
    if changes["ADD"]:
        lines.append("æ–°å¢è®°å¿†:")
        lines.extend([f'  + {m["memory"]}' for m in changes["ADD"]])

    if changes["UPDATE"]:
        lines.append("æ›´æ–°è®°å¿†:")
        lines.extend(
            [
                f'  ~ {m["old_memory"]}  â†’  {m["memory"]}'
                if "old_memory" in m
                else f'  ~ {m["memory"]}'
                for m in changes["UPDATE"]
            ]
        )

    if changes["DELETE"]:
        lines.append("åˆ é™¤è®°å¿†:")
        lines.extend([f'  - {m["memory"]}' for m in changes["DELETE"]])

    msg_out = "\n".join(lines)
    # print(f'\n{msg_out}\n')
    logger.info("\n" + msg_out + "\n")


def result2reply_text(result):
    if isinstance(result, str):
        reply_text = result
    elif isinstance(result, dict):
        # å…¼å®¹åŸæœ‰é€»è¾‘
        if "result" in result and isinstance(result["result"], str):
            reply_text = result["result"]
        elif "result" in result and isinstance(result["result"], dict):
            # åŸæœ‰çš„ result['result']['parts'][0]['text'] ç»“æ„
            parts = result["result"].get("parts")
            if parts and isinstance(parts, list) and "text" in parts[0]:
                reply_text = parts[0]["text"]
            else:
                reply_text = str(result)
        # æ–°å¢ï¼šå…¼å®¹ {'0': {'root_cause': ...}} ç»“æ„
        elif all(isinstance(v, dict) and "root_cause" in v for v in result.values()):
            # åªå–ç¬¬ä¸€ä¸ªkey
            first_key = next(iter(result))
            v = result[first_key]
            reply_text = (
                f"æ ¹å› èŠ‚ç‚¹: {v.get('root_cause', '')}\n"
                f"æ•…éšœç±»å‹: {v.get('failure_type', '')}\n"
                f"Top5æ ¹å› : {v.get('top5', '')}"
            )
        else:
            reply_text = str(result)
    elif isinstance(result, list):
        reply_text = f'æŒ‡æ ‡æ—¶åºå¼‚å¸¸ç‚¹: {result}'
    else:
        reply_text = str(result)
    return reply_text


def push_user_turn(state: AgentState, hostname: str, task: str):
    if task:
        key = ("u", hostname, task)
        if key not in state.get("_msg_keys", set()):
            msg = {
                "role": "user",
                "hostname": hostname,
                "task": task,
            }
            state["messages"] = state.get("messages", []) + [msg]
            state.setdefault("_msg_keys", set()).add(key)
            # logger.info(f"æ·»åŠ æ¡ç›®ï¼š{msg}")


def push_agent_turn(state: AgentState, hostname: str, agent_name: str, response: str):
    if response:
        key = ("a", hostname, agent_name, response)
        msg = {
            "role": "agent",
            "hostname": hostname,
            "name": agent_name,
            "response": response,
        }
        state["messages"] = state.get("messages", []) + [msg]
        state["_msg_keys"].add(key)
        # logger.info(f"æ·»åŠ æ¡ç›®ï¼š{msg}")


def build_agent_url(agent_type: str, hostname: str) -> str:
    """
    æ ¹æ® agent_type å’Œ hostname æ‹¼æ¥ URLã€‚
    ç«¯å£ä¸è·¯å¾„åœ¨æ­¤é›†ä¸­ç®¡ç†ï¼ŒåæœŸè¦æ¢ç«¯å£åªæ”¹è¿™é‡Œå³å¯ã€‚
    """
    route_config = {
        "system_perception": ("5001", "system_perception"),
        "anomaly_analysis": ("5002", "anomaly_analysis"),
        "strategy_plan": ("5003", "strategy_plan"),
        "command_run": ("5004", "command_run"),
        "report_generate": ("5005", "report_generate"),
    }

    if agent_type not in route_config:
        raise KeyError(f"unknown agent_type {agent_type}")

    port, path = route_config[agent_type]
    return f"http://{hostname}:{port}"


async def agent_quest_stream(agent_type: str, node: Node, query: str):
    """
    çœŸæ­£çš„å®æ—¶æµå¼è°ƒç”¨ï¼šä½¿ç”¨HTTPæµå¼æ¥å£ + A2Aé™çº§
    """
    hostname = node.hostname or node.name.split("_")[0]
    if hostname in {"start", "end"}:
        yield ""
        return

    base_url = build_agent_url(agent_type, hostname)
    
    # å¯¹äºæ”¯æŒçœŸå®LLMæµå¼çš„ä»£ç†ï¼Œä¼˜å…ˆä½¿ç”¨HTTPæµå¼è°ƒç”¨
    # æ‰©å±•åˆ°æ‰€æœ‰æœ‰çœŸå®LLMè°ƒç”¨çš„ä»£ç†
    if agent_type in ["report_generate", "system_perception", "anomaly_analysis", "strategy_plan"]:
        try:
            async with httpx.AsyncClient(verify=False, timeout=300, proxy=None) as httpx_client:
                url = f"{base_url}/v1/chat/completions"
                payload = {
                    "messages": [{"role": "user", "content": query}],
                    "stream": True
                }
                
                logger.info(f"å°è¯•æµå¼è°ƒç”¨ {agent_type}, url: {base_url}")
                
                async with httpx_client.stream("POST", url, json=payload, headers={"Content-Type": "application/json"}) as response:
                    response.raise_for_status()
                    
                    async for line in response.aiter_lines():
                        if not line.strip():
                            continue
                            
                        line = line.strip()
                        if line.startswith("data: "):
                            line = line[6:]  # å»æ‰ "data: " å‰ç¼€
                        
                        if line == "[DONE]":
                            break
                            
                        try:
                            chunk = json.loads(line)
                            if "choices" in chunk and chunk["choices"]:
                                delta = chunk["choices"][0].get("delta", {})
                                if "content" in delta:
                                    yield delta["content"]
                        except json.JSONDecodeError:
                            continue
                
                logger.info(f"æµå¼è°ƒç”¨æˆåŠŸ: {agent_type}")
                return
                
        except Exception as e:
            logger.warning(f"æµå¼è°ƒç”¨å¤±è´¥: {str(e)}")
    
    # A2Aåè®®é™çº§æˆ–å…¶ä»–ä»£ç†ç±»å‹
    async with httpx.AsyncClient(verify=False, timeout=300, proxy=None) as httpx_client:
        try:
            resolver = A2ACardResolver(httpx_client=httpx_client, base_url=base_url)
            final_agent_card_to_use = await resolver.get_agent_card()
            client = A2AClient(httpx_client=httpx_client, agent_card=final_agent_card_to_use)

            payload = {
                "message": {
                    "role": "user",
                    "parts": [{"type": "text", "text": query}],
                    "messageId": uuid.uuid4().hex,
                },
            }
            logger.info(f"å‘é€A2Aè¯·æ±‚åˆ° {agent_type}, url: {base_url}")

            request = SendMessageRequest(
                id=str(uuid.uuid4()), params=MessageSendParams(**payload)
            )

            # å‘é€æ¶ˆæ¯å¹¶è·å–å®Œæ•´å“åº”
            response = await client.send_message(request)
            logger.info(f"A2Aå“åº”å·²æ¥æ”¶æ¥è‡ª {agent_type}, url: {base_url}")

            # è§£æå“åº”å†…å®¹
            resp_result = response.model_dump(mode='json', exclude_none=True)
            content = result2reply_text(resp_result)

            # å°è¯•è§£æJSONè·å–å®é™…å†…å®¹
            try:
                if isinstance(content, str) and content.startswith('{'):
                    content_data = json.loads(content)
                    if "result" in content_data:
                        actual_content = content_data["result"]
                    else:
                        actual_content = str(content_data)
                else:
                    actual_content = str(content)
            except json.JSONDecodeError:
                actual_content = str(content)

            # ä½¿ç”¨æŒ‰è¯åˆ†å‰²çš„æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼ˆä»…ä½œä¸ºé™çº§æ–¹æ¡ˆï¼‰
            words = actual_content.split()
            for i, word in enumerate(words):
                if i > 0:
                    yield " "
                yield word
                await asyncio.sleep(0.01)  # åŠ å¿«æ¨¡æ‹Ÿæµå¼é€Ÿåº¦
                        
        except Exception as e:
            error_msg = f"A2Aè¯·æ±‚ {base_url} å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            yield f"é”™è¯¯: {error_msg}"


async def system_perception_stream(state: AgentState, node: Node):
    """
    ç³»ç»Ÿæ„ŸçŸ¥ agentï¼Œæµå¼ç‰ˆæœ¬
    """
    agent = "system_perception"
    logger.info(f"Agent {agent} æ‰§è¡Œä¸­...")

    hostname = node.hostname
    task = state['query']
    expert = node.expert

    if task:
        push_user_turn(state, hostname, task)

    # æµå¼è°ƒç”¨å­ä»£ç†å¹¶ç´¯ç§¯ç»“æœ
    reply_text = ""
    async for token in agent_quest_stream(agent, node, task):
        reply_text += token
        yield token

    # ä¿å­˜å®Œæ•´ç»“æœåˆ°çŠ¶æ€
    push_agent_turn(state, hostname, node.agent_type, reply_text)
    state["result"][agent] = reply_text
    
    # æ›´æ–°çŠ¶æ€
    state["hostname"] = hostname
    state["sub_task"] = ''
    state["expert"] = expert
    state["status"] = "success"


async def anomaly_analysis_stream(state: AgentState, node: Node):
    """
    å¼‚å¸¸åˆ†æ agentï¼Œæµå¼ç‰ˆæœ¬
    """
    agent = "anomaly_analysis"
    logger.info(f"Agent {agent} æ‰§è¡Œä¸­...")

    hostname = node.hostname
    sub_task = state['query']

    if sub_task:
        push_user_turn(state, hostname, sub_task)

    # æµå¼è°ƒç”¨å­ä»£ç†å¹¶ç´¯ç§¯ç»“æœ
    # reply_text = ""
    # async for token in agent_quest_stream(agent, node, sub_task):
    #     reply_text += token
    #     yield token

    if "æŒ‡æ ‡" in sub_task or "å¼‚å¸¸" in sub_task:
        payload = {
            "folder_path": "/home/tanxh/mas/agents/anomaly_model/AnomalyDetection/data/Dataset1/Node1.csv"
        }
        url = f"http://localhost:5411/time_series_ad"
        response = requests.post(url, json=payload)
        agent_result = response.json()
    elif "æ ¹å› å®šä½" in sub_task:
        payload = {
            "folder_path": "/home/tanxh/mas/agents/anomaly_model/HPC_RCA_Demo/dataset",
            "job_id": "job_8113170",
            "failure_start": 1750129350,
            "failure_end": 1750129800,
            "failure_type": "network_bandwidth",
            "root_node": "cn61903",
            "golden_metrics": [],
            "top_k": 5
        }
        url = f"http://localhost:5410/locate_root_cause"
        response = requests.post(url, json=payload)
        agent_result = response.json()
    else:
        agent_result = "no reply"

    reply_text = result2reply_text(agent_result)
    yield f"{reply_text}\n"

    push_agent_turn(state, hostname, node.agent_type, reply_text)
    state["result"][agent] = reply_text
    
    # æ›´æ–°çŠ¶æ€
    state["hostname"] = hostname
    state["sub_task"] = ''
    state["status"] = "success"


async def strategy_plan_stream(state: AgentState, node: Node):
    """
    ç­–ç•¥è§„åˆ’ agentï¼Œæµå¼ç‰ˆæœ¬
    """
    agent = "strategy_plan"
    logger.info(f"Agent {agent} æ‰§è¡Œä¸­...")

    hostname = node.hostname
    query = state['query']
    up_process_result = state.get("result") if state.get("result") else state.get('query')

    # æ„å»ºä¸Šæ¸¸ç»“æœæŠ¥å‘Š
    if isinstance(up_process_result, dict):
        full_report_lines = []
        for agent_name, raw in up_process_result.items():
            if isinstance(raw, str):
                if raw.startswith("æ ¹å› èŠ‚ç‚¹:") or ("root_cause" in raw and "æ•…éšœç±»å‹" in raw):
                    full_report_lines.append(f"## Agent: anomaly_analysis")
                    full_report_lines.append("```")
                    full_report_lines.append(raw.strip())
                    full_report_lines.append("```")
                    full_report_lines.append("")
                    continue

                if raw.startswith("æŒ‡æ ‡æ—¶åº") or ("å¼‚å¸¸ç‚¹" in raw):
                    full_report_lines.append(f"## Agent: anomaly_analysis")
                    full_report_lines.append("```")
                    full_report_lines.append(raw.strip())
                    full_report_lines.append("```")
                    full_report_lines.append("")
                    continue

            text = str(raw).replace("\\n", "\n").replace("\\t", "\t")
            full_report_lines.append(f"## Agent: {agent_name}")
            full_report_lines.append(text)

        all_up_res = "\n".join(full_report_lines)
    elif isinstance(up_process_result, str):
        all_up_res = up_process_result
    else:
        all_up_res = str(up_process_result)

    anomaly_desc = f"# {query}\n\n{all_up_res}"
    push_user_turn(state, hostname, anomaly_desc)

    # æµå¼è°ƒç”¨å­ä»£ç†å¹¶ç´¯ç§¯ç»“æœ
    reply_text = ""
    async for token in agent_quest_stream(agent, node, anomaly_desc):
        reply_text += token
        yield token

    push_agent_turn(state, hostname, node.agent_type, reply_text)
    state["result"][agent] = reply_text
    
    # æ›´æ–°çŠ¶æ€
    state["hostname"] = hostname
    state["status"] = "success"


async def report_generate_stream(state: AgentState, node: Node):
    """
    æŠ¥å‘Šåé¦ˆ agentï¼Œæµå¼ç‰ˆæœ¬
    """
    agent = "report_generate"
    logger.info(f"Agent {agent} æ‰§è¡Œä¸­...")

    hostname = node.hostname
    results = state.get("result") if state.get("result") else state.get('query')

    # æ„å»ºå®Œæ•´æŠ¥å‘Š
    if isinstance(results, dict):
        full_report_lines = []
        for agent_name, raw in results.items():
            if isinstance(raw, str):
                if raw.startswith("æ ¹å› èŠ‚ç‚¹:") or ("root_cause" in raw and "æ•…éšœç±»å‹" in raw):
                    full_report_lines.append(f"## Agent: anomaly_analysis")
                    full_report_lines.append("```")
                    full_report_lines.append(raw.strip())
                    full_report_lines.append("```")
                    full_report_lines.append("")
                    continue

                if raw.startswith("æŒ‡æ ‡æ—¶åº") or ("å¼‚å¸¸ç‚¹" in raw):
                    full_report_lines.append(f"## Agent: anomaly_analysis")
                    full_report_lines.append("```")
                    full_report_lines.append(raw.strip())
                    full_report_lines.append("```")
                    full_report_lines.append("")
                    continue

            text = str(raw).replace("\\n", "\n").replace("\\t", "\t")
            full_report_lines.append(f"## Agent: {agent_name}")
            full_report_lines.append(text)

        full_report_lines.append(f"## Query: {state['query']}")
        full_report = "\n".join(full_report_lines)
    elif isinstance(results, str):
        full_report = f"## Query: {results}"
    else:
        full_report = str(results)

    push_user_turn(state, hostname, full_report)

    # æµå¼è°ƒç”¨å­ä»£ç†å¹¶ç´¯ç§¯ç»“æœ
    reply_text = ""
    async for token in agent_quest_stream(agent, node, full_report):
        reply_text += token
        yield token

    push_agent_turn(state, hostname, node.agent_type, reply_text)
    state["result"][agent] = reply_text
    
    # æ›´æ–°çŠ¶æ€
    state["hostname"] = hostname
    state["status"] = "success"


async def agent_quest(agent_type: str, node: Node, query: str):
    """
    é‡‡ç”¨å¼‚æ­¥é€šä¿¡å¤„ç†httpäº¤äº’ï¼Œ  ä»»åŠ¡è§£æ â€”â€” å…¶ä»– agent â€”â€” å¤§æ¨¡å‹ api
    """
    hostname = node.hostname or node.name.split("_")[0]
    if hostname in {"start", "end"}:
        return ""

    base_url = build_agent_url(agent_type, hostname)

    # mem_msg = [
    #     {"role": "user", "content": query},
    #     {"role": "assistant", "content": ''}
    # ]

    # mem_res = mem0.add(
    #     mem_msg,
    #     user_id = 'agent',
    #     metadata = {"source": "chat", "time": time.time()}
    # )
    # report_memory_changes(mem_res.get("results", []))

    async with httpx.AsyncClient(verify=False, timeout=300, proxy=None) as httpx_client:
        resolver = A2ACardResolver(httpx_client=httpx_client, base_url=base_url,)
        final_agent_card_to_use = await resolver.get_agent_card()
        client = A2AClient(httpx_client=httpx_client, agent_card=final_agent_card_to_use)

        # mems = mem0.search(query, user_id='agent', limit=5)
        # mem_context = "\n".join(f"- {r['memory']}" for r in mems["results"])

        # system_prompt = f"{query}\nä»¥ä¸‹æ˜¯ä¸ç”¨æˆ·ç›¸å…³çš„è®°å¿†ï¼š\n{mem_context}\nè¯·å›ç­”"

        payload = {
            "message": {
                "role": "user",
                "parts": [{"type": "text", "text": query}],
                "messageId": uuid.uuid4().hex,
            },
        }
        logger.info(f"Sending request to {agent_type}, url: {base_url}")

        # return collected_text
        request = SendMessageRequest(
            id=str(uuid.uuid4()), params=MessageSendParams(**payload)
        )

        response = await client.send_message(request)
        logger.info(f"Response received from {agent_type}, url: {base_url}")

        resp_result = response.model_dump(mode='json', exclude_none=True)

        return resp_result


async def system_perception(state: AgentState, node: Node):
    """
    ç³»ç»Ÿæ„ŸçŸ¥ agentï¼Œè´Ÿè´£æ”¶é›†ç³»ç»ŸçŠ¶æ€ä¿¡æ¯
    """
    agent = "system_perception"
    # print(f"Agent {agent} æ‰§è¡Œä¸­...")
    logger.info(f"Agent {agent} æ‰§è¡Œä¸­...")

    # ä»èŠ‚ç‚¹ä¸­æå–ç›¸å…³ä¿¡æ¯
    hostname = node.hostname
    task = state['query']
    expert = node.expert

    if task:
        push_user_turn(state, hostname, task)

    agent_result = await agent_quest(agent, node, task)

    # å°†ç»“æœè½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼
    reply_text = result2reply_text(agent_result)
    reply_text = json.loads(reply_text)["result"]

    # å°† agent çš„å“åº”è®°å½•åˆ°çŠ¶æ€
    push_agent_turn(state, hostname, node.agent_type, reply_text)
    # logger.info(f"Agent {agent} å“åº”: {str(json.loads(reply_text)['state_exp'])}")

    # è¿”å›å·®åˆ†ç»“æœï¼Œæ›´æ–°çŠ¶æ€
    return {
        "hostname": hostname,
        "sub_task": '',
        "expert": expert,
        "result": {agent: reply_text},
        "status": "success",
    }


async def anomaly_analysis(state: AgentState, node: Node):
    """
    å¼‚å¸¸åˆ†æ agentï¼Œæ ¹æ®æ¨¡å‹åˆ†æç»“æœæ¥å®šä½å¼‚å¸¸æ ¹å› 
    """
    # return state
    agent = "anomaly_analysis"
    # print(f"Agent {agent} æ‰§è¡Œä¸­...")
    logger.info(f"Agent {agent} æ‰§è¡Œä¸­...")

    hostname  = node.hostname
    sub_task  = state['query']

    if sub_task:
        push_user_turn(state, hostname, sub_task)

    # è°ƒç”¨ agent
    if "æŒ‡æ ‡" in sub_task or "å¼‚å¸¸" in sub_task:
        payload = {
            "folder_path": "/home/tanxh/mas/agents/anomaly_model/AnomalyDetection/data/Dataset1/Node1.csv"
        }
        url = f"http://localhost:5411/time_series_ad"
        response = requests.post(url, json=payload)
        agent_result = response.json()
    elif "æ ¹å› å®šä½" in sub_task:
        payload = {
            "folder_path": "/home/tanxh/mas/agents/anomaly_model/HPC_RCA_Demo/dataset",
            "job_id": "job_8113170",
            "failure_start": 1750129350,
            "failure_end": 1750129800,
            "failure_type": "network_bandwidth",
            "root_node": "cn61903",
            "golden_metrics": [],
            "top_k": 5
        }
        url = f"http://localhost:5410/locate_root_cause"
        response = requests.post(url, json=payload)
        agent_result = response.json()
    else:
        agent_result = "no reply"

    reply_text = result2reply_text(agent_result)

    # è®°å½•å“åº”
    push_agent_turn(state, hostname, node.agent_type, reply_text)
    # logger.info(f"Agent {agent} å“åº”: {str(reply_text)}")

    return {
        "hostname": hostname,
        "sub_task": '',
        "result": {agent: reply_text},
        "status": "success",
    }


async def strategy_plan(state: AgentState, node: Node):
    """
    ç­–ç•¥è§„åˆ’ agentï¼Œé€šè¿‡ä¸Šæ¸¸èŠ‚ç‚¹çš„ç»“æœæ¥ç”Ÿæˆä¿®å¤ç­–ç•¥
    """
    agent = "strategy_plan"
    logger.info(f"Agent {agent} æ‰§è¡Œä¸­...")

    hostname = node.hostname
    query = state['query']
    up_process_result = state.get("result") if state.get("result") else state.get('query')

    if isinstance(up_process_result, dict):
        full_report_lines = []

        for agent_name, raw in up_process_result.items():
            if isinstance(raw, str):
                if raw.startswith("æ ¹å› èŠ‚ç‚¹:") or ("root_cause" in raw and "æ•…éšœç±»å‹" in raw):
                    full_report_lines.append(f"## Agent: anomaly_analysis")
                    full_report_lines.append("```")
                    full_report_lines.append(raw.strip())
                    full_report_lines.append("```")
                    full_report_lines.append("")
                    continue

                if raw.startswith("æŒ‡æ ‡æ—¶åº") or ("å¼‚å¸¸ç‚¹" in raw):
                    full_report_lines.append(f"## Agent: anomaly_analysis")
                    full_report_lines.append("```")
                    full_report_lines.append(raw.strip())
                    full_report_lines.append("```")
                    full_report_lines.append("")
                    continue

            text = raw.replace("\\n", "\n").replace("\\t", "\t")
            blocks = re.split(r'(?=ã€[^ã€‘]+ã€‘)', text)
            for block in blocks:
                m = re.match(r'ã€([^ã€‘]+)ã€‘\s*(.*)', block, re.DOTALL)
                if not m:
                    continue
                sub_host, rest = m.group(1), m.group(2).strip()
                full_report_lines.append(f"## Agent: {agent_name}")
                full_report_lines.append(f"### {sub_host}")
                full_report_lines.append("```")
                full_report_lines.append(rest)
                full_report_lines.append("```")
                full_report_lines.append("")

        # full_report_lines.append(state['query'])
        all_up_res = "\n".join(full_report_lines)

    elif isinstance(up_process_result, str):
        all_up_res = up_process_result

    anomaly_desc = f"# {query}\n{all_up_res}"
    push_user_turn(state, hostname, anomaly_desc)

    # è°ƒç”¨ agent
    agent_result = await agent_quest(agent, node, anomaly_desc)

    reply_text = result2reply_text(agent_result)
    reply_text = json.loads(reply_text)["result"]

    push_agent_turn(state, hostname, node.agent_type, reply_text)

    return {
        "hostname": hostname,
        "result": {agent: reply_text},
        "status": "success",
    }


async def report_generate(state: AgentState, node: Node):
    """
    æŠ¥å‘Šåé¦ˆ agentï¼Œè´Ÿè´£ç”Ÿæˆæœ€ç»ˆè¿ç»´æŠ¥å‘Š
    """
    agent = "report_generate"
    # print(f"Agent {agent} æ‰§è¡Œä¸­...")
    logger.info(f"Agent {agent} æ‰§è¡Œä¸­...")

    hostname  = node.hostname
    results = state.get("result") if state.get("result") else state.get('query')

    if isinstance(results, dict):
        full_report_lines = []

        for agent_name, raw in results.items():
            # 1. å°è¯•è§£æä¸º JSON å¹¶æå– state_exp
            if isinstance(raw, str):
                # åˆ¤æ–­æ˜¯å¦ä¸ºæ ¹å› åˆ†ææ ¼å¼
                if raw.startswith("æ ¹å› èŠ‚ç‚¹:") or ("root_cause" in raw and "æ•…éšœç±»å‹" in raw):
                    # ç›´æ¥è¾“å‡º
                    full_report_lines.append(f"## Agent: anomaly_analysis")
                    full_report_lines.append("```")
                    full_report_lines.append(raw.strip())
                    full_report_lines.append("```")
                    full_report_lines.append("")
                    continue

                if raw.startswith("æŒ‡æ ‡æ—¶åº") or ("å¼‚å¸¸ç‚¹" in raw):
                    # ç›´æ¥è¾“å‡º
                    full_report_lines.append(f"## Agent: anomaly_analysis")
                    full_report_lines.append("```")
                    full_report_lines.append(raw.strip())
                    full_report_lines.append("```")
                    full_report_lines.append("")
                    continue

            # 3. é»˜è®¤æŒ‰ state_exp æ ¼å¼å¤„ç†
            # è§£ç è½¬ä¹‰å­—ç¬¦
            text = raw.replace("\\n", "\n").replace("\\t", "\t")
            # åˆ†å‰²æ¯ä¸ªä¸»æœºå—
            blocks = re.split(r'(?=ã€[^ã€‘]+ã€‘)', text)
            for block in blocks:
                m = re.match(r'ã€([^ã€‘]+)ã€‘\s*(.*)', block, re.DOTALL)
                if not m:
                    continue
                sub_host, rest = m.group(1), m.group(2).strip()
                full_report_lines.append(f"## Agent: {agent_name}")
                full_report_lines.append(f"### {sub_host}")
                full_report_lines.append("```")
                full_report_lines.append(rest)
                full_report_lines.append("```")
                full_report_lines.append("")

        full_report_lines.append(state['query'])
        full_report = "\n".join(full_report_lines)

    elif isinstance(results, str):
        full_report = results

    push_user_turn(state, hostname, full_report)

    # è°ƒç”¨ agent
    result = await agent_quest(agent, node, full_report)

    reply_text = result2reply_text(result)
    reply_text = json.loads(reply_text)["result"]

    # è®°å½•å“åº”
    push_agent_turn(state, hostname, node.agent_type, reply_text)
    # logger.info(f"Agent {agent} å“åº”: {str(reply_text)}")

    return {
        "hostname": hostname,
        "result": {agent: reply_text},
        "status": "success",
    }


# agentè°ƒç”¨ç´¢å¼•ï¼ŒæŒ‰ç…§èŠ‚ç‚¹åç§°é…ç½®åˆé€‚çš„èŠ‚ç‚¹æ‰§è¡Œå‡½æ•°
agent_dict = {"ç³»ç»Ÿæ„ŸçŸ¥Agent": system_perception_stream, "å¼‚å¸¸åˆ†æAgent": anomaly_analysis_stream, "ç­–ç•¥è§„åˆ’Agent": strategy_plan_stream,
            "æŠ¥å‘Šåé¦ˆAgent": report_generate_stream}


class WorkGraph:
    def __init__(self, dag, start):
        self.graph = None
        self.dag = dag
        self.start = start


    def create_fallback_judge_branch(self, workflow: StateGraph, pre_node, fallback_node):
        # è®¾ç½®å¼‚å¸¸åˆ¤æ–­è¾¹
        def fallback_judge(state: AgentState):
            return "error" if state.get("status") == "error" else "success"

        dag_next_node = self.dag[pre_node].next_nodes[0]
        # å¦‚æœä¸‹ä¸€è·³æ˜¯å­—ç¬¦ä¸² 'END'ï¼Œå°±æ¢æˆå¸¸é‡ END
        dag_next_node = END if dag_next_node == "END" else dag_next_node

        workflow.add_conditional_edges(
            pre_node,
            fallback_judge,
            {"error": fallback_node, "success": dag_next_node},
            # {"error": fallback_node, "success": next_node_name_or_END},
        )
        # print(f"ä¸ºèŠ‚ç‚¹{pre_node}åˆ›å»ºå¼‚å¸¸åˆ¤æ–­åˆ†æ”¯")


    def create_fallback_node(self, workflow):
        """
        é‡æ•…éšœè‡ªåŠ¨åˆ‡æ¢å¤„ç†ç­–ç•¥,
        è®¾ç½®ä¸€ä¸ªç‹¬ç«‹çš„å¼‚å¸¸å¤„ç†èŠ‚ç‚¹,æ¯ä¸ªèŠ‚ç‚¹è¿è¡Œåä½¿ç”¨æ¡ä»¶è¾¹åˆ¤æ–­å¼‚å¸¸å†äº¤ä»˜
        """

        def fall_back(state: AgentState):
            """
            å¼‚å¸¸å¤„ç†å‡½æ•°ï¼Œå¯æ‰©å±•å¢æ·»å…¶ä»–åŠŸèƒ½
            """
            # print("å¼‚å¸¸å¤„ç†èŠ‚ç‚¹")
            # print("ç³»ç»ŸçŠ¶æ€:", state["status"])
            # return
            push_agent_turn(state, "fallback_node",
                    f"å·²è§¦å‘å›é€€ï¼ŒåŸå› ï¼š{state['error_message']}")
            return {"status": "success"}

        workflow.add_node("fallback_node", fall_back)
        workflow.add_edge("fallback_node", END)
        # print("å¼‚å¸¸å¤„ç†èŠ‚ç‚¹åˆ›å»ºå®Œæˆ")


    def dag_to_langgraph(self):
        workflow = StateGraph(AgentState)

        # åˆå§‹åŒ–å¼‚å¸¸å¤„ç†èŠ‚ç‚¹
        self.create_fallback_node(workflow)
        for node in self.dag.values():
            workflow.add_node(node.name, partial(agent_dict[node.agent_type], node=node))
            self.create_fallback_judge_branch(workflow, node.name, "fallback_node")
            # print(f"èŠ‚ç‚¹{node.name}åˆ›å»ºæˆåŠŸ")

        for node in self.dag.values():
            next_nodes = node.next_nodes
            for next_node_name in next_nodes:
                if next_node_name == 'END':
                    workflow.add_edge(node.name, END)
                else:
                    workflow.add_edge(node.name, next_node_name)

        # è®¾ç½®å…¥å£
        workflow.set_entry_point(self.start)

        # ç¼–è¯‘å›¾
        self.graph = workflow.compile()


    def draw_graph(self):
        output_path = "agent_a6000/task_analysis/graph_figs/workflow_dag.png"

        self.graph.get_graph().draw_png(
            output_file_path = output_path,
            fontname = "Noto Sans CJK SC",
        )


    async def run_workflow_stream(self, task):
        """
        æµå¼è¿è¡Œå·¥ä½œæµï¼Œè¾“å‡ºæ ‡å‡†OpenAIæ ¼å¼
        """
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = {
            "messages": [],
            "query": task,
            "result": {},
            "status": 'success',
            "error_code": 0,
            "error_message": '',
            "hostname": None,
            "sub_task": None,
            "expert": None
        }
        
        push_user_turn(initial_state, None, task)
        
        # æŒ‰ç…§DAGé¡ºåºæ‰§è¡ŒèŠ‚ç‚¹ï¼Œæµå¼è¾“å‡º
        current_node = self.start
        state = initial_state
        
        # æµå¼èŠ‚ç‚¹å‡½æ•°æ˜ å°„
        stream_agent_dict = {
            "ç³»ç»Ÿæ„ŸçŸ¥Agent": system_perception_stream,
            "å¼‚å¸¸åˆ†æAgent": anomaly_analysis_stream,
            "ç­–ç•¥è§„åˆ’Agent": strategy_plan_stream,
            "æŠ¥å‘Šåé¦ˆAgent": report_generate_stream
        }
        
        while current_node != "END":
            node = self.dag[current_node]
            
            # æµå¼æ‰§è¡Œå½“å‰èŠ‚ç‚¹
            if node.agent_type in stream_agent_dict:
                stream_func = stream_agent_dict[node.agent_type]
                
                async for token in stream_func(state, node):
                    if token.strip():
                        # è¾“å‡ºæ ‡å‡†OpenAIæµå¼æ ¼å¼
                        chunk = {
                            "choices": [{
                                "delta": {"content": token},
                                "index": 0,
                                "finish_reason": None
                            }]
                        }
                        yield f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"
                
            else:
                # é™çº§å¤„ç†ï¼šå¦‚æœæ²¡æœ‰æµå¼ç‰ˆæœ¬ï¼Œä½¿ç”¨åŸç‰ˆæœ¬
                result = await agent_dict[node.agent_type](state, node)
                if result and "result" in result:
                    for agent_name, agent_result in result["result"].items():
                        content = str(agent_result)
                        # æŒ‰è¯åˆ†å‰²è¾“å‡º
                        words = content.split()
                        for word in words:
                            chunk = {
                                "choices": [{
                                    "delta": {"content": word + " "},
                                    "index": 0,
                                    "finish_reason": None
                                }]
                            }
                            yield f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"
                        state["result"][agent_name] = agent_result
            
            # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
            if node.next_nodes and node.next_nodes[0] != "END":
                current_node = node.next_nodes[0]
            else:
                break
        
        # è¾“å‡ºç»“æŸæ ‡è®°
        final_chunk = {
            "choices": [{
                "delta": {},
                "index": 0,
                "finish_reason": "stop"
            }]
        }
        yield f"data: {json.dumps(final_chunk, ensure_ascii=False)}\n\n"
        yield f"data: [DONE]\n\n"

    async def run_workflow(self, task):
        initial_state = {
            "messages": [],
            "query": task,
            "result": {},
            "status": 'success',
            "error_code": 0,
            "error_message": '',
            "hostname": None,
            "sub_task": None,
            "expert": None
        }

        # è°ƒç”¨ graphï¼Œä¼ å…¥åˆå§‹ state
        config = {"configurable": {"thread_id": str(uuid.uuid4())}}
        push_user_turn(initial_state, None, task)
        final_state = await self.graph.ainvoke(initial_state, config)
        payload = final_state["result"]

        try:
            result = json.dumps(payload, ensure_ascii=False, indent=2)
        except TypeError:
            result = str(payload)

        # print(f"ğŸš© Final payload: {result}")
        return result


def process_resp(result_str):
    resp = json.loads(result_str)

    final_key = "report_generate"
    if final_key not in resp:
        raise ValueError(f"ç¼ºå°‘æœ€ç»ˆæŠ¥å‘Š")

    # 1. ä¼˜åŒ–ä¸»æœºå‘½ä»¤è¾“å‡ºæ ¼å¼
    cmd_md_parts = []
    for agent, md in resp.items():
        if agent == final_key:
            continue
        if isinstance(md, str):
            blocks = re.split(r'(?=ã€[^ã€‘]+ã€‘)', md)
            for block in blocks:
                m = re.match(r'ã€([^ã€‘]+)ã€‘\s*(.*)', block, re.DOTALL)
                if not m:
                    continue
                sub_host, rest = m.group(1), m.group(2).strip()
                cmd_md_parts.append(f"## {sub_host}")
                cmd_md_parts.append("")
                cmd_md_parts.append("```bash")
                cmd_md_parts.append(rest)
                cmd_md_parts.append("```")
                cmd_md_parts.append("")
        else:
            cmd_md_parts.append(str(md))
    cmds_result = "\n".join(cmd_md_parts)

    # 2. ä¼˜åŒ–æœ€ç»ˆæŠ¥å‘Šæ ¼å¼ï¼ˆå»é™¤å¤šä½™ä»£ç å—æ ‡è®°ï¼‰
    final_md = resp[final_key].strip()
    final_md = re.sub(r'^\s*```markdown\s*', '', final_md)
    final_md = re.sub(r'\s*```\s*$', '', final_md)
    # url = "https://img1.baidu.com/it/u=2723109506,3664589887&fm=253&fmt=auto&app=138&f=JPEG?w=955&h=500"
    # md_img = f"![ç¤ºä¾‹å›¾ç‰‡](<{url}>)"

    # final_return = f"{cmds_result}\n{final_md}\n{md_img}".strip()
    final_return = f"{cmds_result}\n{final_md}".strip()

    return JSONResponse({
        "choices": [{
                "message": {"role": "assistant", "content": final_return}
            }]
    })


# === OpenWebUI é£æ ¼ API é›†æˆ ===
openwebui_app = FastAPI()


@openwebui_app.get("/v1/models")
async def get_models():
    return JSONResponse({
        "object": "list",
        "data": [
            {
                "id": "MAS",  # è¿™ä¸ªå¿…é¡»å’Œ chat è¯·æ±‚ä¸­çš„ model ä¿æŒä¸€è‡´
                "object": "model",
                "created": int(time.time()),
                "owned_by": "local"
            }
        ]
    })


@openwebui_app.post("/v1/chat/completions")
async def chat_completions(request: Request):
    """
    OpenAIå…¼å®¹çš„èŠå¤©å®Œæˆæ¥å£ï¼Œæ”¯æŒæµå¼å“åº”
    """
    data = await request.json()
    
    # å…¼å®¹å¤šç§è¾“å…¥æ ¼å¼
    user_query = ""
    if "messages" in data and isinstance(data["messages"], list):
        user_query = data["messages"][-1].get("content", "")
    elif "prompt" in data:
        user_query = data["prompt"]
    else:
        user_query = data.get("query", "")
    
    if not user_query:
        return JSONResponse({
            "error": {
                "message": "æœªæä¾›ç”¨æˆ·æŸ¥è¯¢å†…å®¹",
                "type": "invalid_request_error",
                "code": "missing_query"
            }
        }, status_code=400)

    # æ£€æŸ¥æ˜¯å¦ä¸ºæµå¼è¯·æ±‚
    stream = data.get("stream", False)
    
    try:
        node_dict, start = generate_dag_dict(user_query)
        # ä»»åŠ¡ç±»å‹ä¸ºâ€œå…¶ä»–â€æ—¶ç›´æ¥è¿”å›é€šçŸ¥ç®¡ç†å‘˜
        if node_dict is None and isinstance(start, str):
            notify_msg = f'{start}\n'
            if stream:
                async def notify_stream():
                    chunk = {
                        "choices": [{
                            "delta": {"content": notify_msg},
                            "index": 0,
                            "finish_reason": "stop"
                        }]
                    }
                    yield f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"
                    yield f"data: [DONE]\n\n"
                return StreamingResponse(notify_stream(), media_type="text/plain")
            else:
                return JSONResponse({
                    "choices": [{
                        "message": {
                            "role": "assistant",
                            "content": notify_msg
                        },
                        "index": 0,
                        "finish_reason": "stop"
                    }]
                })

        graph = WorkGraph(node_dict, start)
        graph.dag_to_langgraph()
        graph.draw_graph()
        
        if stream:
            # æµå¼å“åº”ï¼Œæ ‡å‡†OpenAIæ ¼å¼
            async def generate_stream():
                try:
                    async for chunk in graph.run_workflow_stream(user_query):
                        yield chunk
                except Exception as e:
                    # æµå¼é”™è¯¯å¤„ç†
                    error_chunk = {
                        "choices": [{
                            "delta": {"content": f"\n\né”™è¯¯: {str(e)}"},
                            "index": 0,
                            "finish_reason": "stop"
                        }]
                    }
                    yield f"data: {json.dumps(error_chunk, ensure_ascii=False)}\n\n"
                    yield f"data: [DONE]\n\n"
            
            return StreamingResponse(
                generate_stream(),
                media_type="text/plain",
                headers={
                    "Content-Type": "text/plain; charset=utf-8",
                    "Cache-Control": "no-cache",
                    "Connection": "keep-alive"
                }
            )
        else:
            # éæµå¼å“åº”ï¼Œæ ‡å‡†OpenAIæ ¼å¼
            result = await graph.run_workflow(user_query)
            processed_result = process_resp(result)
            
            # æå–å†…å®¹
            if hasattr(processed_result, 'body') and processed_result.body:
                content_data = json.loads(processed_result.body.decode('utf-8'))
                if "choices" in content_data and content_data["choices"]:
                    final_content = content_data["choices"][0]["message"]["content"]
                else:
                    final_content = str(content_data)
            else:
                final_content = str(result)
            
            # è¿”å›æ ‡å‡†OpenAIæ ¼å¼
            return JSONResponse({
                "choices": [{
                    "message": {
                        "role": "assistant",
                        "content": final_content
                    },
                    "index": 0,
                    "finish_reason": "stop"
                }]
            })
            
    except Exception as e:
        logger.exception("Agent workflow error:")
        
        if stream:
            # æµå¼é”™è¯¯å“åº”
            async def error_stream():
                error_chunk = {
                    "choices": [{
                        "delta": {"content": f"é”™è¯¯: {str(e)}"},
                        "index": 0,
                        "finish_reason": "stop"
                    }]
                }
                yield f"data: {json.dumps(error_chunk, ensure_ascii=False)}\n\n"
                yield f"data: [DONE]\n\n"
            return StreamingResponse(error_stream(), media_type="text/plain")
        else:
            # éæµå¼é”™è¯¯å“åº”
            return JSONResponse({
                "error": {
                    "message": str(e),
                    "type": "api_error",
                    "code": "workflow_failed"
                }
            }, status_code=500)


def main() -> None:
    uvicorn.run(openwebui_app, host="0.0.0.0", port=5000)


# === å¯åŠ¨ FastAPI ===
if __name__ == '__main__':
    main()