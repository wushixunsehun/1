import os, re, sys
sys.path.append('./')
log_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'logs')
os.makedirs(log_dir, exist_ok=True)


import time, yaml
import json, uuid
import httpx, uvicorn
from mem0 import Memory
import logging, requests
from pathlib import Path
from typing import Optional
from functools import partial
from agent_state import AgentState
from fastapi import FastAPI, Request
from langgraph.graph import StateGraph, END
from agentsAPI import query_llm, strip_think
from a2a.client import A2ACardResolver, A2AClient
from a2a.types import MessageSendParams, SendMessageRequest
from fastapi.responses import JSONResponse, StreamingResponse
from prompts import UPDATE_MEMORY_PROMPT, custom_fact_extraction_prompt


logging.basicConfig(
    filename = os.path.join(log_dir, "task_analysis_agent.log"),
    level = logging.INFO,
    format = "%(asctime)s [%(levelname)s] %(name)s: %(message)s",
)
logger = logging.getLogger(__name__)
httpx_logger = logging.getLogger("httpx")
httpx_logger.setLevel(logging.WARNING)
httpx_logger.propagate = False


agents_dir = Path(__file__).resolve().parents[2]
config_path = agents_dir / "config.yaml"
with open(config_path, 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)

llm_model = config.get("llm", {}).get("model")
llm_host = config.get("llm", {}).get("base_url")
embedding_model = config.get("rag", {}).get("embedding_model")
embedding_host = config.get("rag", {}).get("base_url")
api_key = config.get("rag", {}).get("api_key")

milvus_collection = config.get("collections", {}).get("mem0_col")
milvus_host = config.get("milvus", {}).get("uri")
milvus_token = config.get("milvus", {}).get("token")


mem0_config = {
    "version": "v1.1",
    "custom_fact_extraction_prompt": custom_fact_extraction_prompt,

    # --- 8< --- æœ¬åœ° LLM æœåŠ¡ --- 8< ---
    "llm": {
        "provider": "openai",
        "config": {
            "model": llm_model,
            "openai_base_url": llm_host,
            "api_key": api_key,
        }
    },

    # --- 8< --- æœ¬åœ° Embedding æœåŠ¡ --- 8< ---
    "embedder": {
        "provider": "openai",
        "config": {
            "model": embedding_model,
            "openai_base_url": embedding_host,
            "api_key": api_key,
            "embedding_dims": 768,
        }
    },

    # --- 8< --- Milvus å‘é‡åº“ --- 8< ---
    "vector_store": {
        "provider": "milvus",
        "config": {
            "collection_name": milvus_collection,
            "embedding_model_dims": 768,
            "url": milvus_host,
            "token": milvus_token,
        }
    },

    # --- 8< --- è‡ªå®šä¹‰æ›´æ–°è®°å¿†æç¤ºè¯ --- 8< ---
    "prompts": {
        "update_memory": UPDATE_MEMORY_PROMPT,
    }
}

# mem0 = Memory.from_config(mem0_config)


class Node:
    def __init__(
        self,
        name: str,
        agent_type: str,
        next_nodes: list[str],
        hostname: Optional[str] = None,
        expert: Optional[str] = None,
        sub_task: Optional[str] = None,
    ):
        self.name = name
        self.agent_type = agent_type
        self.next_nodes = next_nodes
        self.hostname = hostname
        self.expert = expert
        self.sub_task = sub_task

    def add_next_node(self, next_node):
        self.next_nodes.append(next_node)

    def __repr__(self):
        return f"èŠ‚ç‚¹åç§°ï¼š{self.name}ï¼Œç±»å‹ï¼š{self.agent_type}ï¼Œä¸‹ä¸€è·³ï¼š{self.next_nodes}"


TASK_PROMPT_TEMPLATE = '''ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ™ºèƒ½ç³»ç»Ÿä»»åŠ¡å†³ç­–ä¸“å®¶ï¼Œè¯·ä¸¥æ ¼æ ¹æ®ç”¨æˆ·è¾“å…¥çš„ä»»åŠ¡æè¿°è¿›è¡Œæ„å›¾åˆ†æï¼Œå¹¶ç²¾ç¡®åŒ¹é…åˆ°ä»¥ä¸‹ä»»åŠ¡ç±»å‹ï¼š

### ä»»åŠ¡ç±»å‹å®šä¹‰
**çŸ¥è¯†é—®ç­”ä»»åŠ¡**
- ç‰¹å¾ï¼šç”¨æˆ·è¯¢é—®äº‹å®æ€§/è§£é‡Šæ€§é—®é¢˜ã€‚
- ç³»ç»Ÿè¡Œä¸ºï¼šæ£€ç´¢çŸ¥è¯†åº“(RAG)ï¼Œæ•´ç†ä¿¡æ¯å¹¶è¾“å‡ºç­”æ¡ˆ
- ç¤ºä¾‹ï¼š
    "å¦‚ä½•å®‰è£… xx è½¯ä»¶/ç¡¬ä»¶ï¼Ÿ"
    "å¦‚ä½•æŸ¥çœ‹ xx èŠ‚ç‚¹çš„çŠ¶æ€ï¼Ÿ"

**çŠ¶æ€æŸ¥è¯¢ä»»åŠ¡**
- ç‰¹å¾ï¼šç”¨æˆ·è¯·æ±‚è·å–ç³»ç»Ÿ/æœåŠ¡çš„å®æ—¶çŠ¶æ€ä¿¡æ¯
- ç³»ç»Ÿè¡Œä¸ºï¼šç”Ÿæˆç»ˆç«¯å‘½ä»¤â†’æ‰§è¡Œæ“ä½œâ†’æ•´ç†çŠ¶æ€æŠ¥å‘Š
- ç¤ºä¾‹ï¼š
    "æ£€æŸ¥ xx æœåŠ¡çš„è¿è¡ŒçŠ¶æ€"
    "xx ä½œä¸šçš„æ´»è·ƒæ—¶é•¿æ˜¯å¤šå°‘ï¼Ÿ"

**å¼‚å¸¸å¤„ç†ä»»åŠ¡**
- ç‰¹å¾ï¼šç”¨æˆ·æŠ¥å‘Šæ•…éšœ/å¼‚å¸¸ï¼Œéœ€è¦è¯Šæ–­å’Œè§£å†³
- ç³»ç»Ÿè¡Œä¸ºï¼šè·å–ç³»ç»ŸçŠ¶æ€â†’åˆ†æåŸå› â†’æ‰§è¡Œä¿®å¤â†’ç”Ÿæˆå¤„ç†æŠ¥å‘Š
- ç¤ºä¾‹ï¼š
    "ç£ç›˜å‡ºç°æŠ¥é”™ï¼Œåˆ†æåŸå› ç»™å‡ºè§£å†³æ–¹æ¡ˆ"
    "xx ä»»åŠ¡è¿è¡Œä¸­æ–­ï¼Œè¯·æ£€æŸ¥åŸå› "

**å†™æ“ä½œä»»åŠ¡**
- ç‰¹å¾ï¼šç”¨æˆ·éœ€è¦å¯¹ç³»ç»Ÿèµ„æºè¿›è¡Œâ€œå†™â€æ“ä½œï¼Œå¦‚ä¿®æ”¹/åˆ›å»ºæ–‡ä»¶ã€æ›´æ–°é…ç½®ç­‰
- ç³»ç»Ÿè¡Œä¸ºï¼šåŸºäºä»»åŠ¡æè¿°ç›´æ¥è°ƒç”¨ç¬¦åˆéœ€æ±‚çš„è„šæœ¬/è¿ç»´å‰§æœ¬â†’æ‰§è¡Œâ†’è¿”å›ç»“æœç¡®è®¤
- ç¤ºä¾‹ï¼š
    "æŠŠ xx ä¸­çš„ xx è°ƒæˆ xx"
    "ä¿®æ”¹ç”¨æˆ· xx çš„ä½œä¸šé…é¢"
    "å–æ¶ˆä½œä¸š xx"

### åˆ†æè§„åˆ™
1. ä¸¥æ ¼åŸºäºæ–‡æœ¬å­—é¢å«ä¹‰åˆ†æï¼Œç¦æ­¢ä¸»è§‚æ¨æµ‹
2. æ— çŠ¶æ€æ“ä½œçš„çŸ¥è¯†è¯·æ±‚ â‰  çŠ¶æ€æŸ¥è¯¢
3. å•çº¯è¯¢é—®è§£å†³æ–¹æ¡ˆ â‰  å¼‚å¸¸å¤„ç†ï¼ˆéœ€å®é™…æ•…éšœæè¿°ï¼‰
4. å¯¹ç³»ç»Ÿèµ„æºçš„å˜æ›´æ“ä½œä¼˜å…ˆå½’ç±»ä¸ºå†™æ“ä½œä»»åŠ¡

### è¾“å‡ºè¦æ±‚
- ä»…è¿”å›å­—ç¬¦ä¸²å½¢å¼çš„ä»»åŠ¡ç±»å‹ï¼ˆçŸ¥è¯†é—®ç­”ä»»åŠ¡ã€çŠ¶æ€æŸ¥è¯¢ä»»åŠ¡ã€å¼‚å¸¸å¤„ç†ä»»åŠ¡ã€å†™æ“ä½œä»»åŠ¡ï¼‰
- ç¦æ­¢ä»»ä½•è§£é‡Šæˆ–é™„åŠ æ–‡æœ¬

è¯·åˆ†æä»»åŠ¡ï¼š{task}
'''


def judge_task_type(task: str):
    prompt = TASK_PROMPT_TEMPLATE.format(task=task)

    enable_thinking = config.get("intent_recog_think")
    if enable_thinking:
        response = query_llm(prompt, enable_thinking=enable_thinking)
        response = strip_think(response).strip()
    else:
        response = query_llm(prompt)

    return response


def generate_dag_dict(task):
    node_dict = {}
    start_node = ""
    
    logger.info(f"è¾“å…¥ä»»åŠ¡:{task}")
    task_type = judge_task_type(task)
    # print(f"ä»»åŠ¡ç±»å‹:{task_type}")
    logger.info(f"ä»»åŠ¡ç±»å‹:{task_type}")


    if task_type == 'çŸ¥è¯†é—®ç­”ä»»åŠ¡':
        """
        æ“ä½œæ‰§è¡Œä»»åŠ¡ï¼šæŠ¥å‘Šåé¦ˆAgent
        """
        node_dict["æŠ¥å‘Šåé¦ˆ"] = Node("æŠ¥å‘Šåé¦ˆ", "æŠ¥å‘Šåé¦ˆAgent", next_nodes=["END"], hostname='a6000-G5500-V6')
        start_node = "æŠ¥å‘Šåé¦ˆ"


    if task_type == 'çŠ¶æ€æŸ¥è¯¢ä»»åŠ¡':
        """
        çŠ¶æ€æŸ¥è¯¢ä»»åŠ¡ï¼šç³»ç»Ÿæ„ŸçŸ¥ Agent----ï¼ˆå†…ç½®æ“ä½œæ‰§è¡Œ Agentï¼‰----æŠ¥å‘Šåé¦ˆ Agent
        """
        # æ„å»ºç³»ç»Ÿæ„ŸçŸ¥AgentèŠ‚ç‚¹
        node_dict["ç³»ç»Ÿæ„ŸçŸ¥"] = Node("ç³»ç»Ÿæ„ŸçŸ¥", "ç³»ç»Ÿæ„ŸçŸ¥Agent", next_nodes=["æŠ¥å‘Šåé¦ˆ"], hostname='mn10')

        # æ„å»ºæŠ¥å‘Šåé¦ˆAgentèŠ‚ç‚¹
        node_dict["æŠ¥å‘Šåé¦ˆ"] = Node("æŠ¥å‘Šåé¦ˆ", "æŠ¥å‘Šåé¦ˆAgent", next_nodes=["END"], hostname='a6000-G5500-V6')
        start_node = "ç³»ç»Ÿæ„ŸçŸ¥"


    if task_type == 'å¼‚å¸¸å¤„ç†ä»»åŠ¡':
        """
        å¼‚å¸¸å¤„ç†ä»»åŠ¡ï¼šç³»ç»Ÿæ„ŸçŸ¥ Agent----å¼‚å¸¸åˆ†æ Agent----ç­–ç•¥è§„åˆ’ Agent----æ“ä½œæ‰§è¡Œ Agent----æŠ¥å‘Šåé¦ˆ Agent
        """
        # æ„å»ºç³»ç»Ÿæ„ŸçŸ¥AgentèŠ‚ç‚¹
        node_dict["ç³»ç»Ÿæ„ŸçŸ¥"] = Node("ç³»ç»Ÿæ„ŸçŸ¥", "ç³»ç»Ÿæ„ŸçŸ¥Agent", next_nodes=["å¼‚å¸¸åˆ†æ"], hostname='mn10')

        # æ„å»ºå¼‚å¸¸åˆ†æAgentèŠ‚ç‚¹
        node_dict["å¼‚å¸¸åˆ†æ"] = Node("å¼‚å¸¸åˆ†æ", "å¼‚å¸¸åˆ†æAgent", next_nodes=["ç­–ç•¥è§„åˆ’"], hostname='a6000-G5500-V6')

        # æ„å»ºç­–ç•¥è§„åˆ’AgentèŠ‚ç‚¹
        node_dict["ç­–ç•¥è§„åˆ’"] = Node("ç­–ç•¥è§„åˆ’", "ç­–ç•¥è§„åˆ’Agent", next_nodes=["æŠ¥å‘Šåé¦ˆ"], hostname='mn10')

        # æ„å»ºæŠ¥å‘Šåé¦ˆAgentèŠ‚ç‚¹
        node_dict["æŠ¥å‘Šåé¦ˆ"] = Node("æŠ¥å‘Šåé¦ˆ", "æŠ¥å‘Šåé¦ˆAgent", next_nodes=["END"], hostname='a6000-G5500-V6')
        start_node = "ç³»ç»Ÿæ„ŸçŸ¥"


    if task_type == 'å†™æ“ä½œä»»åŠ¡':
        """
        å†™æ“ä½œä»»åŠ¡ï¼šç­–ç•¥è§„åˆ’ Agent----æŠ¥å‘Šåé¦ˆ Agent
        """
        # æ„å»ºç­–ç•¥è§„åˆ’AgentèŠ‚ç‚¹
        node_dict["ç­–ç•¥è§„åˆ’"] = Node("ç­–ç•¥è§„åˆ’", "ç­–ç•¥è§„åˆ’Agent", next_nodes=["æŠ¥å‘Šåé¦ˆ"], hostname='mn10')

        # æ„å»ºæŠ¥å‘Šåé¦ˆAgentèŠ‚ç‚¹
        node_dict["æŠ¥å‘Šåé¦ˆ"] = Node("æŠ¥å‘Šåé¦ˆ", "æŠ¥å‘Šåé¦ˆAgent", next_nodes=["END"], hostname='a6000-G5500-V6')
        start_node = "ç­–ç•¥è§„åˆ’"

    return node_dict, start_node


def travel_dag(nodes, stack):
    if stack[0] == 'END':
        return
    node = nodes[stack[0]]
    print(node.name)
    print("  |")
    stack.pop(0)
    for item in node.next_nodes:
        if item not in stack:
            stack.append(item)
    travel_dag(nodes, stack)

    return


def print_dag(nodes, start_node):
    print("ç”ŸæˆDAGæµ:")
    travel_dag(nodes, [start_node])
    print(" END")


def node_func(state: AgentState):
    print("æµ‹è¯•ç¼“å†²èŠ‚ç‚¹......")
    return


def report_memory_changes(mem_results: list[dict]) -> None:
    """
    æŠŠ Mem0 è¿”å›çš„ç»“æœåˆ†ç»„æ‰“å°åˆ°ç»ˆç«¯å’Œæ—¥å¿—ã€‚
    åªå¤„ç† eventâ‰ NONE çš„æ¡ç›®ï¼›å®Œå…¨æ— å˜åŠ¨æ—¶é™é»˜ã€‚
    """
    changes = {"ADD": [], "UPDATE": [], "DELETE": []}

    for r in mem_results:
        evt = r.get("event", "NONE")
        if evt != "NONE":
            changes[evt].append(r)

    if not any(changes.values()):
        return  # æ²¡æœ‰ä»»ä½•æ–°å¢ / æ›´æ–° / åˆ é™¤

    lines: list[str] = []
    if changes["ADD"]:
        lines.append("ğŸ”¹ æ–°å¢è®°å¿†:")
        lines.extend([f'  + {m["memory"]}' for m in changes["ADD"]])

    if changes["UPDATE"]:
        lines.append("ğŸ”¸ æ›´æ–°è®°å¿†:")
        lines.extend(
            [
                f'  ~ {m["old_memory"]}  â†’  {m["memory"]}'
                if "old_memory" in m
                else f'  ~ {m["memory"]}'
                for m in changes["UPDATE"]
            ]
        )

    if changes["DELETE"]:
        lines.append("ğŸ”» åˆ é™¤è®°å¿†:")
        lines.extend([f'  - {m["memory"]}' for m in changes["DELETE"]])

    msg_out = "\n".join(lines)
    # print(f'\n{msg_out}\n')
    logger.info("\n" + msg_out + "\n")


def result2reply_text(result):
    if isinstance(result, str):
        reply_text = result
    elif isinstance(result, dict):
        # å…¼å®¹åŸæœ‰é€»è¾‘
        if "result" in result and isinstance(result["result"], str):
            reply_text = result["result"]
        elif "result" in result and isinstance(result["result"], dict):
            # åŸæœ‰çš„ result['result']['parts'][0]['text'] ç»“æ„
            parts = result["result"].get("parts")
            if parts and isinstance(parts, list) and "text" in parts[0]:
                reply_text = parts[0]["text"]
            else:
                reply_text = str(result)
        # æ–°å¢ï¼šå…¼å®¹ {'0': {'root_cause': ...}} ç»“æ„
        elif all(isinstance(v, dict) and "root_cause" in v for v in result.values()):
            # åªå–ç¬¬ä¸€ä¸ªkey
            first_key = next(iter(result))
            v = result[first_key]
            reply_text = (
                f"æ ¹å› èŠ‚ç‚¹: {v.get('root_cause', '')}\n"
                f"æ•…éšœç±»å‹: {v.get('failure_type', '')}\n"
                f"Top5æ ¹å› : {v.get('top5', '')}"
            )
        else:
            reply_text = str(result)
    elif isinstance(result, list):
        reply_text = f'æŒ‡æ ‡æ—¶åºå¼‚å¸¸ç‚¹: {result}'
    else:
        reply_text = str(result)
    return reply_text


def push_user_turn(state: AgentState, hostname: str, task: str):
    if task:
        key = ("u", hostname, task)
        if key not in state.get("_msg_keys", set()):
            msg = {
                "role": "user",
                "hostname": hostname,
                "task": task,
            }
            state["messages"] = state.get("messages", []) + [msg]
            state.setdefault("_msg_keys", set()).add(key)
            # logger.info(f"æ·»åŠ æ¡ç›®ï¼š{msg}")


def push_agent_turn(state: AgentState, hostname: str, agent_name: str, response: str):
    if response:
        key = ("a", hostname, agent_name, response)
        msg = {
            "role": "agent",
            "hostname": hostname,
            "name": agent_name,
            "response": response,
        }
        state["messages"] = state.get("messages", []) + [msg]
        state["_msg_keys"].add(key)
        # logger.info(f"æ·»åŠ æ¡ç›®ï¼š{msg}")


def build_agent_url(agent_type: str, hostname: str) -> str:
    """
    æ ¹æ® agent_type å’Œ hostname æ‹¼æ¥ URLã€‚
    ç«¯å£ä¸è·¯å¾„åœ¨æ­¤é›†ä¸­ç®¡ç†ï¼ŒåæœŸè¦æ¢ç«¯å£åªæ”¹è¿™é‡Œå³å¯ã€‚
    """
    route_config = {
        "system_perception": ("5001", "system_perception"),
        "anomaly_analysis": ("5002", "anomaly_analysis"),
        "strategy_plan": ("5003", "strategy_plan"),
        "command_run": ("5004", "command_run"),
        "report_generate": ("5005", "report_generate"),
    }

    if agent_type not in route_config:
        raise KeyError(f"unknown agent_type {agent_type}")

    port, path = route_config[agent_type]
    return f"http://{hostname}:{port}"


async def agent_quest(agent_type: str, node: Node, query: str):
    """
    é‡‡ç”¨å¼‚æ­¥é€šä¿¡å¤„ç†httpäº¤äº’ï¼Œ  ä»»åŠ¡è§£æ â€”â€” å…¶ä»– agent â€”â€” å¤§æ¨¡å‹ api
    """
    hostname = node.hostname or node.name.split("_")[0]
    if hostname in {"start", "end"}:
        return ""

    base_url = build_agent_url(agent_type, hostname)

    # mem_msg = [
    #     {"role": "user", "content": query},
    #     {"role": "assistant", "content": ''}
    # ]

    # mem_res = mem0.add(
    #     mem_msg,
    #     user_id = 'agent',
    #     metadata = {"source": "chat", "time": time.time()}
    # )
    # report_memory_changes(mem_res.get("results", []))

    async with httpx.AsyncClient(verify=False, timeout=300, proxy=None) as httpx_client:
        resolver = A2ACardResolver(httpx_client=httpx_client, base_url=base_url,)
        final_agent_card_to_use = await resolver.get_agent_card()
        client = A2AClient(httpx_client=httpx_client, agent_card=final_agent_card_to_use)

        # mems = mem0.search(query, user_id='agent', limit=5)
        # mem_context = "\n".join(f"- {r['memory']}" for r in mems["results"])

        # system_prompt = f"{query}\nä»¥ä¸‹æ˜¯ä¸ç”¨æˆ·ç›¸å…³çš„è®°å¿†ï¼š\n{mem_context}\nè¯·å›ç­”"

        payload = {
            "message": {
                "role": "user",
                "parts": [{"type": "text", "text": query}],
                "messageId": uuid.uuid4().hex,
            },
        }
        logger.info(f"ğŸ“¤ Sending request to {agent_type}, url: {base_url}")

        # return collected_text
        request = SendMessageRequest(
            id=str(uuid.uuid4()), params=MessageSendParams(**payload)
        )

        response = await client.send_message(request)
        logger.info(f"ğŸ“¥ Response received from {agent_type}, url: {base_url}")

        resp_result = response.model_dump(mode='json', exclude_none=True)

        return resp_result


async def system_perception(state: AgentState, node: Node):
    """
    ç³»ç»Ÿæ„ŸçŸ¥ agentï¼Œè´Ÿè´£æ”¶é›†ç³»ç»ŸçŠ¶æ€ä¿¡æ¯
    """
    agent = "system_perception"
    # print(f"ğŸ¤– Agent {agent} æ‰§è¡Œä¸­...")
    logger.info(f"ğŸ¤– Agent {agent} æ‰§è¡Œä¸­...")

    # ä»èŠ‚ç‚¹ä¸­æå–ç›¸å…³ä¿¡æ¯
    hostname = node.hostname
    task = state['query']
    expert = node.expert

    if task:
        push_user_turn(state, hostname, task)

    agent_result = await agent_quest(agent, node, task)

    # å°†ç»“æœè½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼
    reply_text = result2reply_text(agent_result)
    reply_text = json.loads(reply_text)["result"]

    # å°† agent çš„å“åº”è®°å½•åˆ°çŠ¶æ€
    push_agent_turn(state, hostname, node.agent_type, reply_text)
    # logger.info(f"ğŸ¤– Agent {agent} å“åº”: {str(json.loads(reply_text)['state_exp'])}")

    # è¿”å›å·®åˆ†ç»“æœï¼Œæ›´æ–°çŠ¶æ€
    return {
        "hostname": hostname,
        "sub_task": '',
        "expert": expert,
        "result": {agent: reply_text},
        "status": "success",
    }


async def anomaly_analysis(state: AgentState, node: Node):
    """
    å¼‚å¸¸åˆ†æ agentï¼Œæ ¹æ®æ¨¡å‹åˆ†æç»“æœæ¥å®šä½å¼‚å¸¸æ ¹å› 
    """
    # return state
    agent = "anomaly_analysis"
    # print(f"ğŸ¤– Agent {agent} æ‰§è¡Œä¸­...")
    logger.info(f"ğŸ¤– Agent {agent} æ‰§è¡Œä¸­...")

    hostname  = node.hostname
    sub_task  = state['query']

    if sub_task:
        push_user_turn(state, hostname, sub_task)

    # è°ƒç”¨ agent
    if "æŒ‡æ ‡" in sub_task or "å¼‚å¸¸" in sub_task:
        payload = {
            "folder_path": "/home/tanxh/mas/agents/anomaly_model/AnomalyDetection/data/Dataset1/Node1.csv"
        }
        url = f"http://localhost:5411/time_series_ad"
        response = requests.post(url, json=payload)
        agent_result = response.json()
    elif "æ ¹å› å®šä½" in sub_task:
        payload = {
            "folder_path": "/home/tanxh/mas/agents/anomaly_model/HPC_RCA_Demo/dataset",
            "job_id": "job_8113170",
            "failure_start": 1750129350,
            "failure_end": 1750129800,
            "failure_type": "network_bandwidth",
            "root_node": "cn61903",
            "golden_metrics": [],
            "top_k": 5
        }
        url = f"http://localhost:5410/locate_root_cause"
        response = requests.post(url, json=payload)
        agent_result = response.json()
    else:
        agent_result = "no reply"

    reply_text = result2reply_text(agent_result)

    # è®°å½•å“åº”
    push_agent_turn(state, hostname, node.agent_type, reply_text)
    # logger.info(f"ğŸ¤– Agent {agent} å“åº”: {str(reply_text)}")

    return {
        "hostname": hostname,
        "sub_task": '',
        "result": {agent: reply_text},
        "status": "success",
    }


async def strategy_plan(state: AgentState, node: Node):
    """
    ç­–ç•¥è§„åˆ’ agentï¼Œé€šè¿‡ä¸Šæ¸¸èŠ‚ç‚¹çš„ç»“æœæ¥ç”Ÿæˆä¿®å¤ç­–ç•¥
    """
    agent = "strategy_plan"
    logger.info(f"ğŸ¤– Agent {agent} æ‰§è¡Œä¸­...")

    hostname = node.hostname
    query = state['query']
    up_process_result = state.get("result") if state.get("result") else state.get('query')
    confirmed_params = state.get("confirmed_params")

    if isinstance(up_process_result, dict):
        full_report_lines = []
        for agent_name, raw in up_process_result.items():
            if isinstance(raw, str):
                if raw.startswith("æ ¹å› èŠ‚ç‚¹:") or ("root_cause" in raw and "æ•…éšœç±»å‹" in raw):
                    full_report_lines.append(f"## Agent: anomaly_analysis")
                    full_report_lines.append("```")
                    full_report_lines.append(raw.strip())
                    full_report_lines.append("```")
                    full_report_lines.append("")
                    continue
                if raw.startswith("æŒ‡æ ‡æ—¶åº") or ("å¼‚å¸¸ç‚¹" in raw):
                    full_report_lines.append(f"## Agent: anomaly_analysis")
                    full_report_lines.append("```")
                    full_report_lines.append(raw.strip())
                    full_report_lines.append("```")
                    full_report_lines.append("")
                    continue
            text = raw.replace("\\n", "\n").replace("\\t", "\t")
            blocks = re.split(r'(?=ã€[^ã€‘]+ã€‘)', text)
            for block in blocks:
                m = re.match(r'ã€([^ã€‘]+)ã€‘\s*(.*)', block, re.DOTALL)
                if not m:
                    continue
                sub_host, rest = m.group(1), m.group(2).strip()
                full_report_lines.append(f"## Agent: {agent_name}")
                full_report_lines.append(f"### {sub_host}")
                full_report_lines.append("```")
                full_report_lines.append(rest)
                full_report_lines.append("```")
                full_report_lines.append("")
        all_up_res = "\n".join(full_report_lines)
    elif isinstance(up_process_result, str):
        all_up_res = up_process_result

    anomaly_desc = f"# {query}\n{all_up_res}"
    push_user_turn(state, hostname, anomaly_desc)

    # æ„é€ è¯·æ±‚æ•°æ®
    request_data = {
        "query": anomaly_desc,
        "confirmed_params": confirmed_params
    }
    agent_result = await agent_quest(agent, node, json.dumps(request_data))
    result = json.loads(result2reply_text(agent_result))

    # å‚æ•°ç¡®è®¤æµç¨‹
    if result.get("status") == "need_confirm":
        # è¿”å›ç»™å®¢æˆ·ç«¯ï¼Œç­‰å¾…å‚æ•°ç¡®è®¤
        return {
            "hostname": hostname,
            "result": {agent: None},
            "status": "need_params_confirm",
            "playbooks": result.get("playbooks"),
            "query": result.get("query"),
        }

    # æ­£å¸¸æ‰§è¡Œæµç¨‹
    reply_text = result.get("result", "")
    push_agent_turn(state, hostname, node.agent_type, reply_text)
    return {
        "hostname": hostname,
        "result": {agent: reply_text},
        "status": "success",
    }


async def report_generate(state: AgentState, node: Node):
    """
    æŠ¥å‘Šåé¦ˆ agentï¼Œè´Ÿè´£ç”Ÿæˆæœ€ç»ˆè¿ç»´æŠ¥å‘Š
    """
    agent = "report_generate"
    # print(f"ğŸ¤– Agent {agent} æ‰§è¡Œä¸­...")
    logger.info(f"ğŸ¤– Agent {agent} æ‰§è¡Œä¸­...")

    hostname  = node.hostname
    results = state.get("result") if state.get("result") else state.get('query')

    if isinstance(results, dict):
        full_report_lines = []

        for agent_name, raw in results.items():
            # 1. å°è¯•è§£æä¸º JSON å¹¶æå– state_exp
            if isinstance(raw, str):
                # åˆ¤æ–­æ˜¯å¦ä¸ºæ ¹å› åˆ†ææ ¼å¼
                if raw.startswith("æ ¹å› èŠ‚ç‚¹:") or ("root_cause" in raw and "æ•…éšœç±»å‹" in raw):
                    # ç›´æ¥è¾“å‡º
                    full_report_lines.append(f"## Agent: anomaly_analysis")
                    full_report_lines.append("```")
                    full_report_lines.append(raw.strip())
                    full_report_lines.append("```")
                    full_report_lines.append("")
                    continue

                if raw.startswith("æŒ‡æ ‡æ—¶åº") or ("å¼‚å¸¸ç‚¹" in raw):
                    # ç›´æ¥è¾“å‡º
                    full_report_lines.append(f"## Agent: anomaly_analysis")
                    full_report_lines.append("```")
                    full_report_lines.append(raw.strip())
                    full_report_lines.append("```")
                    full_report_lines.append("")
                    continue

            # 3. é»˜è®¤æŒ‰ state_exp æ ¼å¼å¤„ç†
            # è§£ç è½¬ä¹‰å­—ç¬¦
            text = raw.replace("\\n", "\n").replace("\\t", "\t")
            # åˆ†å‰²æ¯ä¸ªä¸»æœºå—
            blocks = re.split(r'(?=ã€[^ã€‘]+ã€‘)', text)
            for block in blocks:
                m = re.match(r'ã€([^ã€‘]+)ã€‘\s*(.*)', block, re.DOTALL)
                if not m:
                    continue
                sub_host, rest = m.group(1), m.group(2).strip()
                full_report_lines.append(f"## Agent: {agent_name}")
                full_report_lines.append(f"### {sub_host}")
                full_report_lines.append("```")
                full_report_lines.append(rest)
                full_report_lines.append("```")
                full_report_lines.append("")

        full_report_lines.append(state['query'])
        full_report = "\n".join(full_report_lines)

    elif isinstance(results, str):
        full_report = results

    push_user_turn(state, hostname, full_report)

    # è°ƒç”¨ agent
    result = await agent_quest(agent, node, full_report)

    reply_text = result2reply_text(result)
    reply_text = json.loads(reply_text)["result"]

    # è®°å½•å“åº”
    push_agent_turn(state, hostname, node.agent_type, reply_text)
    # logger.info(f"ğŸ¤– Agent {agent} å“åº”: {str(reply_text)}")

    return {
        "hostname": hostname,
        "result": {agent: reply_text},
        "status": "success",
    }


# agentè°ƒç”¨ç´¢å¼•ï¼ŒæŒ‰ç…§èŠ‚ç‚¹åç§°é…ç½®åˆé€‚çš„èŠ‚ç‚¹æ‰§è¡Œå‡½æ•°
agent_dict = {"ç³»ç»Ÿæ„ŸçŸ¥Agent": system_perception, "å¼‚å¸¸åˆ†æAgent": anomaly_analysis, "ç­–ç•¥è§„åˆ’Agent": strategy_plan,
            "æŠ¥å‘Šåé¦ˆAgent": report_generate}


class WorkGraph:
    def __init__(self, dag, start):
        self.graph = None
        self.dag = dag
        self.start = start


    def create_fallback_judge_branch(self, workflow: StateGraph, pre_node, fallback_node):
        # è®¾ç½®å¼‚å¸¸åˆ¤æ–­è¾¹
        def fallback_judge(state: AgentState):
            return "error" if state.get("status") == "error" else "success"

        dag_next_node = self.dag[pre_node].next_nodes[0]
        # å¦‚æœä¸‹ä¸€è·³æ˜¯å­—ç¬¦ä¸² 'END'ï¼Œå°±æ¢æˆå¸¸é‡ END
        dag_next_node = END if dag_next_node == "END" else dag_next_node

        workflow.add_conditional_edges(
            pre_node,
            fallback_judge,
            {"error": fallback_node, "success": dag_next_node},
            # {"error": fallback_node, "success": next_node_name_or_END},
        )
        # print(f"ä¸ºèŠ‚ç‚¹{pre_node}åˆ›å»ºå¼‚å¸¸åˆ¤æ–­åˆ†æ”¯")


    def create_fallback_node(self, workflow):
        """
        é‡æ•…éšœè‡ªåŠ¨åˆ‡æ¢å¤„ç†ç­–ç•¥,
        è®¾ç½®ä¸€ä¸ªç‹¬ç«‹çš„å¼‚å¸¸å¤„ç†èŠ‚ç‚¹,æ¯ä¸ªèŠ‚ç‚¹è¿è¡Œåä½¿ç”¨æ¡ä»¶è¾¹åˆ¤æ–­å¼‚å¸¸å†äº¤ä»˜
        """

        def fall_back(state: AgentState):
            """
            å¼‚å¸¸å¤„ç†å‡½æ•°ï¼Œå¯æ‰©å±•å¢æ·»å…¶ä»–åŠŸèƒ½
            """
            # print("å¼‚å¸¸å¤„ç†èŠ‚ç‚¹")
            # print("ç³»ç»ŸçŠ¶æ€:", state["status"])
            # return
            push_agent_turn(state, "fallback_node",
                    f"å·²è§¦å‘å›é€€ï¼ŒåŸå› ï¼š{state['error_message']}")
            return {"status": "success"}

        workflow.add_node("fallback_node", fall_back)
        workflow.add_edge("fallback_node", END)
        # print("å¼‚å¸¸å¤„ç†èŠ‚ç‚¹åˆ›å»ºå®Œæˆ")


    def dag_to_langgraph(self):
        workflow = StateGraph(AgentState)

        # åˆå§‹åŒ–å¼‚å¸¸å¤„ç†èŠ‚ç‚¹
        self.create_fallback_node(workflow)
        for node in self.dag.values():
            workflow.add_node(node.name, partial(agent_dict[node.agent_type], node=node))
            self.create_fallback_judge_branch(workflow, node.name, "fallback_node")
            # print(f"èŠ‚ç‚¹{node.name}åˆ›å»ºæˆåŠŸ")

        for node in self.dag.values():
            next_nodes = node.next_nodes
            for next_node_name in next_nodes:
                if next_node_name == 'END':
                    workflow.add_edge(node.name, END)
                else:
                    workflow.add_edge(node.name, next_node_name)

        # è®¾ç½®å…¥å£
        workflow.set_entry_point(self.start)

        # ç¼–è¯‘å›¾
        self.graph = workflow.compile()


    def draw_graph(self):
        output_path = "agent_a6000/task_analysis/graph_figs/workflow_dag.png"

        self.graph.get_graph().draw_png(
            output_file_path = output_path,
            fontname = "Noto Sans CJK SC",
        )


    async def run_workflow(self, task_or_state):
        """
        æ”¯æŒä¸¤ç§è°ƒç”¨æ–¹å¼ï¼š
        - é¦–æ¬¡è°ƒç”¨ä¼ å…¥ task å­—ç¬¦ä¸²ï¼Œè‡ªåŠ¨æ„é€ åˆå§‹ state
        - å‚æ•°ç¡®è®¤åä¼ å…¥è¡¥å……å‚æ•°çš„ state dictï¼Œç»§ç»­æ¨è¿› DAG
        """
        if isinstance(task_or_state, dict):
            state = task_or_state
        else:
            state = {
                "messages": [],
                "query": task_or_state,
                "result": {},
                "status": 'success',
                "error_code": 0,
                "error_message": '',
                "hostname": None,
                "sub_task": None,
                "expert": None,
                "session_id": str(uuid.uuid4()),
            }

        config = {"configurable": {"thread_id": str(uuid.uuid4())}}

        # ç”¨ astream é€æ­¥æ¨è¿›ï¼Œæ¯æ­¥æ£€æŸ¥ status
        async for step_state in self.graph.astream(state, config):
            # å‚æ•°ç¡®è®¤æµç¨‹ï¼Œä¸»åŠ¨æš‚åœ
            if step_state.get("status") == "need_params_confirm":
                payload = step_state
                try:
                    result = json.dumps(payload, ensure_ascii=False, indent=2)
                except TypeError:
                    result = str(payload)
                return result
        # æ­£å¸¸æµç¨‹ï¼Œæœ€ç»ˆè¿”å›
        payload = step_state["result"]
        try:
            result = json.dumps(payload, ensure_ascii=False, indent=2)
        except TypeError:
            result = str(payload)
        return result


def process_resp(result_str):
    resp = json.loads(result_str)

    final_key = "report_generate"
    if final_key not in resp:
        raise ValueError(f"ç¼ºå°‘æœ€ç»ˆæŠ¥å‘Š")

    # 1. ä¼˜åŒ–ä¸»æœºå‘½ä»¤è¾“å‡ºæ ¼å¼
    cmd_md_parts = []
    for agent, md in resp.items():
        if agent == final_key:
            continue
        if isinstance(md, str):
            blocks = re.split(r'(?=ã€[^ã€‘]+ã€‘)', md)
            for block in blocks:
                m = re.match(r'ã€([^ã€‘]+)ã€‘\s*(.*)', block, re.DOTALL)
                if not m:
                    continue
                sub_host, rest = m.group(1), m.group(2).strip()
                cmd_md_parts.append(f"## {sub_host}")
                cmd_md_parts.append("")
                cmd_md_parts.append("```bash")
                cmd_md_parts.append(rest)
                cmd_md_parts.append("```")
                cmd_md_parts.append("")
        else:
            cmd_md_parts.append(str(md))
    cmds_result = "\n".join(cmd_md_parts)

    # 2. ä¼˜åŒ–æœ€ç»ˆæŠ¥å‘Šæ ¼å¼ï¼ˆå»é™¤å¤šä½™ä»£ç å—æ ‡è®°ï¼‰
    final_md = resp[final_key].strip()
    final_md = re.sub(r'^\s*```markdown\s*', '', final_md)
    final_md = re.sub(r'\s*```\s*$', '', final_md)

    final_return = f"{cmds_result}\n{final_md}".strip()

    return JSONResponse({
        "choices": [
            {
                "message": {
                    "role": "assistant",
                    "content": final_return
                }
            }
        ]
    })


# === OpenWebUI é£æ ¼ API é›†æˆ ===
openwebui_app = FastAPI()


@openwebui_app.get("/v1/models")
async def get_models():
    return JSONResponse({
        "object": "list",
        "data": [
            {
                "id": "MAS",  # è¿™ä¸ªå¿…é¡»å’Œ chat è¯·æ±‚ä¸­çš„ model ä¿æŒä¸€è‡´
                "object": "model",
                "created": int(time.time()),
                "owned_by": "local"
            }
        ]
    })


@openwebui_app.post("/v1/chat/completions")
async def chat_completions(request: Request):
    data = await request.json()
    # åˆ¤æ–­æ˜¯å¦ä¸ºå‚æ•°è¡¥å……ï¼ˆå¸¦ status/playbooks/confirmed_params/query å­—æ®µï¼‰
    is_param_resume = any(k in data for k in ["status", "playbooks", "confirmed_params", "query"]) and data.get("status") == "need_params_confirm"

    # å…¨å±€ session_id -> (dag, start) ç¼“å­˜
    if not hasattr(chat_completions, "session_cache"):
        chat_completions.session_cache = {}
    session_cache = chat_completions.session_cache

    try:
        if is_param_resume:
            # å‚æ•°è¡¥å……ï¼Œç›´æ¥ç”¨ state ç»§ç»­æ¨è¿›
            session_id = data.get("session_id") or data.get("sessiong_id") or data.get("sessionid") or (data.get("state") and data["state"].get("session_id")) or data.get("state", {}).get("sessiong_id")
            if not session_id:
                session_id = data.get("state", {}).get("session_id")
            if not session_id or session_id not in session_cache:
                return JSONResponse({"error": "å‚æ•°è¡¥å……è¯·æ±‚ç¼ºå°‘ session_id æˆ– session_id æ— æ•ˆã€‚"}, status_code=400)
            dag, start = session_cache[session_id]
            # å¼ºåˆ¶å°† session_id å†™å…¥ stateï¼Œä¿è¯åç»­èŠ‚ç‚¹éƒ½èƒ½è®¿é—®
            data["session_id"] = session_id
            graph = WorkGraph(dag, start)
            graph.dag_to_langgraph()
            result = await graph.run_workflow(data)
        else:
            # é¦–æ¬¡è®¿é—®ï¼Œç”Ÿæˆ DAG
            user_query = ""
            if "messages" in data and isinstance(data["messages"], list):
                user_query = data["messages"][-1].get("content", "")
            elif "prompt" in data:
                user_query = data["prompt"]
            else:
                user_query = data.get("query", "")
            if not user_query:
                return JSONResponse({"error": "No user query provided."}, status_code=400)
            
            node_dict, start = generate_dag_dict(user_query)
            graph = WorkGraph(node_dict, start)
            graph.dag_to_langgraph()
            graph.draw_graph()
            session_id = str(uuid.uuid4())
            session_cache[session_id] = (node_dict, start)

            # é¦–æ¬¡æ„é€  state æ—¶å†™å…¥ session_id
            initial_state = {
                "messages": [],
                "query": user_query,
                "result": {},
                "status": 'success',
                "error_code": 0,
                "error_message": '',
                "hostname": None,
                "sub_task": None,
                "expert": None,
                "session_id": session_id
            }
            result = await graph.run_workflow(initial_state)

            # åœ¨å‚æ•°ç¡®è®¤æ—¶ï¼ŒæŠŠ session_id ä¸€å¹¶è¿”å›
            result_dict = json.loads(result)
            if result_dict.get("status") == "need_params_confirm":
                result_dict["session_id"] = session_id
                return JSONResponse(result_dict)

            return process_resp(result)
    except Exception as e:
        logger.exception("Agent workflow error:")
        return JSONResponse({"error": str(e)}, status_code=500)


# === å¯åŠ¨ FastAPI ===
if __name__ == '__main__':
    uvicorn.run(openwebui_app, host="0.0.0.0", port=5000)
